{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 3.0,
  "eval_steps": 50,
  "global_step": 3750,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.008,
      "grad_norm": 342.3143615722656,
      "learning_rate": 1e-05,
      "loss": 6.0009,
      "step": 10
    },
    {
      "epoch": 0.016,
      "grad_norm": 251.9384307861328,
      "learning_rate": 2e-05,
      "loss": 6.0252,
      "step": 20
    },
    {
      "epoch": 0.024,
      "grad_norm": 163.14666748046875,
      "learning_rate": 3e-05,
      "loss": 5.1386,
      "step": 30
    },
    {
      "epoch": 0.032,
      "grad_norm": 650.2999267578125,
      "learning_rate": 4e-05,
      "loss": 5.1798,
      "step": 40
    },
    {
      "epoch": 0.04,
      "grad_norm": 163.15377807617188,
      "learning_rate": 5e-05,
      "loss": 3.8216,
      "step": 50
    },
    {
      "epoch": 0.04,
      "eval_loss": 2.5266523361206055,
      "eval_runtime": 15.7678,
      "eval_samples_per_second": 63.421,
      "eval_steps_per_second": 7.928,
      "step": 50
    },
    {
      "epoch": 0.048,
      "grad_norm": 601.0142211914062,
      "learning_rate": 6e-05,
      "loss": 3.087,
      "step": 60
    },
    {
      "epoch": 0.056,
      "grad_norm": 94.30509948730469,
      "learning_rate": 7e-05,
      "loss": 2.384,
      "step": 70
    },
    {
      "epoch": 0.064,
      "grad_norm": 32.07740783691406,
      "learning_rate": 8e-05,
      "loss": 1.713,
      "step": 80
    },
    {
      "epoch": 0.072,
      "grad_norm": 49.23200225830078,
      "learning_rate": 9e-05,
      "loss": 1.3805,
      "step": 90
    },
    {
      "epoch": 0.08,
      "grad_norm": 27.15478515625,
      "learning_rate": 0.0001,
      "loss": 1.0253,
      "step": 100
    },
    {
      "epoch": 0.08,
      "eval_loss": 0.6525037884712219,
      "eval_runtime": 15.6497,
      "eval_samples_per_second": 63.899,
      "eval_steps_per_second": 7.987,
      "step": 100
    },
    {
      "epoch": 0.088,
      "grad_norm": 26.624561309814453,
      "learning_rate": 9.972602739726028e-05,
      "loss": 0.9206,
      "step": 110
    },
    {
      "epoch": 0.096,
      "grad_norm": 8.742449760437012,
      "learning_rate": 9.945205479452056e-05,
      "loss": 0.5854,
      "step": 120
    },
    {
      "epoch": 0.104,
      "grad_norm": 21.319427490234375,
      "learning_rate": 9.917808219178082e-05,
      "loss": 0.3947,
      "step": 130
    },
    {
      "epoch": 0.112,
      "grad_norm": 10.534024238586426,
      "learning_rate": 9.89041095890411e-05,
      "loss": 0.4188,
      "step": 140
    },
    {
      "epoch": 0.12,
      "grad_norm": 9.461337089538574,
      "learning_rate": 9.863013698630137e-05,
      "loss": 0.4096,
      "step": 150
    },
    {
      "epoch": 0.12,
      "eval_loss": 0.18986758589744568,
      "eval_runtime": 15.7204,
      "eval_samples_per_second": 63.612,
      "eval_steps_per_second": 7.951,
      "step": 150
    },
    {
      "epoch": 0.128,
      "grad_norm": 6.2668986320495605,
      "learning_rate": 9.835616438356165e-05,
      "loss": 0.3521,
      "step": 160
    },
    {
      "epoch": 0.136,
      "grad_norm": 11.05238151550293,
      "learning_rate": 9.808219178082192e-05,
      "loss": 0.3239,
      "step": 170
    },
    {
      "epoch": 0.144,
      "grad_norm": 5.5145063400268555,
      "learning_rate": 9.78082191780822e-05,
      "loss": 0.2645,
      "step": 180
    },
    {
      "epoch": 0.152,
      "grad_norm": 8.24492073059082,
      "learning_rate": 9.753424657534247e-05,
      "loss": 0.2916,
      "step": 190
    },
    {
      "epoch": 0.16,
      "grad_norm": 3.6066603660583496,
      "learning_rate": 9.726027397260274e-05,
      "loss": 0.2298,
      "step": 200
    },
    {
      "epoch": 0.16,
      "eval_loss": 0.0914178267121315,
      "eval_runtime": 15.7615,
      "eval_samples_per_second": 63.446,
      "eval_steps_per_second": 7.931,
      "step": 200
    },
    {
      "epoch": 0.168,
      "grad_norm": 3.877696990966797,
      "learning_rate": 9.698630136986302e-05,
      "loss": 0.1971,
      "step": 210
    },
    {
      "epoch": 0.176,
      "grad_norm": 2.5887386798858643,
      "learning_rate": 9.67123287671233e-05,
      "loss": 0.2063,
      "step": 220
    },
    {
      "epoch": 0.184,
      "grad_norm": 2.0046024322509766,
      "learning_rate": 9.643835616438356e-05,
      "loss": 0.1652,
      "step": 230
    },
    {
      "epoch": 0.192,
      "grad_norm": 6.573962211608887,
      "learning_rate": 9.616438356164384e-05,
      "loss": 0.2093,
      "step": 240
    },
    {
      "epoch": 0.2,
      "grad_norm": 3.8678934574127197,
      "learning_rate": 9.58904109589041e-05,
      "loss": 0.1356,
      "step": 250
    },
    {
      "epoch": 0.2,
      "eval_loss": 0.07126278430223465,
      "eval_runtime": 15.838,
      "eval_samples_per_second": 63.139,
      "eval_steps_per_second": 7.892,
      "step": 250
    },
    {
      "epoch": 0.208,
      "grad_norm": 3.9649810791015625,
      "learning_rate": 9.561643835616438e-05,
      "loss": 0.095,
      "step": 260
    },
    {
      "epoch": 0.216,
      "grad_norm": 2.9338748455047607,
      "learning_rate": 9.534246575342466e-05,
      "loss": 0.1421,
      "step": 270
    },
    {
      "epoch": 0.224,
      "grad_norm": 5.328263759613037,
      "learning_rate": 9.506849315068494e-05,
      "loss": 0.1736,
      "step": 280
    },
    {
      "epoch": 0.232,
      "grad_norm": 3.8904879093170166,
      "learning_rate": 9.47945205479452e-05,
      "loss": 0.126,
      "step": 290
    },
    {
      "epoch": 0.24,
      "grad_norm": 7.676357269287109,
      "learning_rate": 9.452054794520548e-05,
      "loss": 0.123,
      "step": 300
    },
    {
      "epoch": 0.24,
      "eval_loss": 0.04726489260792732,
      "eval_runtime": 15.8879,
      "eval_samples_per_second": 62.941,
      "eval_steps_per_second": 7.868,
      "step": 300
    },
    {
      "epoch": 0.248,
      "grad_norm": 1.8592489957809448,
      "learning_rate": 9.424657534246576e-05,
      "loss": 0.1216,
      "step": 310
    },
    {
      "epoch": 0.256,
      "grad_norm": 3.436210870742798,
      "learning_rate": 9.397260273972604e-05,
      "loss": 0.1974,
      "step": 320
    },
    {
      "epoch": 0.264,
      "grad_norm": 8.433972358703613,
      "learning_rate": 9.369863013698632e-05,
      "loss": 0.1293,
      "step": 330
    },
    {
      "epoch": 0.272,
      "grad_norm": 4.586466312408447,
      "learning_rate": 9.342465753424658e-05,
      "loss": 0.143,
      "step": 340
    },
    {
      "epoch": 0.28,
      "grad_norm": 5.055758953094482,
      "learning_rate": 9.315068493150684e-05,
      "loss": 0.1457,
      "step": 350
    },
    {
      "epoch": 0.28,
      "eval_loss": 0.03958738222718239,
      "eval_runtime": 16.0619,
      "eval_samples_per_second": 62.259,
      "eval_steps_per_second": 7.782,
      "step": 350
    },
    {
      "epoch": 0.288,
      "grad_norm": 4.451120853424072,
      "learning_rate": 9.287671232876712e-05,
      "loss": 0.0898,
      "step": 360
    },
    {
      "epoch": 0.296,
      "grad_norm": 0.6066002249717712,
      "learning_rate": 9.26027397260274e-05,
      "loss": 0.1693,
      "step": 370
    },
    {
      "epoch": 0.304,
      "grad_norm": 3.2953155040740967,
      "learning_rate": 9.232876712328768e-05,
      "loss": 0.0954,
      "step": 380
    },
    {
      "epoch": 0.312,
      "grad_norm": 4.901031494140625,
      "learning_rate": 9.205479452054796e-05,
      "loss": 0.09,
      "step": 390
    },
    {
      "epoch": 0.32,
      "grad_norm": 5.536909103393555,
      "learning_rate": 9.178082191780822e-05,
      "loss": 0.0896,
      "step": 400
    },
    {
      "epoch": 0.32,
      "eval_loss": 0.04554697871208191,
      "eval_runtime": 16.2877,
      "eval_samples_per_second": 61.396,
      "eval_steps_per_second": 7.675,
      "step": 400
    },
    {
      "epoch": 0.328,
      "grad_norm": 0.7242996096611023,
      "learning_rate": 9.15068493150685e-05,
      "loss": 0.0805,
      "step": 410
    },
    {
      "epoch": 0.336,
      "grad_norm": 0.9945757985115051,
      "learning_rate": 9.123287671232878e-05,
      "loss": 0.0463,
      "step": 420
    },
    {
      "epoch": 0.344,
      "grad_norm": 1.7500468492507935,
      "learning_rate": 9.095890410958905e-05,
      "loss": 0.1144,
      "step": 430
    },
    {
      "epoch": 0.352,
      "grad_norm": 0.9986070394515991,
      "learning_rate": 9.068493150684932e-05,
      "loss": 0.0974,
      "step": 440
    },
    {
      "epoch": 0.36,
      "grad_norm": 3.1454410552978516,
      "learning_rate": 9.041095890410958e-05,
      "loss": 0.0511,
      "step": 450
    },
    {
      "epoch": 0.36,
      "eval_loss": 0.0334438681602478,
      "eval_runtime": 16.1926,
      "eval_samples_per_second": 61.756,
      "eval_steps_per_second": 7.72,
      "step": 450
    },
    {
      "epoch": 0.368,
      "grad_norm": 2.047860860824585,
      "learning_rate": 9.013698630136986e-05,
      "loss": 0.0588,
      "step": 460
    },
    {
      "epoch": 0.376,
      "grad_norm": 0.47257205843925476,
      "learning_rate": 8.986301369863014e-05,
      "loss": 0.0839,
      "step": 470
    },
    {
      "epoch": 0.384,
      "grad_norm": 5.569790840148926,
      "learning_rate": 8.958904109589042e-05,
      "loss": 0.093,
      "step": 480
    },
    {
      "epoch": 0.392,
      "grad_norm": 2.0821917057037354,
      "learning_rate": 8.93150684931507e-05,
      "loss": 0.0326,
      "step": 490
    },
    {
      "epoch": 0.4,
      "grad_norm": 2.252241611480713,
      "learning_rate": 8.904109589041096e-05,
      "loss": 0.0764,
      "step": 500
    },
    {
      "epoch": 0.4,
      "eval_loss": 0.03165176510810852,
      "eval_runtime": 19.4616,
      "eval_samples_per_second": 51.383,
      "eval_steps_per_second": 6.423,
      "step": 500
    },
    {
      "epoch": 0.408,
      "grad_norm": 1.8912822008132935,
      "learning_rate": 8.876712328767124e-05,
      "loss": 0.0609,
      "step": 510
    },
    {
      "epoch": 0.416,
      "grad_norm": 1.2707573175430298,
      "learning_rate": 8.849315068493151e-05,
      "loss": 0.084,
      "step": 520
    },
    {
      "epoch": 0.424,
      "grad_norm": 1.2974315881729126,
      "learning_rate": 8.821917808219179e-05,
      "loss": 0.0523,
      "step": 530
    },
    {
      "epoch": 0.432,
      "grad_norm": 0.9469766616821289,
      "learning_rate": 8.794520547945207e-05,
      "loss": 0.0694,
      "step": 540
    },
    {
      "epoch": 0.44,
      "grad_norm": 1.1078945398330688,
      "learning_rate": 8.767123287671233e-05,
      "loss": 0.0425,
      "step": 550
    },
    {
      "epoch": 0.44,
      "eval_loss": 0.03437618538737297,
      "eval_runtime": 16.7958,
      "eval_samples_per_second": 59.539,
      "eval_steps_per_second": 7.442,
      "step": 550
    },
    {
      "epoch": 0.448,
      "grad_norm": 0.05419810861349106,
      "learning_rate": 8.73972602739726e-05,
      "loss": 0.0484,
      "step": 560
    },
    {
      "epoch": 0.456,
      "grad_norm": 1.3026689291000366,
      "learning_rate": 8.712328767123288e-05,
      "loss": 0.0566,
      "step": 570
    },
    {
      "epoch": 0.464,
      "grad_norm": 1.2118109464645386,
      "learning_rate": 8.684931506849315e-05,
      "loss": 0.0379,
      "step": 580
    },
    {
      "epoch": 0.472,
      "grad_norm": 1.6802583932876587,
      "learning_rate": 8.657534246575343e-05,
      "loss": 0.0739,
      "step": 590
    },
    {
      "epoch": 0.48,
      "grad_norm": 0.5497663617134094,
      "learning_rate": 8.630136986301371e-05,
      "loss": 0.0741,
      "step": 600
    },
    {
      "epoch": 0.48,
      "eval_loss": 0.035753894597291946,
      "eval_runtime": 20.3996,
      "eval_samples_per_second": 49.021,
      "eval_steps_per_second": 6.128,
      "step": 600
    },
    {
      "epoch": 0.488,
      "grad_norm": 1.239699125289917,
      "learning_rate": 8.602739726027397e-05,
      "loss": 0.0633,
      "step": 610
    },
    {
      "epoch": 0.496,
      "grad_norm": 1.1128016710281372,
      "learning_rate": 8.575342465753425e-05,
      "loss": 0.0693,
      "step": 620
    },
    {
      "epoch": 0.504,
      "grad_norm": 0.87567138671875,
      "learning_rate": 8.547945205479453e-05,
      "loss": 0.0487,
      "step": 630
    },
    {
      "epoch": 0.512,
      "grad_norm": 6.26271915435791,
      "learning_rate": 8.520547945205481e-05,
      "loss": 0.0933,
      "step": 640
    },
    {
      "epoch": 0.52,
      "grad_norm": 1.8784757852554321,
      "learning_rate": 8.493150684931507e-05,
      "loss": 0.0523,
      "step": 650
    },
    {
      "epoch": 0.52,
      "eval_loss": 0.023703869432210922,
      "eval_runtime": 19.6479,
      "eval_samples_per_second": 50.896,
      "eval_steps_per_second": 6.362,
      "step": 650
    },
    {
      "epoch": 0.528,
      "grad_norm": 3.8055100440979004,
      "learning_rate": 8.465753424657534e-05,
      "loss": 0.0875,
      "step": 660
    },
    {
      "epoch": 0.536,
      "grad_norm": 1.0954124927520752,
      "learning_rate": 8.438356164383561e-05,
      "loss": 0.0309,
      "step": 670
    },
    {
      "epoch": 0.544,
      "grad_norm": 3.0762133598327637,
      "learning_rate": 8.410958904109589e-05,
      "loss": 0.0811,
      "step": 680
    },
    {
      "epoch": 0.552,
      "grad_norm": 3.4819300174713135,
      "learning_rate": 8.383561643835617e-05,
      "loss": 0.0589,
      "step": 690
    },
    {
      "epoch": 0.56,
      "grad_norm": 0.3840917646884918,
      "learning_rate": 8.356164383561645e-05,
      "loss": 0.0956,
      "step": 700
    },
    {
      "epoch": 0.56,
      "eval_loss": 0.029079575091600418,
      "eval_runtime": 21.612,
      "eval_samples_per_second": 46.27,
      "eval_steps_per_second": 5.784,
      "step": 700
    },
    {
      "epoch": 0.568,
      "grad_norm": 0.7972502708435059,
      "learning_rate": 8.328767123287671e-05,
      "loss": 0.0241,
      "step": 710
    },
    {
      "epoch": 0.576,
      "grad_norm": 1.9480985403060913,
      "learning_rate": 8.301369863013699e-05,
      "loss": 0.0766,
      "step": 720
    },
    {
      "epoch": 0.584,
      "grad_norm": 4.682775020599365,
      "learning_rate": 8.273972602739727e-05,
      "loss": 0.112,
      "step": 730
    },
    {
      "epoch": 0.592,
      "grad_norm": 2.131382942199707,
      "learning_rate": 8.246575342465755e-05,
      "loss": 0.0645,
      "step": 740
    },
    {
      "epoch": 0.6,
      "grad_norm": 4.7556681632995605,
      "learning_rate": 8.219178082191781e-05,
      "loss": 0.0724,
      "step": 750
    },
    {
      "epoch": 0.6,
      "eval_loss": 0.024738483130931854,
      "eval_runtime": 21.5986,
      "eval_samples_per_second": 46.299,
      "eval_steps_per_second": 5.787,
      "step": 750
    },
    {
      "epoch": 0.608,
      "grad_norm": 0.7304609417915344,
      "learning_rate": 8.191780821917809e-05,
      "loss": 0.0684,
      "step": 760
    },
    {
      "epoch": 0.616,
      "grad_norm": 0.9506180882453918,
      "learning_rate": 8.164383561643835e-05,
      "loss": 0.0268,
      "step": 770
    },
    {
      "epoch": 0.624,
      "grad_norm": 0.2882358133792877,
      "learning_rate": 8.136986301369863e-05,
      "loss": 0.0592,
      "step": 780
    },
    {
      "epoch": 0.632,
      "grad_norm": 7.672696590423584,
      "learning_rate": 8.109589041095891e-05,
      "loss": 0.1288,
      "step": 790
    },
    {
      "epoch": 0.64,
      "grad_norm": 0.058952003717422485,
      "learning_rate": 8.082191780821919e-05,
      "loss": 0.0784,
      "step": 800
    },
    {
      "epoch": 0.64,
      "eval_loss": 0.024988098070025444,
      "eval_runtime": 21.5731,
      "eval_samples_per_second": 46.354,
      "eval_steps_per_second": 5.794,
      "step": 800
    },
    {
      "epoch": 0.648,
      "grad_norm": 0.22802592813968658,
      "learning_rate": 8.054794520547946e-05,
      "loss": 0.0406,
      "step": 810
    },
    {
      "epoch": 0.656,
      "grad_norm": 0.5235990881919861,
      "learning_rate": 8.027397260273973e-05,
      "loss": 0.056,
      "step": 820
    },
    {
      "epoch": 0.664,
      "grad_norm": 0.569226861000061,
      "learning_rate": 8e-05,
      "loss": 0.0655,
      "step": 830
    },
    {
      "epoch": 0.672,
      "grad_norm": 0.7579675912857056,
      "learning_rate": 7.972602739726027e-05,
      "loss": 0.0765,
      "step": 840
    },
    {
      "epoch": 0.68,
      "grad_norm": 2.999518632888794,
      "learning_rate": 7.945205479452055e-05,
      "loss": 0.0294,
      "step": 850
    },
    {
      "epoch": 0.68,
      "eval_loss": 0.02757059969007969,
      "eval_runtime": 21.6372,
      "eval_samples_per_second": 46.217,
      "eval_steps_per_second": 5.777,
      "step": 850
    },
    {
      "epoch": 0.688,
      "grad_norm": 1.2645795345306396,
      "learning_rate": 7.917808219178083e-05,
      "loss": 0.0567,
      "step": 860
    },
    {
      "epoch": 0.696,
      "grad_norm": 4.562007904052734,
      "learning_rate": 7.890410958904109e-05,
      "loss": 0.0682,
      "step": 870
    },
    {
      "epoch": 0.704,
      "grad_norm": 0.07068333774805069,
      "learning_rate": 7.863013698630137e-05,
      "loss": 0.0328,
      "step": 880
    },
    {
      "epoch": 0.712,
      "grad_norm": 0.8514870405197144,
      "learning_rate": 7.835616438356165e-05,
      "loss": 0.017,
      "step": 890
    },
    {
      "epoch": 0.72,
      "grad_norm": 0.13394513726234436,
      "learning_rate": 7.808219178082192e-05,
      "loss": 0.0307,
      "step": 900
    },
    {
      "epoch": 0.72,
      "eval_loss": 0.028965745121240616,
      "eval_runtime": 21.6231,
      "eval_samples_per_second": 46.247,
      "eval_steps_per_second": 5.781,
      "step": 900
    },
    {
      "epoch": 0.728,
      "grad_norm": 7.168375492095947,
      "learning_rate": 7.78082191780822e-05,
      "loss": 0.0491,
      "step": 910
    },
    {
      "epoch": 0.736,
      "grad_norm": 0.1978677213191986,
      "learning_rate": 7.753424657534247e-05,
      "loss": 0.0531,
      "step": 920
    },
    {
      "epoch": 0.744,
      "grad_norm": 0.6162046790122986,
      "learning_rate": 7.726027397260274e-05,
      "loss": 0.0423,
      "step": 930
    },
    {
      "epoch": 0.752,
      "grad_norm": 1.5434234142303467,
      "learning_rate": 7.698630136986301e-05,
      "loss": 0.0523,
      "step": 940
    },
    {
      "epoch": 0.76,
      "grad_norm": 0.8126989006996155,
      "learning_rate": 7.671232876712329e-05,
      "loss": 0.0477,
      "step": 950
    },
    {
      "epoch": 0.76,
      "eval_loss": 0.024934299290180206,
      "eval_runtime": 21.6741,
      "eval_samples_per_second": 46.138,
      "eval_steps_per_second": 5.767,
      "step": 950
    },
    {
      "epoch": 0.768,
      "grad_norm": 0.04023098200559616,
      "learning_rate": 7.643835616438356e-05,
      "loss": 0.0471,
      "step": 960
    },
    {
      "epoch": 0.776,
      "grad_norm": 2.5097620487213135,
      "learning_rate": 7.616438356164384e-05,
      "loss": 0.0275,
      "step": 970
    },
    {
      "epoch": 0.784,
      "grad_norm": 2.809095621109009,
      "learning_rate": 7.589041095890411e-05,
      "loss": 0.0368,
      "step": 980
    },
    {
      "epoch": 0.792,
      "grad_norm": 0.885765790939331,
      "learning_rate": 7.561643835616439e-05,
      "loss": 0.0911,
      "step": 990
    },
    {
      "epoch": 0.8,
      "grad_norm": 2.875171184539795,
      "learning_rate": 7.534246575342466e-05,
      "loss": 0.0668,
      "step": 1000
    },
    {
      "epoch": 0.8,
      "eval_loss": 0.025229576975107193,
      "eval_runtime": 21.695,
      "eval_samples_per_second": 46.093,
      "eval_steps_per_second": 5.762,
      "step": 1000
    },
    {
      "epoch": 0.808,
      "grad_norm": 0.13296788930892944,
      "learning_rate": 7.506849315068494e-05,
      "loss": 0.0341,
      "step": 1010
    },
    {
      "epoch": 0.816,
      "grad_norm": 0.34257805347442627,
      "learning_rate": 7.479452054794522e-05,
      "loss": 0.034,
      "step": 1020
    },
    {
      "epoch": 0.824,
      "grad_norm": 0.6058387160301208,
      "learning_rate": 7.452054794520548e-05,
      "loss": 0.0363,
      "step": 1030
    },
    {
      "epoch": 0.832,
      "grad_norm": 0.7015665769577026,
      "learning_rate": 7.424657534246575e-05,
      "loss": 0.0259,
      "step": 1040
    },
    {
      "epoch": 0.84,
      "grad_norm": 1.3989603519439697,
      "learning_rate": 7.397260273972603e-05,
      "loss": 0.0452,
      "step": 1050
    },
    {
      "epoch": 0.84,
      "eval_loss": 0.023350868374109268,
      "eval_runtime": 21.6055,
      "eval_samples_per_second": 46.285,
      "eval_steps_per_second": 5.786,
      "step": 1050
    },
    {
      "epoch": 0.848,
      "grad_norm": 0.1775919646024704,
      "learning_rate": 7.36986301369863e-05,
      "loss": 0.0096,
      "step": 1060
    },
    {
      "epoch": 0.856,
      "grad_norm": 0.22078487277030945,
      "learning_rate": 7.342465753424658e-05,
      "loss": 0.0631,
      "step": 1070
    },
    {
      "epoch": 0.864,
      "grad_norm": 0.22325173020362854,
      "learning_rate": 7.315068493150685e-05,
      "loss": 0.0449,
      "step": 1080
    },
    {
      "epoch": 0.872,
      "grad_norm": 2.2934281826019287,
      "learning_rate": 7.287671232876712e-05,
      "loss": 0.0531,
      "step": 1090
    },
    {
      "epoch": 0.88,
      "grad_norm": 0.454650342464447,
      "learning_rate": 7.26027397260274e-05,
      "loss": 0.0674,
      "step": 1100
    },
    {
      "epoch": 0.88,
      "eval_loss": 0.02223670668900013,
      "eval_runtime": 21.6201,
      "eval_samples_per_second": 46.253,
      "eval_steps_per_second": 5.782,
      "step": 1100
    },
    {
      "epoch": 0.888,
      "grad_norm": 0.3863196074962616,
      "learning_rate": 7.232876712328768e-05,
      "loss": 0.0139,
      "step": 1110
    },
    {
      "epoch": 0.896,
      "grad_norm": 0.03456716984510422,
      "learning_rate": 7.205479452054796e-05,
      "loss": 0.0273,
      "step": 1120
    },
    {
      "epoch": 0.904,
      "grad_norm": 0.8415141701698303,
      "learning_rate": 7.178082191780822e-05,
      "loss": 0.0659,
      "step": 1130
    },
    {
      "epoch": 0.912,
      "grad_norm": 0.8890745639801025,
      "learning_rate": 7.150684931506849e-05,
      "loss": 0.1289,
      "step": 1140
    },
    {
      "epoch": 0.92,
      "grad_norm": 0.3718321919441223,
      "learning_rate": 7.123287671232876e-05,
      "loss": 0.0149,
      "step": 1150
    },
    {
      "epoch": 0.92,
      "eval_loss": 0.020408913493156433,
      "eval_runtime": 21.547,
      "eval_samples_per_second": 46.41,
      "eval_steps_per_second": 5.801,
      "step": 1150
    },
    {
      "epoch": 0.928,
      "grad_norm": 0.7226507663726807,
      "learning_rate": 7.095890410958904e-05,
      "loss": 0.0555,
      "step": 1160
    },
    {
      "epoch": 0.936,
      "grad_norm": 0.5568185448646545,
      "learning_rate": 7.068493150684932e-05,
      "loss": 0.0317,
      "step": 1170
    },
    {
      "epoch": 0.944,
      "grad_norm": 0.05753463879227638,
      "learning_rate": 7.04109589041096e-05,
      "loss": 0.0553,
      "step": 1180
    },
    {
      "epoch": 0.952,
      "grad_norm": 1.2712956666946411,
      "learning_rate": 7.013698630136986e-05,
      "loss": 0.0214,
      "step": 1190
    },
    {
      "epoch": 0.96,
      "grad_norm": 1.0580633878707886,
      "learning_rate": 6.986301369863014e-05,
      "loss": 0.0248,
      "step": 1200
    },
    {
      "epoch": 0.96,
      "eval_loss": 0.02505151554942131,
      "eval_runtime": 21.5417,
      "eval_samples_per_second": 46.422,
      "eval_steps_per_second": 5.803,
      "step": 1200
    },
    {
      "epoch": 0.968,
      "grad_norm": 0.07756343483924866,
      "learning_rate": 6.958904109589042e-05,
      "loss": 0.0288,
      "step": 1210
    },
    {
      "epoch": 0.976,
      "grad_norm": 0.7933893799781799,
      "learning_rate": 6.93150684931507e-05,
      "loss": 0.0521,
      "step": 1220
    },
    {
      "epoch": 0.984,
      "grad_norm": 3.347107410430908,
      "learning_rate": 6.904109589041097e-05,
      "loss": 0.0922,
      "step": 1230
    },
    {
      "epoch": 0.992,
      "grad_norm": 0.48668983578681946,
      "learning_rate": 6.876712328767124e-05,
      "loss": 0.0611,
      "step": 1240
    },
    {
      "epoch": 1.0,
      "grad_norm": 8.56624698638916,
      "learning_rate": 6.84931506849315e-05,
      "loss": 0.0379,
      "step": 1250
    },
    {
      "epoch": 1.0,
      "eval_loss": 0.02090449072420597,
      "eval_runtime": 21.6084,
      "eval_samples_per_second": 46.278,
      "eval_steps_per_second": 5.785,
      "step": 1250
    },
    {
      "epoch": 1.008,
      "grad_norm": 5.0727458000183105,
      "learning_rate": 6.821917808219178e-05,
      "loss": 0.0177,
      "step": 1260
    },
    {
      "epoch": 1.016,
      "grad_norm": 0.5775026082992554,
      "learning_rate": 6.794520547945206e-05,
      "loss": 0.0453,
      "step": 1270
    },
    {
      "epoch": 1.024,
      "grad_norm": 5.154294490814209,
      "learning_rate": 6.767123287671234e-05,
      "loss": 0.0466,
      "step": 1280
    },
    {
      "epoch": 1.032,
      "grad_norm": 1.032725214958191,
      "learning_rate": 6.73972602739726e-05,
      "loss": 0.0106,
      "step": 1290
    },
    {
      "epoch": 1.04,
      "grad_norm": 0.586540699005127,
      "learning_rate": 6.712328767123288e-05,
      "loss": 0.0201,
      "step": 1300
    },
    {
      "epoch": 1.04,
      "eval_loss": 0.02054969035089016,
      "eval_runtime": 21.5666,
      "eval_samples_per_second": 46.368,
      "eval_steps_per_second": 5.796,
      "step": 1300
    },
    {
      "epoch": 1.048,
      "grad_norm": 0.28357669711112976,
      "learning_rate": 6.684931506849316e-05,
      "loss": 0.0501,
      "step": 1310
    },
    {
      "epoch": 1.056,
      "grad_norm": 1.4660683870315552,
      "learning_rate": 6.657534246575343e-05,
      "loss": 0.0176,
      "step": 1320
    },
    {
      "epoch": 1.064,
      "grad_norm": 0.17430706322193146,
      "learning_rate": 6.630136986301371e-05,
      "loss": 0.0064,
      "step": 1330
    },
    {
      "epoch": 1.072,
      "grad_norm": 1.284639835357666,
      "learning_rate": 6.602739726027398e-05,
      "loss": 0.0174,
      "step": 1340
    },
    {
      "epoch": 1.08,
      "grad_norm": 2.429130792617798,
      "learning_rate": 6.575342465753424e-05,
      "loss": 0.0333,
      "step": 1350
    },
    {
      "epoch": 1.08,
      "eval_loss": 0.021673832088708878,
      "eval_runtime": 21.4613,
      "eval_samples_per_second": 46.595,
      "eval_steps_per_second": 5.824,
      "step": 1350
    },
    {
      "epoch": 1.088,
      "grad_norm": 0.04760860651731491,
      "learning_rate": 6.547945205479452e-05,
      "loss": 0.0429,
      "step": 1360
    },
    {
      "epoch": 1.096,
      "grad_norm": 1.7292951345443726,
      "learning_rate": 6.52054794520548e-05,
      "loss": 0.1219,
      "step": 1370
    },
    {
      "epoch": 1.104,
      "grad_norm": 1.9884339570999146,
      "learning_rate": 6.493150684931507e-05,
      "loss": 0.0197,
      "step": 1380
    },
    {
      "epoch": 1.112,
      "grad_norm": 3.0839176177978516,
      "learning_rate": 6.465753424657535e-05,
      "loss": 0.0368,
      "step": 1390
    },
    {
      "epoch": 1.12,
      "grad_norm": 0.02875404804944992,
      "learning_rate": 6.438356164383562e-05,
      "loss": 0.0169,
      "step": 1400
    },
    {
      "epoch": 1.12,
      "eval_loss": 0.018540842458605766,
      "eval_runtime": 21.5979,
      "eval_samples_per_second": 46.301,
      "eval_steps_per_second": 5.788,
      "step": 1400
    },
    {
      "epoch": 1.1280000000000001,
      "grad_norm": 0.6873936653137207,
      "learning_rate": 6.41095890410959e-05,
      "loss": 0.0573,
      "step": 1410
    },
    {
      "epoch": 1.1360000000000001,
      "grad_norm": 0.9214739799499512,
      "learning_rate": 6.383561643835617e-05,
      "loss": 0.0361,
      "step": 1420
    },
    {
      "epoch": 1.144,
      "grad_norm": 0.06932642310857773,
      "learning_rate": 6.356164383561645e-05,
      "loss": 0.0204,
      "step": 1430
    },
    {
      "epoch": 1.152,
      "grad_norm": 0.2749132513999939,
      "learning_rate": 6.328767123287671e-05,
      "loss": 0.0356,
      "step": 1440
    },
    {
      "epoch": 1.16,
      "grad_norm": 0.26296141743659973,
      "learning_rate": 6.301369863013699e-05,
      "loss": 0.0213,
      "step": 1450
    },
    {
      "epoch": 1.16,
      "eval_loss": 0.018094466999173164,
      "eval_runtime": 21.6036,
      "eval_samples_per_second": 46.289,
      "eval_steps_per_second": 5.786,
      "step": 1450
    },
    {
      "epoch": 1.168,
      "grad_norm": 1.8620712757110596,
      "learning_rate": 6.273972602739726e-05,
      "loss": 0.0306,
      "step": 1460
    },
    {
      "epoch": 1.176,
      "grad_norm": 0.39547187089920044,
      "learning_rate": 6.246575342465753e-05,
      "loss": 0.0471,
      "step": 1470
    },
    {
      "epoch": 1.184,
      "grad_norm": 1.2425212860107422,
      "learning_rate": 6.219178082191781e-05,
      "loss": 0.0626,
      "step": 1480
    },
    {
      "epoch": 1.192,
      "grad_norm": 0.05923769250512123,
      "learning_rate": 6.191780821917809e-05,
      "loss": 0.0309,
      "step": 1490
    },
    {
      "epoch": 1.2,
      "grad_norm": 0.6676239967346191,
      "learning_rate": 6.164383561643835e-05,
      "loss": 0.0289,
      "step": 1500
    },
    {
      "epoch": 1.2,
      "eval_loss": 0.017938407137989998,
      "eval_runtime": 21.5841,
      "eval_samples_per_second": 46.33,
      "eval_steps_per_second": 5.791,
      "step": 1500
    },
    {
      "epoch": 1.208,
      "grad_norm": 0.05668776109814644,
      "learning_rate": 6.136986301369863e-05,
      "loss": 0.0456,
      "step": 1510
    },
    {
      "epoch": 1.216,
      "grad_norm": 0.20323941111564636,
      "learning_rate": 6.109589041095891e-05,
      "loss": 0.0229,
      "step": 1520
    },
    {
      "epoch": 1.224,
      "grad_norm": 0.0764264464378357,
      "learning_rate": 6.082191780821919e-05,
      "loss": 0.0197,
      "step": 1530
    },
    {
      "epoch": 1.232,
      "grad_norm": 0.20863397419452667,
      "learning_rate": 6.054794520547945e-05,
      "loss": 0.0222,
      "step": 1540
    },
    {
      "epoch": 1.24,
      "grad_norm": 0.06426974385976791,
      "learning_rate": 6.0273972602739724e-05,
      "loss": 0.0233,
      "step": 1550
    },
    {
      "epoch": 1.24,
      "eval_loss": 0.019316790625452995,
      "eval_runtime": 21.4089,
      "eval_samples_per_second": 46.709,
      "eval_steps_per_second": 5.839,
      "step": 1550
    },
    {
      "epoch": 1.248,
      "grad_norm": 1.4848703145980835,
      "learning_rate": 6e-05,
      "loss": 0.0312,
      "step": 1560
    },
    {
      "epoch": 1.256,
      "grad_norm": 0.2761245369911194,
      "learning_rate": 5.972602739726027e-05,
      "loss": 0.0558,
      "step": 1570
    },
    {
      "epoch": 1.264,
      "grad_norm": 0.26158764958381653,
      "learning_rate": 5.945205479452055e-05,
      "loss": 0.0226,
      "step": 1580
    },
    {
      "epoch": 1.272,
      "grad_norm": 0.057116419076919556,
      "learning_rate": 5.917808219178083e-05,
      "loss": 0.0285,
      "step": 1590
    },
    {
      "epoch": 1.28,
      "grad_norm": 0.15300199389457703,
      "learning_rate": 5.89041095890411e-05,
      "loss": 0.0303,
      "step": 1600
    },
    {
      "epoch": 1.28,
      "eval_loss": 0.018945636227726936,
      "eval_runtime": 21.5966,
      "eval_samples_per_second": 46.304,
      "eval_steps_per_second": 5.788,
      "step": 1600
    },
    {
      "epoch": 1.288,
      "grad_norm": 1.5802377462387085,
      "learning_rate": 5.863013698630138e-05,
      "loss": 0.0235,
      "step": 1610
    },
    {
      "epoch": 1.296,
      "grad_norm": 0.12005618214607239,
      "learning_rate": 5.835616438356165e-05,
      "loss": 0.0221,
      "step": 1620
    },
    {
      "epoch": 1.304,
      "grad_norm": 0.12787505984306335,
      "learning_rate": 5.808219178082191e-05,
      "loss": 0.077,
      "step": 1630
    },
    {
      "epoch": 1.312,
      "grad_norm": 1.062717080116272,
      "learning_rate": 5.780821917808219e-05,
      "loss": 0.0324,
      "step": 1640
    },
    {
      "epoch": 1.32,
      "grad_norm": 0.10094251483678818,
      "learning_rate": 5.753424657534247e-05,
      "loss": 0.0249,
      "step": 1650
    },
    {
      "epoch": 1.32,
      "eval_loss": 0.018037501722574234,
      "eval_runtime": 21.504,
      "eval_samples_per_second": 46.503,
      "eval_steps_per_second": 5.813,
      "step": 1650
    },
    {
      "epoch": 1.328,
      "grad_norm": 1.3742166757583618,
      "learning_rate": 5.726027397260274e-05,
      "loss": 0.0149,
      "step": 1660
    },
    {
      "epoch": 1.336,
      "grad_norm": 1.573935866355896,
      "learning_rate": 5.698630136986302e-05,
      "loss": 0.0797,
      "step": 1670
    },
    {
      "epoch": 1.3439999999999999,
      "grad_norm": 0.031039070338010788,
      "learning_rate": 5.671232876712329e-05,
      "loss": 0.0305,
      "step": 1680
    },
    {
      "epoch": 1.3519999999999999,
      "grad_norm": 0.057985056191682816,
      "learning_rate": 5.643835616438357e-05,
      "loss": 0.0173,
      "step": 1690
    },
    {
      "epoch": 1.3599999999999999,
      "grad_norm": 0.9109511971473694,
      "learning_rate": 5.616438356164384e-05,
      "loss": 0.065,
      "step": 1700
    },
    {
      "epoch": 1.3599999999999999,
      "eval_loss": 0.016982166096568108,
      "eval_runtime": 21.5612,
      "eval_samples_per_second": 46.38,
      "eval_steps_per_second": 5.797,
      "step": 1700
    },
    {
      "epoch": 1.3679999999999999,
      "grad_norm": 1.078916072845459,
      "learning_rate": 5.5890410958904116e-05,
      "loss": 0.0152,
      "step": 1710
    },
    {
      "epoch": 1.376,
      "grad_norm": 0.09088202565908432,
      "learning_rate": 5.5616438356164394e-05,
      "loss": 0.0655,
      "step": 1720
    },
    {
      "epoch": 1.384,
      "grad_norm": 2.061781406402588,
      "learning_rate": 5.534246575342466e-05,
      "loss": 0.0259,
      "step": 1730
    },
    {
      "epoch": 1.392,
      "grad_norm": 0.05347147211432457,
      "learning_rate": 5.506849315068493e-05,
      "loss": 0.0238,
      "step": 1740
    },
    {
      "epoch": 1.4,
      "grad_norm": 0.9623178839683533,
      "learning_rate": 5.479452054794521e-05,
      "loss": 0.0184,
      "step": 1750
    },
    {
      "epoch": 1.4,
      "eval_loss": 0.017920799553394318,
      "eval_runtime": 21.6248,
      "eval_samples_per_second": 46.243,
      "eval_steps_per_second": 5.78,
      "step": 1750
    },
    {
      "epoch": 1.408,
      "grad_norm": 0.049780409783124924,
      "learning_rate": 5.452054794520548e-05,
      "loss": 0.0652,
      "step": 1760
    },
    {
      "epoch": 1.416,
      "grad_norm": 0.21927444636821747,
      "learning_rate": 5.4246575342465756e-05,
      "loss": 0.0233,
      "step": 1770
    },
    {
      "epoch": 1.424,
      "grad_norm": 2.2430429458618164,
      "learning_rate": 5.397260273972603e-05,
      "loss": 0.0411,
      "step": 1780
    },
    {
      "epoch": 1.432,
      "grad_norm": 0.7122311592102051,
      "learning_rate": 5.3698630136986305e-05,
      "loss": 0.0421,
      "step": 1790
    },
    {
      "epoch": 1.44,
      "grad_norm": 0.12160292267799377,
      "learning_rate": 5.342465753424658e-05,
      "loss": 0.044,
      "step": 1800
    },
    {
      "epoch": 1.44,
      "eval_loss": 0.01765647903084755,
      "eval_runtime": 21.6471,
      "eval_samples_per_second": 46.196,
      "eval_steps_per_second": 5.774,
      "step": 1800
    },
    {
      "epoch": 1.448,
      "grad_norm": 0.6076325178146362,
      "learning_rate": 5.3150684931506854e-05,
      "loss": 0.0403,
      "step": 1810
    },
    {
      "epoch": 1.456,
      "grad_norm": 0.16574248671531677,
      "learning_rate": 5.287671232876713e-05,
      "loss": 0.0375,
      "step": 1820
    },
    {
      "epoch": 1.464,
      "grad_norm": 1.364334225654602,
      "learning_rate": 5.2602739726027396e-05,
      "loss": 0.0336,
      "step": 1830
    },
    {
      "epoch": 1.472,
      "grad_norm": 1.727734088897705,
      "learning_rate": 5.232876712328767e-05,
      "loss": 0.0264,
      "step": 1840
    },
    {
      "epoch": 1.48,
      "grad_norm": 0.31411075592041016,
      "learning_rate": 5.2054794520547945e-05,
      "loss": 0.0227,
      "step": 1850
    },
    {
      "epoch": 1.48,
      "eval_loss": 0.017872368916869164,
      "eval_runtime": 21.5403,
      "eval_samples_per_second": 46.425,
      "eval_steps_per_second": 5.803,
      "step": 1850
    },
    {
      "epoch": 1.488,
      "grad_norm": 0.02852192334830761,
      "learning_rate": 5.178082191780822e-05,
      "loss": 0.0412,
      "step": 1860
    },
    {
      "epoch": 1.496,
      "grad_norm": 0.9585972428321838,
      "learning_rate": 5.1506849315068494e-05,
      "loss": 0.0249,
      "step": 1870
    },
    {
      "epoch": 1.504,
      "grad_norm": 10.774225234985352,
      "learning_rate": 5.123287671232877e-05,
      "loss": 0.0492,
      "step": 1880
    },
    {
      "epoch": 1.512,
      "grad_norm": 1.144046425819397,
      "learning_rate": 5.095890410958904e-05,
      "loss": 0.0542,
      "step": 1890
    },
    {
      "epoch": 1.52,
      "grad_norm": 0.484526127576828,
      "learning_rate": 5.068493150684932e-05,
      "loss": 0.0279,
      "step": 1900
    },
    {
      "epoch": 1.52,
      "eval_loss": 0.019940471276640892,
      "eval_runtime": 21.6019,
      "eval_samples_per_second": 46.292,
      "eval_steps_per_second": 5.787,
      "step": 1900
    },
    {
      "epoch": 1.528,
      "grad_norm": 2.131960153579712,
      "learning_rate": 5.041095890410959e-05,
      "loss": 0.0521,
      "step": 1910
    },
    {
      "epoch": 1.536,
      "grad_norm": 0.7309334874153137,
      "learning_rate": 5.013698630136987e-05,
      "loss": 0.0239,
      "step": 1920
    },
    {
      "epoch": 1.544,
      "grad_norm": 9.387615203857422,
      "learning_rate": 4.986301369863014e-05,
      "loss": 0.0308,
      "step": 1930
    },
    {
      "epoch": 1.552,
      "grad_norm": 1.070591926574707,
      "learning_rate": 4.958904109589041e-05,
      "loss": 0.0262,
      "step": 1940
    },
    {
      "epoch": 1.56,
      "grad_norm": 0.5958150029182434,
      "learning_rate": 4.9315068493150684e-05,
      "loss": 0.0138,
      "step": 1950
    },
    {
      "epoch": 1.56,
      "eval_loss": 0.020087484270334244,
      "eval_runtime": 21.6101,
      "eval_samples_per_second": 46.275,
      "eval_steps_per_second": 5.784,
      "step": 1950
    },
    {
      "epoch": 1.568,
      "grad_norm": 0.08580941706895828,
      "learning_rate": 4.904109589041096e-05,
      "loss": 0.0494,
      "step": 1960
    },
    {
      "epoch": 1.576,
      "grad_norm": 0.1229938194155693,
      "learning_rate": 4.876712328767123e-05,
      "loss": 0.039,
      "step": 1970
    },
    {
      "epoch": 1.584,
      "grad_norm": 2.463348150253296,
      "learning_rate": 4.849315068493151e-05,
      "loss": 0.0408,
      "step": 1980
    },
    {
      "epoch": 1.592,
      "grad_norm": 0.20099321007728577,
      "learning_rate": 4.821917808219178e-05,
      "loss": 0.0187,
      "step": 1990
    },
    {
      "epoch": 1.6,
      "grad_norm": 0.37662583589553833,
      "learning_rate": 4.794520547945205e-05,
      "loss": 0.0124,
      "step": 2000
    },
    {
      "epoch": 1.6,
      "eval_loss": 0.018549932166934013,
      "eval_runtime": 21.578,
      "eval_samples_per_second": 46.343,
      "eval_steps_per_second": 5.793,
      "step": 2000
    },
    {
      "epoch": 1.608,
      "grad_norm": 0.113151915371418,
      "learning_rate": 4.767123287671233e-05,
      "loss": 0.0112,
      "step": 2010
    },
    {
      "epoch": 1.616,
      "grad_norm": 1.8245922327041626,
      "learning_rate": 4.73972602739726e-05,
      "loss": 0.0433,
      "step": 2020
    },
    {
      "epoch": 1.624,
      "grad_norm": 0.04256374388933182,
      "learning_rate": 4.712328767123288e-05,
      "loss": 0.0302,
      "step": 2030
    },
    {
      "epoch": 1.6320000000000001,
      "grad_norm": 0.06351523846387863,
      "learning_rate": 4.684931506849316e-05,
      "loss": 0.0545,
      "step": 2040
    },
    {
      "epoch": 1.6400000000000001,
      "grad_norm": 0.00795385055243969,
      "learning_rate": 4.657534246575342e-05,
      "loss": 0.0359,
      "step": 2050
    },
    {
      "epoch": 1.6400000000000001,
      "eval_loss": 0.01780213601887226,
      "eval_runtime": 21.4775,
      "eval_samples_per_second": 46.56,
      "eval_steps_per_second": 5.82,
      "step": 2050
    },
    {
      "epoch": 1.6480000000000001,
      "grad_norm": 1.348435640335083,
      "learning_rate": 4.63013698630137e-05,
      "loss": 0.0109,
      "step": 2060
    },
    {
      "epoch": 1.6560000000000001,
      "grad_norm": 1.5883396863937378,
      "learning_rate": 4.602739726027398e-05,
      "loss": 0.0312,
      "step": 2070
    },
    {
      "epoch": 1.6640000000000001,
      "grad_norm": 1.8340164422988892,
      "learning_rate": 4.575342465753425e-05,
      "loss": 0.0137,
      "step": 2080
    },
    {
      "epoch": 1.6720000000000002,
      "grad_norm": 0.028105247765779495,
      "learning_rate": 4.547945205479453e-05,
      "loss": 0.0224,
      "step": 2090
    },
    {
      "epoch": 1.6800000000000002,
      "grad_norm": 1.0270898342132568,
      "learning_rate": 4.520547945205479e-05,
      "loss": 0.0151,
      "step": 2100
    },
    {
      "epoch": 1.6800000000000002,
      "eval_loss": 0.01930857263505459,
      "eval_runtime": 21.639,
      "eval_samples_per_second": 46.213,
      "eval_steps_per_second": 5.777,
      "step": 2100
    },
    {
      "epoch": 1.688,
      "grad_norm": 0.14205320179462433,
      "learning_rate": 4.493150684931507e-05,
      "loss": 0.0774,
      "step": 2110
    },
    {
      "epoch": 1.696,
      "grad_norm": 0.8760988116264343,
      "learning_rate": 4.465753424657535e-05,
      "loss": 0.0292,
      "step": 2120
    },
    {
      "epoch": 1.704,
      "grad_norm": 1.6285521984100342,
      "learning_rate": 4.438356164383562e-05,
      "loss": 0.0549,
      "step": 2130
    },
    {
      "epoch": 1.712,
      "grad_norm": 0.09845197945833206,
      "learning_rate": 4.4109589041095896e-05,
      "loss": 0.0453,
      "step": 2140
    },
    {
      "epoch": 1.72,
      "grad_norm": 0.016761472448706627,
      "learning_rate": 4.383561643835617e-05,
      "loss": 0.089,
      "step": 2150
    },
    {
      "epoch": 1.72,
      "eval_loss": 0.016666296869516373,
      "eval_runtime": 21.4667,
      "eval_samples_per_second": 46.584,
      "eval_steps_per_second": 5.823,
      "step": 2150
    },
    {
      "epoch": 1.728,
      "grad_norm": 0.16122941672801971,
      "learning_rate": 4.356164383561644e-05,
      "loss": 0.0297,
      "step": 2160
    },
    {
      "epoch": 1.736,
      "grad_norm": 0.48228421807289124,
      "learning_rate": 4.3287671232876716e-05,
      "loss": 0.0158,
      "step": 2170
    },
    {
      "epoch": 1.744,
      "grad_norm": 1.5652142763137817,
      "learning_rate": 4.301369863013699e-05,
      "loss": 0.05,
      "step": 2180
    },
    {
      "epoch": 1.752,
      "grad_norm": 0.7071164846420288,
      "learning_rate": 4.2739726027397265e-05,
      "loss": 0.0213,
      "step": 2190
    },
    {
      "epoch": 1.76,
      "grad_norm": 0.04162217676639557,
      "learning_rate": 4.2465753424657536e-05,
      "loss": 0.0205,
      "step": 2200
    },
    {
      "epoch": 1.76,
      "eval_loss": 0.01671369932591915,
      "eval_runtime": 21.6183,
      "eval_samples_per_second": 46.257,
      "eval_steps_per_second": 5.782,
      "step": 2200
    },
    {
      "epoch": 1.768,
      "grad_norm": 1.1301777362823486,
      "learning_rate": 4.219178082191781e-05,
      "loss": 0.0473,
      "step": 2210
    },
    {
      "epoch": 1.776,
      "grad_norm": 0.1644953340291977,
      "learning_rate": 4.1917808219178085e-05,
      "loss": 0.0053,
      "step": 2220
    },
    {
      "epoch": 1.784,
      "grad_norm": 1.2117829322814941,
      "learning_rate": 4.1643835616438356e-05,
      "loss": 0.0103,
      "step": 2230
    },
    {
      "epoch": 1.792,
      "grad_norm": 0.044653721153736115,
      "learning_rate": 4.1369863013698634e-05,
      "loss": 0.0401,
      "step": 2240
    },
    {
      "epoch": 1.8,
      "grad_norm": 0.02847285009920597,
      "learning_rate": 4.1095890410958905e-05,
      "loss": 0.021,
      "step": 2250
    },
    {
      "epoch": 1.8,
      "eval_loss": 0.017156770452857018,
      "eval_runtime": 21.5888,
      "eval_samples_per_second": 46.32,
      "eval_steps_per_second": 5.79,
      "step": 2250
    },
    {
      "epoch": 1.808,
      "grad_norm": 0.39143043756484985,
      "learning_rate": 4.0821917808219176e-05,
      "loss": 0.0079,
      "step": 2260
    },
    {
      "epoch": 1.8159999999999998,
      "grad_norm": 0.15956878662109375,
      "learning_rate": 4.0547945205479454e-05,
      "loss": 0.0117,
      "step": 2270
    },
    {
      "epoch": 1.8239999999999998,
      "grad_norm": 0.017067043110728264,
      "learning_rate": 4.027397260273973e-05,
      "loss": 0.0391,
      "step": 2280
    },
    {
      "epoch": 1.8319999999999999,
      "grad_norm": 0.8656187057495117,
      "learning_rate": 4e-05,
      "loss": 0.0375,
      "step": 2290
    },
    {
      "epoch": 1.8399999999999999,
      "grad_norm": 0.8333684206008911,
      "learning_rate": 3.9726027397260274e-05,
      "loss": 0.01,
      "step": 2300
    },
    {
      "epoch": 1.8399999999999999,
      "eval_loss": 0.016695672646164894,
      "eval_runtime": 21.5688,
      "eval_samples_per_second": 46.363,
      "eval_steps_per_second": 5.795,
      "step": 2300
    },
    {
      "epoch": 1.8479999999999999,
      "grad_norm": 0.275337278842926,
      "learning_rate": 3.9452054794520546e-05,
      "loss": 0.0244,
      "step": 2310
    },
    {
      "epoch": 1.8559999999999999,
      "grad_norm": 0.6846943497657776,
      "learning_rate": 3.9178082191780823e-05,
      "loss": 0.0221,
      "step": 2320
    },
    {
      "epoch": 1.8639999999999999,
      "grad_norm": 0.7355998754501343,
      "learning_rate": 3.89041095890411e-05,
      "loss": 0.0163,
      "step": 2330
    },
    {
      "epoch": 1.8719999999999999,
      "grad_norm": 0.05854734778404236,
      "learning_rate": 3.863013698630137e-05,
      "loss": 0.0374,
      "step": 2340
    },
    {
      "epoch": 1.88,
      "grad_norm": 1.0740398168563843,
      "learning_rate": 3.8356164383561644e-05,
      "loss": 0.0264,
      "step": 2350
    },
    {
      "epoch": 1.88,
      "eval_loss": 0.0166641753166914,
      "eval_runtime": 21.6097,
      "eval_samples_per_second": 46.275,
      "eval_steps_per_second": 5.784,
      "step": 2350
    },
    {
      "epoch": 1.888,
      "grad_norm": 0.2838088572025299,
      "learning_rate": 3.808219178082192e-05,
      "loss": 0.0356,
      "step": 2360
    },
    {
      "epoch": 1.896,
      "grad_norm": 0.5063249468803406,
      "learning_rate": 3.780821917808219e-05,
      "loss": 0.0442,
      "step": 2370
    },
    {
      "epoch": 1.904,
      "grad_norm": 0.14247669279575348,
      "learning_rate": 3.753424657534247e-05,
      "loss": 0.0401,
      "step": 2380
    },
    {
      "epoch": 1.912,
      "grad_norm": 0.1821759045124054,
      "learning_rate": 3.726027397260274e-05,
      "loss": 0.0194,
      "step": 2390
    },
    {
      "epoch": 1.92,
      "grad_norm": 1.1073946952819824,
      "learning_rate": 3.698630136986301e-05,
      "loss": 0.0367,
      "step": 2400
    },
    {
      "epoch": 1.92,
      "eval_loss": 0.018025638535618782,
      "eval_runtime": 21.6132,
      "eval_samples_per_second": 46.268,
      "eval_steps_per_second": 5.784,
      "step": 2400
    },
    {
      "epoch": 1.928,
      "grad_norm": 0.17271065711975098,
      "learning_rate": 3.671232876712329e-05,
      "loss": 0.0167,
      "step": 2410
    },
    {
      "epoch": 1.936,
      "grad_norm": 0.35982683300971985,
      "learning_rate": 3.643835616438356e-05,
      "loss": 0.0195,
      "step": 2420
    },
    {
      "epoch": 1.944,
      "grad_norm": 0.06598541885614395,
      "learning_rate": 3.616438356164384e-05,
      "loss": 0.0206,
      "step": 2430
    },
    {
      "epoch": 1.952,
      "grad_norm": 0.027659526094794273,
      "learning_rate": 3.589041095890411e-05,
      "loss": 0.0411,
      "step": 2440
    },
    {
      "epoch": 1.96,
      "grad_norm": 0.12271900475025177,
      "learning_rate": 3.561643835616438e-05,
      "loss": 0.0179,
      "step": 2450
    },
    {
      "epoch": 1.96,
      "eval_loss": 0.018556781113147736,
      "eval_runtime": 21.5816,
      "eval_samples_per_second": 46.336,
      "eval_steps_per_second": 5.792,
      "step": 2450
    },
    {
      "epoch": 1.968,
      "grad_norm": 0.9947712421417236,
      "learning_rate": 3.534246575342466e-05,
      "loss": 0.0213,
      "step": 2460
    },
    {
      "epoch": 1.976,
      "grad_norm": 1.031062364578247,
      "learning_rate": 3.506849315068493e-05,
      "loss": 0.025,
      "step": 2470
    },
    {
      "epoch": 1.984,
      "grad_norm": 0.7133617997169495,
      "learning_rate": 3.479452054794521e-05,
      "loss": 0.0837,
      "step": 2480
    },
    {
      "epoch": 1.992,
      "grad_norm": 0.8624683618545532,
      "learning_rate": 3.452054794520549e-05,
      "loss": 0.0189,
      "step": 2490
    },
    {
      "epoch": 2.0,
      "grad_norm": 1.6145236492156982,
      "learning_rate": 3.424657534246575e-05,
      "loss": 0.0549,
      "step": 2500
    },
    {
      "epoch": 2.0,
      "eval_loss": 0.016286002472043037,
      "eval_runtime": 21.6323,
      "eval_samples_per_second": 46.227,
      "eval_steps_per_second": 5.778,
      "step": 2500
    },
    {
      "epoch": 2.008,
      "grad_norm": 2.5379087924957275,
      "learning_rate": 3.397260273972603e-05,
      "loss": 0.0184,
      "step": 2510
    },
    {
      "epoch": 2.016,
      "grad_norm": 0.0897538885474205,
      "learning_rate": 3.36986301369863e-05,
      "loss": 0.0154,
      "step": 2520
    },
    {
      "epoch": 2.024,
      "grad_norm": 0.693060576915741,
      "learning_rate": 3.342465753424658e-05,
      "loss": 0.0066,
      "step": 2530
    },
    {
      "epoch": 2.032,
      "grad_norm": 1.5942312479019165,
      "learning_rate": 3.3150684931506856e-05,
      "loss": 0.0339,
      "step": 2540
    },
    {
      "epoch": 2.04,
      "grad_norm": 0.14640407264232635,
      "learning_rate": 3.287671232876712e-05,
      "loss": 0.0211,
      "step": 2550
    },
    {
      "epoch": 2.04,
      "eval_loss": 0.016129858791828156,
      "eval_runtime": 21.549,
      "eval_samples_per_second": 46.406,
      "eval_steps_per_second": 5.801,
      "step": 2550
    },
    {
      "epoch": 2.048,
      "grad_norm": 0.06044871360063553,
      "learning_rate": 3.26027397260274e-05,
      "loss": 0.0463,
      "step": 2560
    },
    {
      "epoch": 2.056,
      "grad_norm": 0.3975900411605835,
      "learning_rate": 3.2328767123287676e-05,
      "loss": 0.0185,
      "step": 2570
    },
    {
      "epoch": 2.064,
      "grad_norm": 0.040480200201272964,
      "learning_rate": 3.205479452054795e-05,
      "loss": 0.0031,
      "step": 2580
    },
    {
      "epoch": 2.072,
      "grad_norm": 0.22091102600097656,
      "learning_rate": 3.1780821917808225e-05,
      "loss": 0.0336,
      "step": 2590
    },
    {
      "epoch": 2.08,
      "grad_norm": 0.902068018913269,
      "learning_rate": 3.1506849315068496e-05,
      "loss": 0.0213,
      "step": 2600
    },
    {
      "epoch": 2.08,
      "eval_loss": 0.017132805660367012,
      "eval_runtime": 21.5842,
      "eval_samples_per_second": 46.33,
      "eval_steps_per_second": 5.791,
      "step": 2600
    },
    {
      "epoch": 2.088,
      "grad_norm": 1.20700204372406,
      "learning_rate": 3.123287671232877e-05,
      "loss": 0.0271,
      "step": 2610
    },
    {
      "epoch": 2.096,
      "grad_norm": 1.62068772315979,
      "learning_rate": 3.0958904109589045e-05,
      "loss": 0.0286,
      "step": 2620
    },
    {
      "epoch": 2.104,
      "grad_norm": 0.02403850480914116,
      "learning_rate": 3.0684931506849316e-05,
      "loss": 0.0209,
      "step": 2630
    },
    {
      "epoch": 2.112,
      "grad_norm": 0.45466169714927673,
      "learning_rate": 3.0410958904109594e-05,
      "loss": 0.0095,
      "step": 2640
    },
    {
      "epoch": 2.12,
      "grad_norm": 0.2556714415550232,
      "learning_rate": 3.0136986301369862e-05,
      "loss": 0.006,
      "step": 2650
    },
    {
      "epoch": 2.12,
      "eval_loss": 0.01762140728533268,
      "eval_runtime": 21.5967,
      "eval_samples_per_second": 46.303,
      "eval_steps_per_second": 5.788,
      "step": 2650
    },
    {
      "epoch": 2.128,
      "grad_norm": 0.0392913743853569,
      "learning_rate": 2.9863013698630136e-05,
      "loss": 0.0283,
      "step": 2660
    },
    {
      "epoch": 2.136,
      "grad_norm": 0.012166492640972137,
      "learning_rate": 2.9589041095890414e-05,
      "loss": 0.0155,
      "step": 2670
    },
    {
      "epoch": 2.144,
      "grad_norm": 1.7590104341506958,
      "learning_rate": 2.931506849315069e-05,
      "loss": 0.028,
      "step": 2680
    },
    {
      "epoch": 2.152,
      "grad_norm": 0.06592776626348495,
      "learning_rate": 2.9041095890410956e-05,
      "loss": 0.0379,
      "step": 2690
    },
    {
      "epoch": 2.16,
      "grad_norm": 0.1680014580488205,
      "learning_rate": 2.8767123287671234e-05,
      "loss": 0.006,
      "step": 2700
    },
    {
      "epoch": 2.16,
      "eval_loss": 0.017370983958244324,
      "eval_runtime": 21.5942,
      "eval_samples_per_second": 46.309,
      "eval_steps_per_second": 5.789,
      "step": 2700
    },
    {
      "epoch": 2.168,
      "grad_norm": 0.1588265597820282,
      "learning_rate": 2.849315068493151e-05,
      "loss": 0.0066,
      "step": 2710
    },
    {
      "epoch": 2.176,
      "grad_norm": 0.07420934736728668,
      "learning_rate": 2.8219178082191783e-05,
      "loss": 0.0357,
      "step": 2720
    },
    {
      "epoch": 2.184,
      "grad_norm": 0.018400631844997406,
      "learning_rate": 2.7945205479452058e-05,
      "loss": 0.0481,
      "step": 2730
    },
    {
      "epoch": 2.192,
      "grad_norm": 0.09550429880619049,
      "learning_rate": 2.767123287671233e-05,
      "loss": 0.0241,
      "step": 2740
    },
    {
      "epoch": 2.2,
      "grad_norm": 0.44285711646080017,
      "learning_rate": 2.7397260273972603e-05,
      "loss": 0.0284,
      "step": 2750
    },
    {
      "epoch": 2.2,
      "eval_loss": 0.017959564924240112,
      "eval_runtime": 21.5563,
      "eval_samples_per_second": 46.39,
      "eval_steps_per_second": 5.799,
      "step": 2750
    },
    {
      "epoch": 2.208,
      "grad_norm": 0.009111467748880386,
      "learning_rate": 2.7123287671232878e-05,
      "loss": 0.0109,
      "step": 2760
    },
    {
      "epoch": 2.216,
      "grad_norm": 0.015667250379920006,
      "learning_rate": 2.6849315068493153e-05,
      "loss": 0.0109,
      "step": 2770
    },
    {
      "epoch": 2.224,
      "grad_norm": 1.2249008417129517,
      "learning_rate": 2.6575342465753427e-05,
      "loss": 0.0202,
      "step": 2780
    },
    {
      "epoch": 2.232,
      "grad_norm": 0.09066685289144516,
      "learning_rate": 2.6301369863013698e-05,
      "loss": 0.0561,
      "step": 2790
    },
    {
      "epoch": 2.24,
      "grad_norm": 2.175679922103882,
      "learning_rate": 2.6027397260273973e-05,
      "loss": 0.0351,
      "step": 2800
    },
    {
      "epoch": 2.24,
      "eval_loss": 0.017898378893733025,
      "eval_runtime": 21.6104,
      "eval_samples_per_second": 46.274,
      "eval_steps_per_second": 5.784,
      "step": 2800
    },
    {
      "epoch": 2.248,
      "grad_norm": 0.04699478670954704,
      "learning_rate": 2.5753424657534247e-05,
      "loss": 0.0273,
      "step": 2810
    },
    {
      "epoch": 2.2560000000000002,
      "grad_norm": 0.17717958986759186,
      "learning_rate": 2.547945205479452e-05,
      "loss": 0.0182,
      "step": 2820
    },
    {
      "epoch": 2.2640000000000002,
      "grad_norm": 0.02334856055676937,
      "learning_rate": 2.5205479452054796e-05,
      "loss": 0.012,
      "step": 2830
    },
    {
      "epoch": 2.2720000000000002,
      "grad_norm": 0.040727850049734116,
      "learning_rate": 2.493150684931507e-05,
      "loss": 0.0265,
      "step": 2840
    },
    {
      "epoch": 2.2800000000000002,
      "grad_norm": 0.06423823535442352,
      "learning_rate": 2.4657534246575342e-05,
      "loss": 0.027,
      "step": 2850
    },
    {
      "epoch": 2.2800000000000002,
      "eval_loss": 0.01770845800638199,
      "eval_runtime": 21.5816,
      "eval_samples_per_second": 46.336,
      "eval_steps_per_second": 5.792,
      "step": 2850
    },
    {
      "epoch": 2.288,
      "grad_norm": 1.1048822402954102,
      "learning_rate": 2.4383561643835616e-05,
      "loss": 0.0322,
      "step": 2860
    },
    {
      "epoch": 2.296,
      "grad_norm": 0.04369717836380005,
      "learning_rate": 2.410958904109589e-05,
      "loss": 0.0078,
      "step": 2870
    },
    {
      "epoch": 2.304,
      "grad_norm": 0.04214087128639221,
      "learning_rate": 2.3835616438356165e-05,
      "loss": 0.0097,
      "step": 2880
    },
    {
      "epoch": 2.312,
      "grad_norm": 6.699228286743164,
      "learning_rate": 2.356164383561644e-05,
      "loss": 0.0435,
      "step": 2890
    },
    {
      "epoch": 2.32,
      "grad_norm": 0.017603237181901932,
      "learning_rate": 2.328767123287671e-05,
      "loss": 0.0023,
      "step": 2900
    },
    {
      "epoch": 2.32,
      "eval_loss": 0.018147999420762062,
      "eval_runtime": 21.6451,
      "eval_samples_per_second": 46.2,
      "eval_steps_per_second": 5.775,
      "step": 2900
    },
    {
      "epoch": 2.328,
      "grad_norm": 0.022148124873638153,
      "learning_rate": 2.301369863013699e-05,
      "loss": 0.0123,
      "step": 2910
    },
    {
      "epoch": 2.336,
      "grad_norm": 0.2552921175956726,
      "learning_rate": 2.2739726027397263e-05,
      "loss": 0.0488,
      "step": 2920
    },
    {
      "epoch": 2.344,
      "grad_norm": 0.1004483625292778,
      "learning_rate": 2.2465753424657534e-05,
      "loss": 0.0238,
      "step": 2930
    },
    {
      "epoch": 2.352,
      "grad_norm": 1.299883246421814,
      "learning_rate": 2.219178082191781e-05,
      "loss": 0.0202,
      "step": 2940
    },
    {
      "epoch": 2.36,
      "grad_norm": 0.7947975993156433,
      "learning_rate": 2.1917808219178083e-05,
      "loss": 0.0306,
      "step": 2950
    },
    {
      "epoch": 2.36,
      "eval_loss": 0.017051219940185547,
      "eval_runtime": 21.6129,
      "eval_samples_per_second": 46.269,
      "eval_steps_per_second": 5.784,
      "step": 2950
    },
    {
      "epoch": 2.368,
      "grad_norm": 0.11950549483299255,
      "learning_rate": 2.1643835616438358e-05,
      "loss": 0.0123,
      "step": 2960
    },
    {
      "epoch": 2.376,
      "grad_norm": 0.026501933112740517,
      "learning_rate": 2.1369863013698632e-05,
      "loss": 0.0055,
      "step": 2970
    },
    {
      "epoch": 2.384,
      "grad_norm": 0.21480108797550201,
      "learning_rate": 2.1095890410958904e-05,
      "loss": 0.0274,
      "step": 2980
    },
    {
      "epoch": 2.392,
      "grad_norm": 0.06747163832187653,
      "learning_rate": 2.0821917808219178e-05,
      "loss": 0.0162,
      "step": 2990
    },
    {
      "epoch": 2.4,
      "grad_norm": 0.8086835145950317,
      "learning_rate": 2.0547945205479453e-05,
      "loss": 0.0444,
      "step": 3000
    },
    {
      "epoch": 2.4,
      "eval_loss": 0.015946364030241966,
      "eval_runtime": 21.6285,
      "eval_samples_per_second": 46.235,
      "eval_steps_per_second": 5.779,
      "step": 3000
    },
    {
      "epoch": 2.408,
      "grad_norm": 0.0301868487149477,
      "learning_rate": 2.0273972602739727e-05,
      "loss": 0.006,
      "step": 3010
    },
    {
      "epoch": 2.416,
      "grad_norm": 0.5196273922920227,
      "learning_rate": 2e-05,
      "loss": 0.0165,
      "step": 3020
    },
    {
      "epoch": 2.424,
      "grad_norm": 1.6136823892593384,
      "learning_rate": 1.9726027397260273e-05,
      "loss": 0.0438,
      "step": 3030
    },
    {
      "epoch": 2.432,
      "grad_norm": 1.634284257888794,
      "learning_rate": 1.945205479452055e-05,
      "loss": 0.0257,
      "step": 3040
    },
    {
      "epoch": 2.44,
      "grad_norm": 0.012388606555759907,
      "learning_rate": 1.9178082191780822e-05,
      "loss": 0.0303,
      "step": 3050
    },
    {
      "epoch": 2.44,
      "eval_loss": 0.016123028472065926,
      "eval_runtime": 16.2173,
      "eval_samples_per_second": 61.662,
      "eval_steps_per_second": 7.708,
      "step": 3050
    },
    {
      "epoch": 2.448,
      "grad_norm": 0.8092033267021179,
      "learning_rate": 1.8904109589041096e-05,
      "loss": 0.0313,
      "step": 3060
    },
    {
      "epoch": 2.456,
      "grad_norm": 1.7790570259094238,
      "learning_rate": 1.863013698630137e-05,
      "loss": 0.0352,
      "step": 3070
    },
    {
      "epoch": 2.464,
      "grad_norm": 1.0157135725021362,
      "learning_rate": 1.8356164383561645e-05,
      "loss": 0.029,
      "step": 3080
    },
    {
      "epoch": 2.472,
      "grad_norm": 0.013394705019891262,
      "learning_rate": 1.808219178082192e-05,
      "loss": 0.0161,
      "step": 3090
    },
    {
      "epoch": 2.48,
      "grad_norm": 0.6953507661819458,
      "learning_rate": 1.780821917808219e-05,
      "loss": 0.0051,
      "step": 3100
    },
    {
      "epoch": 2.48,
      "eval_loss": 0.01604146882891655,
      "eval_runtime": 16.0782,
      "eval_samples_per_second": 62.196,
      "eval_steps_per_second": 7.775,
      "step": 3100
    },
    {
      "epoch": 2.488,
      "grad_norm": 0.2648172974586487,
      "learning_rate": 1.7534246575342465e-05,
      "loss": 0.0255,
      "step": 3110
    },
    {
      "epoch": 2.496,
      "grad_norm": 0.3069462180137634,
      "learning_rate": 1.7260273972602743e-05,
      "loss": 0.0112,
      "step": 3120
    },
    {
      "epoch": 2.504,
      "grad_norm": 0.0391482338309288,
      "learning_rate": 1.6986301369863014e-05,
      "loss": 0.0303,
      "step": 3130
    },
    {
      "epoch": 2.512,
      "grad_norm": 0.97590172290802,
      "learning_rate": 1.671232876712329e-05,
      "loss": 0.0286,
      "step": 3140
    },
    {
      "epoch": 2.52,
      "grad_norm": 0.12278836965560913,
      "learning_rate": 1.643835616438356e-05,
      "loss": 0.0124,
      "step": 3150
    },
    {
      "epoch": 2.52,
      "eval_loss": 0.016274385154247284,
      "eval_runtime": 15.8512,
      "eval_samples_per_second": 63.087,
      "eval_steps_per_second": 7.886,
      "step": 3150
    },
    {
      "epoch": 2.528,
      "grad_norm": 0.01761525869369507,
      "learning_rate": 1.6164383561643838e-05,
      "loss": 0.0071,
      "step": 3160
    },
    {
      "epoch": 2.536,
      "grad_norm": 0.03502941504120827,
      "learning_rate": 1.5890410958904112e-05,
      "loss": 0.0278,
      "step": 3170
    },
    {
      "epoch": 2.544,
      "grad_norm": 0.04192565754055977,
      "learning_rate": 1.5616438356164384e-05,
      "loss": 0.0057,
      "step": 3180
    },
    {
      "epoch": 2.552,
      "grad_norm": 0.2850358784198761,
      "learning_rate": 1.5342465753424658e-05,
      "loss": 0.002,
      "step": 3190
    },
    {
      "epoch": 2.56,
      "grad_norm": 1.3127894401550293,
      "learning_rate": 1.5068493150684931e-05,
      "loss": 0.0247,
      "step": 3200
    },
    {
      "epoch": 2.56,
      "eval_loss": 0.01624993234872818,
      "eval_runtime": 16.0963,
      "eval_samples_per_second": 62.126,
      "eval_steps_per_second": 7.766,
      "step": 3200
    },
    {
      "epoch": 2.568,
      "grad_norm": 0.23805619776248932,
      "learning_rate": 1.4794520547945207e-05,
      "loss": 0.0083,
      "step": 3210
    },
    {
      "epoch": 2.576,
      "grad_norm": 1.4069297313690186,
      "learning_rate": 1.4520547945205478e-05,
      "loss": 0.0111,
      "step": 3220
    },
    {
      "epoch": 2.584,
      "grad_norm": 0.8475540280342102,
      "learning_rate": 1.4246575342465754e-05,
      "loss": 0.0192,
      "step": 3230
    },
    {
      "epoch": 2.592,
      "grad_norm": 0.1411738395690918,
      "learning_rate": 1.3972602739726029e-05,
      "loss": 0.0176,
      "step": 3240
    },
    {
      "epoch": 2.6,
      "grad_norm": 0.04221339151263237,
      "learning_rate": 1.3698630136986302e-05,
      "loss": 0.0083,
      "step": 3250
    },
    {
      "epoch": 2.6,
      "eval_loss": 0.01620551571249962,
      "eval_runtime": 21.3879,
      "eval_samples_per_second": 46.755,
      "eval_steps_per_second": 5.844,
      "step": 3250
    },
    {
      "epoch": 2.608,
      "grad_norm": 0.031100282445549965,
      "learning_rate": 1.3424657534246576e-05,
      "loss": 0.0073,
      "step": 3260
    },
    {
      "epoch": 2.616,
      "grad_norm": 0.3057138919830322,
      "learning_rate": 1.3150684931506849e-05,
      "loss": 0.0151,
      "step": 3270
    },
    {
      "epoch": 2.624,
      "grad_norm": 0.03195703774690628,
      "learning_rate": 1.2876712328767124e-05,
      "loss": 0.0095,
      "step": 3280
    },
    {
      "epoch": 2.632,
      "grad_norm": 0.1628921926021576,
      "learning_rate": 1.2602739726027398e-05,
      "loss": 0.041,
      "step": 3290
    },
    {
      "epoch": 2.64,
      "grad_norm": 5.254112243652344,
      "learning_rate": 1.2328767123287671e-05,
      "loss": 0.0234,
      "step": 3300
    },
    {
      "epoch": 2.64,
      "eval_loss": 0.017009034752845764,
      "eval_runtime": 21.5371,
      "eval_samples_per_second": 46.431,
      "eval_steps_per_second": 5.804,
      "step": 3300
    },
    {
      "epoch": 2.648,
      "grad_norm": 0.046960748732089996,
      "learning_rate": 1.2054794520547945e-05,
      "loss": 0.0151,
      "step": 3310
    },
    {
      "epoch": 2.656,
      "grad_norm": 0.046513691544532776,
      "learning_rate": 1.178082191780822e-05,
      "loss": 0.0086,
      "step": 3320
    },
    {
      "epoch": 2.664,
      "grad_norm": 0.03986421227455139,
      "learning_rate": 1.1506849315068494e-05,
      "loss": 0.0407,
      "step": 3330
    },
    {
      "epoch": 2.672,
      "grad_norm": 0.013513474725186825,
      "learning_rate": 1.1232876712328767e-05,
      "loss": 0.041,
      "step": 3340
    },
    {
      "epoch": 2.68,
      "grad_norm": 0.04248392581939697,
      "learning_rate": 1.0958904109589042e-05,
      "loss": 0.0075,
      "step": 3350
    },
    {
      "epoch": 2.68,
      "eval_loss": 0.01658700592815876,
      "eval_runtime": 21.5077,
      "eval_samples_per_second": 46.495,
      "eval_steps_per_second": 5.812,
      "step": 3350
    },
    {
      "epoch": 2.6879999999999997,
      "grad_norm": 0.6313009262084961,
      "learning_rate": 1.0684931506849316e-05,
      "loss": 0.0155,
      "step": 3360
    },
    {
      "epoch": 2.6959999999999997,
      "grad_norm": 0.37146979570388794,
      "learning_rate": 1.0410958904109589e-05,
      "loss": 0.0428,
      "step": 3370
    },
    {
      "epoch": 2.7039999999999997,
      "grad_norm": 0.5261489748954773,
      "learning_rate": 1.0136986301369864e-05,
      "loss": 0.0152,
      "step": 3380
    },
    {
      "epoch": 2.7119999999999997,
      "grad_norm": 4.794611930847168,
      "learning_rate": 9.863013698630136e-06,
      "loss": 0.0543,
      "step": 3390
    },
    {
      "epoch": 2.7199999999999998,
      "grad_norm": 0.25532346963882446,
      "learning_rate": 9.589041095890411e-06,
      "loss": 0.0048,
      "step": 3400
    },
    {
      "epoch": 2.7199999999999998,
      "eval_loss": 0.0165299940854311,
      "eval_runtime": 21.5362,
      "eval_samples_per_second": 46.434,
      "eval_steps_per_second": 5.804,
      "step": 3400
    },
    {
      "epoch": 2.7279999999999998,
      "grad_norm": 3.186983823776245,
      "learning_rate": 9.315068493150685e-06,
      "loss": 0.0184,
      "step": 3410
    },
    {
      "epoch": 2.7359999999999998,
      "grad_norm": 1.2658730745315552,
      "learning_rate": 9.04109589041096e-06,
      "loss": 0.0214,
      "step": 3420
    },
    {
      "epoch": 2.7439999999999998,
      "grad_norm": 0.03896724432706833,
      "learning_rate": 8.767123287671233e-06,
      "loss": 0.0508,
      "step": 3430
    },
    {
      "epoch": 2.752,
      "grad_norm": 0.46270257234573364,
      "learning_rate": 8.493150684931507e-06,
      "loss": 0.0078,
      "step": 3440
    },
    {
      "epoch": 2.76,
      "grad_norm": 0.10082948207855225,
      "learning_rate": 8.21917808219178e-06,
      "loss": 0.0113,
      "step": 3450
    },
    {
      "epoch": 2.76,
      "eval_loss": 0.016445515677332878,
      "eval_runtime": 21.6343,
      "eval_samples_per_second": 46.223,
      "eval_steps_per_second": 5.778,
      "step": 3450
    },
    {
      "epoch": 2.768,
      "grad_norm": 0.21432894468307495,
      "learning_rate": 7.945205479452056e-06,
      "loss": 0.0235,
      "step": 3460
    },
    {
      "epoch": 2.776,
      "grad_norm": 1.459684133529663,
      "learning_rate": 7.671232876712329e-06,
      "loss": 0.0401,
      "step": 3470
    },
    {
      "epoch": 2.784,
      "grad_norm": 0.029516246169805527,
      "learning_rate": 7.3972602739726036e-06,
      "loss": 0.0389,
      "step": 3480
    },
    {
      "epoch": 2.792,
      "grad_norm": 0.3384513556957245,
      "learning_rate": 7.123287671232877e-06,
      "loss": 0.0141,
      "step": 3490
    },
    {
      "epoch": 2.8,
      "grad_norm": 0.7942516803741455,
      "learning_rate": 6.849315068493151e-06,
      "loss": 0.0068,
      "step": 3500
    },
    {
      "epoch": 2.8,
      "eval_loss": 0.016181372106075287,
      "eval_runtime": 21.6731,
      "eval_samples_per_second": 46.14,
      "eval_steps_per_second": 5.768,
      "step": 3500
    },
    {
      "epoch": 2.808,
      "grad_norm": 1.7965426445007324,
      "learning_rate": 6.5753424657534245e-06,
      "loss": 0.0475,
      "step": 3510
    },
    {
      "epoch": 2.816,
      "grad_norm": 0.026112405583262444,
      "learning_rate": 6.301369863013699e-06,
      "loss": 0.0239,
      "step": 3520
    },
    {
      "epoch": 2.824,
      "grad_norm": 1.9000498056411743,
      "learning_rate": 6.027397260273973e-06,
      "loss": 0.0286,
      "step": 3530
    },
    {
      "epoch": 2.832,
      "grad_norm": 0.1423993706703186,
      "learning_rate": 5.753424657534247e-06,
      "loss": 0.0116,
      "step": 3540
    },
    {
      "epoch": 2.84,
      "grad_norm": 0.6056176424026489,
      "learning_rate": 5.479452054794521e-06,
      "loss": 0.0162,
      "step": 3550
    },
    {
      "epoch": 2.84,
      "eval_loss": 0.015823040157556534,
      "eval_runtime": 21.6084,
      "eval_samples_per_second": 46.278,
      "eval_steps_per_second": 5.785,
      "step": 3550
    },
    {
      "epoch": 2.848,
      "grad_norm": 0.6356903910636902,
      "learning_rate": 5.2054794520547945e-06,
      "loss": 0.0223,
      "step": 3560
    },
    {
      "epoch": 2.856,
      "grad_norm": 0.06313629448413849,
      "learning_rate": 4.931506849315068e-06,
      "loss": 0.0138,
      "step": 3570
    },
    {
      "epoch": 2.864,
      "grad_norm": 1.9319099187850952,
      "learning_rate": 4.657534246575343e-06,
      "loss": 0.0331,
      "step": 3580
    },
    {
      "epoch": 2.872,
      "grad_norm": 0.06421949714422226,
      "learning_rate": 4.383561643835616e-06,
      "loss": 0.0072,
      "step": 3590
    },
    {
      "epoch": 2.88,
      "grad_norm": 0.08084248006343842,
      "learning_rate": 4.10958904109589e-06,
      "loss": 0.0228,
      "step": 3600
    },
    {
      "epoch": 2.88,
      "eval_loss": 0.015809958800673485,
      "eval_runtime": 21.631,
      "eval_samples_per_second": 46.23,
      "eval_steps_per_second": 5.779,
      "step": 3600
    },
    {
      "epoch": 2.888,
      "grad_norm": 0.17187006771564484,
      "learning_rate": 3.8356164383561645e-06,
      "loss": 0.0179,
      "step": 3610
    },
    {
      "epoch": 2.896,
      "grad_norm": 1.8364979028701782,
      "learning_rate": 3.5616438356164386e-06,
      "loss": 0.0388,
      "step": 3620
    },
    {
      "epoch": 2.904,
      "grad_norm": 2.227139472961426,
      "learning_rate": 3.2876712328767123e-06,
      "loss": 0.0353,
      "step": 3630
    },
    {
      "epoch": 2.912,
      "grad_norm": 0.0163631159812212,
      "learning_rate": 3.0136986301369864e-06,
      "loss": 0.0042,
      "step": 3640
    },
    {
      "epoch": 2.92,
      "grad_norm": 2.0166492462158203,
      "learning_rate": 2.7397260273972604e-06,
      "loss": 0.013,
      "step": 3650
    },
    {
      "epoch": 2.92,
      "eval_loss": 0.015813235193490982,
      "eval_runtime": 21.6243,
      "eval_samples_per_second": 46.244,
      "eval_steps_per_second": 5.781,
      "step": 3650
    },
    {
      "epoch": 2.928,
      "grad_norm": 0.038746993988752365,
      "learning_rate": 2.465753424657534e-06,
      "loss": 0.0144,
      "step": 3660
    },
    {
      "epoch": 2.936,
      "grad_norm": 0.5901272892951965,
      "learning_rate": 2.191780821917808e-06,
      "loss": 0.0145,
      "step": 3670
    },
    {
      "epoch": 2.944,
      "grad_norm": 0.06658583134412766,
      "learning_rate": 1.9178082191780823e-06,
      "loss": 0.0215,
      "step": 3680
    },
    {
      "epoch": 2.952,
      "grad_norm": 0.26652806997299194,
      "learning_rate": 1.6438356164383561e-06,
      "loss": 0.02,
      "step": 3690
    },
    {
      "epoch": 2.96,
      "grad_norm": 0.8956859111785889,
      "learning_rate": 1.3698630136986302e-06,
      "loss": 0.03,
      "step": 3700
    },
    {
      "epoch": 2.96,
      "eval_loss": 0.01573299989104271,
      "eval_runtime": 21.6129,
      "eval_samples_per_second": 46.269,
      "eval_steps_per_second": 5.784,
      "step": 3700
    },
    {
      "epoch": 2.968,
      "grad_norm": 0.24221616983413696,
      "learning_rate": 1.095890410958904e-06,
      "loss": 0.0058,
      "step": 3710
    },
    {
      "epoch": 2.976,
      "grad_norm": 0.03611302003264427,
      "learning_rate": 8.219178082191781e-07,
      "loss": 0.0126,
      "step": 3720
    },
    {
      "epoch": 2.984,
      "grad_norm": 0.08014797419309616,
      "learning_rate": 5.47945205479452e-07,
      "loss": 0.0207,
      "step": 3730
    },
    {
      "epoch": 2.992,
      "grad_norm": 0.04169336333870888,
      "learning_rate": 2.73972602739726e-07,
      "loss": 0.0077,
      "step": 3740
    },
    {
      "epoch": 3.0,
      "grad_norm": 5.034517765045166,
      "learning_rate": 0.0,
      "loss": 0.0234,
      "step": 3750
    },
    {
      "epoch": 3.0,
      "eval_loss": 0.015736699104309082,
      "eval_runtime": 21.7263,
      "eval_samples_per_second": 46.027,
      "eval_steps_per_second": 5.753,
      "step": 3750
    }
  ],
  "logging_steps": 10,
  "max_steps": 3750,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 3,
  "save_steps": 100,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 3161891025451008.0,
  "train_batch_size": 8,
  "trial_name": null,
  "trial_params": null
}
