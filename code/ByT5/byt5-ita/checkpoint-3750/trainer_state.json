{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 3.0,
  "eval_steps": 50,
  "global_step": 3750,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.008,
      "grad_norm": 50.262962341308594,
      "learning_rate": 1e-05,
      "loss": 5.6137,
      "step": 10
    },
    {
      "epoch": 0.016,
      "grad_norm": 73.80225372314453,
      "learning_rate": 2e-05,
      "loss": 5.6179,
      "step": 20
    },
    {
      "epoch": 0.024,
      "grad_norm": 264.79388427734375,
      "learning_rate": 3e-05,
      "loss": 5.0729,
      "step": 30
    },
    {
      "epoch": 0.032,
      "grad_norm": 41.87322998046875,
      "learning_rate": 4e-05,
      "loss": 4.2438,
      "step": 40
    },
    {
      "epoch": 0.04,
      "grad_norm": 38.94024658203125,
      "learning_rate": 5e-05,
      "loss": 3.4707,
      "step": 50
    },
    {
      "epoch": 0.04,
      "eval_loss": 2.682150363922119,
      "eval_runtime": 130.6401,
      "eval_samples_per_second": 7.655,
      "eval_steps_per_second": 0.957,
      "step": 50
    },
    {
      "epoch": 0.048,
      "grad_norm": 33.8330078125,
      "learning_rate": 6e-05,
      "loss": 3.0468,
      "step": 60
    },
    {
      "epoch": 0.056,
      "grad_norm": 31.994787216186523,
      "learning_rate": 7e-05,
      "loss": 2.5236,
      "step": 70
    },
    {
      "epoch": 0.064,
      "grad_norm": 12.388368606567383,
      "learning_rate": 8e-05,
      "loss": 1.8398,
      "step": 80
    },
    {
      "epoch": 0.072,
      "grad_norm": 12.454593658447266,
      "learning_rate": 9e-05,
      "loss": 1.5626,
      "step": 90
    },
    {
      "epoch": 0.08,
      "grad_norm": 16.579975128173828,
      "learning_rate": 0.0001,
      "loss": 1.3816,
      "step": 100
    },
    {
      "epoch": 0.08,
      "eval_loss": 0.9048722386360168,
      "eval_runtime": 127.512,
      "eval_samples_per_second": 7.842,
      "eval_steps_per_second": 0.98,
      "step": 100
    },
    {
      "epoch": 0.088,
      "grad_norm": 154.0546417236328,
      "learning_rate": 9.972602739726028e-05,
      "loss": 1.2708,
      "step": 110
    },
    {
      "epoch": 0.096,
      "grad_norm": 30.249683380126953,
      "learning_rate": 9.945205479452056e-05,
      "loss": 1.0261,
      "step": 120
    },
    {
      "epoch": 0.104,
      "grad_norm": 5.319546222686768,
      "learning_rate": 9.917808219178082e-05,
      "loss": 0.8958,
      "step": 130
    },
    {
      "epoch": 0.112,
      "grad_norm": 10.607141494750977,
      "learning_rate": 9.89041095890411e-05,
      "loss": 0.8222,
      "step": 140
    },
    {
      "epoch": 0.12,
      "grad_norm": 4.445873260498047,
      "learning_rate": 9.863013698630137e-05,
      "loss": 0.7302,
      "step": 150
    },
    {
      "epoch": 0.12,
      "eval_loss": 0.5139639377593994,
      "eval_runtime": 151.6933,
      "eval_samples_per_second": 6.592,
      "eval_steps_per_second": 0.824,
      "step": 150
    },
    {
      "epoch": 0.128,
      "grad_norm": 4.998250484466553,
      "learning_rate": 9.835616438356165e-05,
      "loss": 0.7226,
      "step": 160
    },
    {
      "epoch": 0.136,
      "grad_norm": 4.283036231994629,
      "learning_rate": 9.808219178082192e-05,
      "loss": 0.6778,
      "step": 170
    },
    {
      "epoch": 0.144,
      "grad_norm": 8.7313232421875,
      "learning_rate": 9.78082191780822e-05,
      "loss": 0.6491,
      "step": 180
    },
    {
      "epoch": 0.152,
      "grad_norm": 4.572432994842529,
      "learning_rate": 9.753424657534247e-05,
      "loss": 0.6102,
      "step": 190
    },
    {
      "epoch": 0.16,
      "grad_norm": 5.186918258666992,
      "learning_rate": 9.726027397260274e-05,
      "loss": 0.6557,
      "step": 200
    },
    {
      "epoch": 0.16,
      "eval_loss": 0.5006030797958374,
      "eval_runtime": 151.6236,
      "eval_samples_per_second": 6.595,
      "eval_steps_per_second": 0.824,
      "step": 200
    },
    {
      "epoch": 0.168,
      "grad_norm": 15.985669136047363,
      "learning_rate": 9.698630136986302e-05,
      "loss": 0.5794,
      "step": 210
    },
    {
      "epoch": 0.176,
      "grad_norm": 3.8626294136047363,
      "learning_rate": 9.67123287671233e-05,
      "loss": 0.6055,
      "step": 220
    },
    {
      "epoch": 0.184,
      "grad_norm": 3.421365261077881,
      "learning_rate": 9.643835616438356e-05,
      "loss": 0.5387,
      "step": 230
    },
    {
      "epoch": 0.192,
      "grad_norm": 5.8336710929870605,
      "learning_rate": 9.616438356164384e-05,
      "loss": 0.6157,
      "step": 240
    },
    {
      "epoch": 0.2,
      "grad_norm": 6.530664920806885,
      "learning_rate": 9.58904109589041e-05,
      "loss": 0.5679,
      "step": 250
    },
    {
      "epoch": 0.2,
      "eval_loss": 0.4333657920360565,
      "eval_runtime": 151.7916,
      "eval_samples_per_second": 6.588,
      "eval_steps_per_second": 0.823,
      "step": 250
    },
    {
      "epoch": 0.208,
      "grad_norm": 2.966235399246216,
      "learning_rate": 9.561643835616438e-05,
      "loss": 0.5484,
      "step": 260
    },
    {
      "epoch": 0.216,
      "grad_norm": 3.062969923019409,
      "learning_rate": 9.534246575342466e-05,
      "loss": 0.5105,
      "step": 270
    },
    {
      "epoch": 0.224,
      "grad_norm": 5.353931903839111,
      "learning_rate": 9.506849315068494e-05,
      "loss": 0.5574,
      "step": 280
    },
    {
      "epoch": 0.232,
      "grad_norm": 3.8904175758361816,
      "learning_rate": 9.47945205479452e-05,
      "loss": 0.584,
      "step": 290
    },
    {
      "epoch": 0.24,
      "grad_norm": 4.135995388031006,
      "learning_rate": 9.452054794520548e-05,
      "loss": 0.5115,
      "step": 300
    },
    {
      "epoch": 0.24,
      "eval_loss": 0.4334321618080139,
      "eval_runtime": 151.6797,
      "eval_samples_per_second": 6.593,
      "eval_steps_per_second": 0.824,
      "step": 300
    },
    {
      "epoch": 0.248,
      "grad_norm": 3.1780176162719727,
      "learning_rate": 9.424657534246576e-05,
      "loss": 0.5396,
      "step": 310
    },
    {
      "epoch": 0.256,
      "grad_norm": 6.1653971672058105,
      "learning_rate": 9.397260273972604e-05,
      "loss": 0.5783,
      "step": 320
    },
    {
      "epoch": 0.264,
      "grad_norm": 2.7828330993652344,
      "learning_rate": 9.369863013698632e-05,
      "loss": 0.5243,
      "step": 330
    },
    {
      "epoch": 0.272,
      "grad_norm": 3.1570630073547363,
      "learning_rate": 9.342465753424658e-05,
      "loss": 0.4866,
      "step": 340
    },
    {
      "epoch": 0.28,
      "grad_norm": 2.40368914604187,
      "learning_rate": 9.315068493150684e-05,
      "loss": 0.4323,
      "step": 350
    },
    {
      "epoch": 0.28,
      "eval_loss": 0.37948960065841675,
      "eval_runtime": 151.583,
      "eval_samples_per_second": 6.597,
      "eval_steps_per_second": 0.825,
      "step": 350
    },
    {
      "epoch": 0.288,
      "grad_norm": 2.0516746044158936,
      "learning_rate": 9.287671232876712e-05,
      "loss": 0.4933,
      "step": 360
    },
    {
      "epoch": 0.296,
      "grad_norm": 2.154013156890869,
      "learning_rate": 9.26027397260274e-05,
      "loss": 0.4868,
      "step": 370
    },
    {
      "epoch": 0.304,
      "grad_norm": 2.391810417175293,
      "learning_rate": 9.232876712328768e-05,
      "loss": 0.479,
      "step": 380
    },
    {
      "epoch": 0.312,
      "grad_norm": 1.6931431293487549,
      "learning_rate": 9.205479452054796e-05,
      "loss": 0.4188,
      "step": 390
    },
    {
      "epoch": 0.32,
      "grad_norm": 2.6925251483917236,
      "learning_rate": 9.178082191780822e-05,
      "loss": 0.4398,
      "step": 400
    },
    {
      "epoch": 0.32,
      "eval_loss": 0.3184119164943695,
      "eval_runtime": 151.54,
      "eval_samples_per_second": 6.599,
      "eval_steps_per_second": 0.825,
      "step": 400
    },
    {
      "epoch": 0.328,
      "grad_norm": 4.285583972930908,
      "learning_rate": 9.15068493150685e-05,
      "loss": 0.4492,
      "step": 410
    },
    {
      "epoch": 0.336,
      "grad_norm": 3.7702717781066895,
      "learning_rate": 9.123287671232878e-05,
      "loss": 0.4341,
      "step": 420
    },
    {
      "epoch": 0.344,
      "grad_norm": 2.3006463050842285,
      "learning_rate": 9.095890410958905e-05,
      "loss": 0.4592,
      "step": 430
    },
    {
      "epoch": 0.352,
      "grad_norm": 3.9486610889434814,
      "learning_rate": 9.068493150684932e-05,
      "loss": 0.4046,
      "step": 440
    },
    {
      "epoch": 0.36,
      "grad_norm": 15.280439376831055,
      "learning_rate": 9.041095890410958e-05,
      "loss": 0.4251,
      "step": 450
    },
    {
      "epoch": 0.36,
      "eval_loss": 0.2982513904571533,
      "eval_runtime": 151.7083,
      "eval_samples_per_second": 6.592,
      "eval_steps_per_second": 0.824,
      "step": 450
    },
    {
      "epoch": 0.368,
      "grad_norm": 2.403181314468384,
      "learning_rate": 9.013698630136986e-05,
      "loss": 0.4078,
      "step": 460
    },
    {
      "epoch": 0.376,
      "grad_norm": 2.7743515968322754,
      "learning_rate": 8.986301369863014e-05,
      "loss": 0.4115,
      "step": 470
    },
    {
      "epoch": 0.384,
      "grad_norm": 2.598440408706665,
      "learning_rate": 8.958904109589042e-05,
      "loss": 0.4016,
      "step": 480
    },
    {
      "epoch": 0.392,
      "grad_norm": 2.0680630207061768,
      "learning_rate": 8.93150684931507e-05,
      "loss": 0.3815,
      "step": 490
    },
    {
      "epoch": 0.4,
      "grad_norm": 2.2999041080474854,
      "learning_rate": 8.904109589041096e-05,
      "loss": 0.3911,
      "step": 500
    },
    {
      "epoch": 0.4,
      "eval_loss": 0.23285485804080963,
      "eval_runtime": 151.6417,
      "eval_samples_per_second": 6.594,
      "eval_steps_per_second": 0.824,
      "step": 500
    },
    {
      "epoch": 0.408,
      "grad_norm": 3.8857154846191406,
      "learning_rate": 8.876712328767124e-05,
      "loss": 0.3536,
      "step": 510
    },
    {
      "epoch": 0.416,
      "grad_norm": 1.9795875549316406,
      "learning_rate": 8.849315068493151e-05,
      "loss": 0.3772,
      "step": 520
    },
    {
      "epoch": 0.424,
      "grad_norm": 2.6880805492401123,
      "learning_rate": 8.821917808219179e-05,
      "loss": 0.3227,
      "step": 530
    },
    {
      "epoch": 0.432,
      "grad_norm": 6.192370891571045,
      "learning_rate": 8.794520547945207e-05,
      "loss": 0.3719,
      "step": 540
    },
    {
      "epoch": 0.44,
      "grad_norm": 2.977296829223633,
      "learning_rate": 8.767123287671233e-05,
      "loss": 0.362,
      "step": 550
    },
    {
      "epoch": 0.44,
      "eval_loss": 0.21791379153728485,
      "eval_runtime": 151.737,
      "eval_samples_per_second": 6.59,
      "eval_steps_per_second": 0.824,
      "step": 550
    },
    {
      "epoch": 0.448,
      "grad_norm": 2.378291606903076,
      "learning_rate": 8.73972602739726e-05,
      "loss": 0.3084,
      "step": 560
    },
    {
      "epoch": 0.456,
      "grad_norm": 13.53662395477295,
      "learning_rate": 8.712328767123288e-05,
      "loss": 0.3673,
      "step": 570
    },
    {
      "epoch": 0.464,
      "grad_norm": 1.941288948059082,
      "learning_rate": 8.684931506849315e-05,
      "loss": 0.3429,
      "step": 580
    },
    {
      "epoch": 0.472,
      "grad_norm": 2.119323253631592,
      "learning_rate": 8.657534246575343e-05,
      "loss": 0.3141,
      "step": 590
    },
    {
      "epoch": 0.48,
      "grad_norm": 1.9861555099487305,
      "learning_rate": 8.630136986301371e-05,
      "loss": 0.3005,
      "step": 600
    },
    {
      "epoch": 0.48,
      "eval_loss": 0.15872442722320557,
      "eval_runtime": 151.7192,
      "eval_samples_per_second": 6.591,
      "eval_steps_per_second": 0.824,
      "step": 600
    },
    {
      "epoch": 0.488,
      "grad_norm": 2.1907544136047363,
      "learning_rate": 8.602739726027397e-05,
      "loss": 0.3028,
      "step": 610
    },
    {
      "epoch": 0.496,
      "grad_norm": 1.9620286226272583,
      "learning_rate": 8.575342465753425e-05,
      "loss": 0.2527,
      "step": 620
    },
    {
      "epoch": 0.504,
      "grad_norm": 3.5397422313690186,
      "learning_rate": 8.547945205479453e-05,
      "loss": 0.2918,
      "step": 630
    },
    {
      "epoch": 0.512,
      "grad_norm": 5.517844200134277,
      "learning_rate": 8.520547945205481e-05,
      "loss": 0.2456,
      "step": 640
    },
    {
      "epoch": 0.52,
      "grad_norm": 2.1986477375030518,
      "learning_rate": 8.493150684931507e-05,
      "loss": 0.229,
      "step": 650
    },
    {
      "epoch": 0.52,
      "eval_loss": 0.165738046169281,
      "eval_runtime": 151.6198,
      "eval_samples_per_second": 6.595,
      "eval_steps_per_second": 0.824,
      "step": 650
    },
    {
      "epoch": 0.528,
      "grad_norm": 2.2712490558624268,
      "learning_rate": 8.465753424657534e-05,
      "loss": 0.2499,
      "step": 660
    },
    {
      "epoch": 0.536,
      "grad_norm": 2.7882561683654785,
      "learning_rate": 8.438356164383561e-05,
      "loss": 0.3205,
      "step": 670
    },
    {
      "epoch": 0.544,
      "grad_norm": 4.1839470863342285,
      "learning_rate": 8.410958904109589e-05,
      "loss": 0.241,
      "step": 680
    },
    {
      "epoch": 0.552,
      "grad_norm": 2.9384093284606934,
      "learning_rate": 8.383561643835617e-05,
      "loss": 0.2229,
      "step": 690
    },
    {
      "epoch": 0.56,
      "grad_norm": 2.08603572845459,
      "learning_rate": 8.356164383561645e-05,
      "loss": 0.2888,
      "step": 700
    },
    {
      "epoch": 0.56,
      "eval_loss": 0.12620824575424194,
      "eval_runtime": 151.6001,
      "eval_samples_per_second": 6.596,
      "eval_steps_per_second": 0.825,
      "step": 700
    },
    {
      "epoch": 0.568,
      "grad_norm": 2.6006455421447754,
      "learning_rate": 8.328767123287671e-05,
      "loss": 0.2961,
      "step": 710
    },
    {
      "epoch": 0.576,
      "grad_norm": 2.8328335285186768,
      "learning_rate": 8.301369863013699e-05,
      "loss": 0.2278,
      "step": 720
    },
    {
      "epoch": 0.584,
      "grad_norm": 5.273918151855469,
      "learning_rate": 8.273972602739727e-05,
      "loss": 0.2469,
      "step": 730
    },
    {
      "epoch": 0.592,
      "grad_norm": 2.0236403942108154,
      "learning_rate": 8.246575342465755e-05,
      "loss": 0.2015,
      "step": 740
    },
    {
      "epoch": 0.6,
      "grad_norm": 1.963011384010315,
      "learning_rate": 8.219178082191781e-05,
      "loss": 0.2279,
      "step": 750
    },
    {
      "epoch": 0.6,
      "eval_loss": 0.10668652504682541,
      "eval_runtime": 151.6351,
      "eval_samples_per_second": 6.595,
      "eval_steps_per_second": 0.824,
      "step": 750
    },
    {
      "epoch": 0.608,
      "grad_norm": 2.6131370067596436,
      "learning_rate": 8.191780821917809e-05,
      "loss": 0.2324,
      "step": 760
    },
    {
      "epoch": 0.616,
      "grad_norm": 3.701441526412964,
      "learning_rate": 8.164383561643835e-05,
      "loss": 0.2228,
      "step": 770
    },
    {
      "epoch": 0.624,
      "grad_norm": 1.5480382442474365,
      "learning_rate": 8.136986301369863e-05,
      "loss": 0.2164,
      "step": 780
    },
    {
      "epoch": 0.632,
      "grad_norm": 1.9619578123092651,
      "learning_rate": 8.109589041095891e-05,
      "loss": 0.1866,
      "step": 790
    },
    {
      "epoch": 0.64,
      "grad_norm": 1.5508689880371094,
      "learning_rate": 8.082191780821919e-05,
      "loss": 0.2113,
      "step": 800
    },
    {
      "epoch": 0.64,
      "eval_loss": 0.09260682016611099,
      "eval_runtime": 151.7354,
      "eval_samples_per_second": 6.59,
      "eval_steps_per_second": 0.824,
      "step": 800
    },
    {
      "epoch": 0.648,
      "grad_norm": 2.0232295989990234,
      "learning_rate": 8.054794520547946e-05,
      "loss": 0.1836,
      "step": 810
    },
    {
      "epoch": 0.656,
      "grad_norm": 3.822300672531128,
      "learning_rate": 8.027397260273973e-05,
      "loss": 0.2425,
      "step": 820
    },
    {
      "epoch": 0.664,
      "grad_norm": 4.289901256561279,
      "learning_rate": 8e-05,
      "loss": 0.2631,
      "step": 830
    },
    {
      "epoch": 0.672,
      "grad_norm": 1.4851993322372437,
      "learning_rate": 7.972602739726027e-05,
      "loss": 0.2092,
      "step": 840
    },
    {
      "epoch": 0.68,
      "grad_norm": 2.0195164680480957,
      "learning_rate": 7.945205479452055e-05,
      "loss": 0.1896,
      "step": 850
    },
    {
      "epoch": 0.68,
      "eval_loss": 0.09248583763837814,
      "eval_runtime": 151.5535,
      "eval_samples_per_second": 6.598,
      "eval_steps_per_second": 0.825,
      "step": 850
    },
    {
      "epoch": 0.688,
      "grad_norm": 1.5955982208251953,
      "learning_rate": 7.917808219178083e-05,
      "loss": 0.166,
      "step": 860
    },
    {
      "epoch": 0.696,
      "grad_norm": 1.706937551498413,
      "learning_rate": 7.890410958904109e-05,
      "loss": 0.1511,
      "step": 870
    },
    {
      "epoch": 0.704,
      "grad_norm": 1.6571742296218872,
      "learning_rate": 7.863013698630137e-05,
      "loss": 0.1792,
      "step": 880
    },
    {
      "epoch": 0.712,
      "grad_norm": 1.091920256614685,
      "learning_rate": 7.835616438356165e-05,
      "loss": 0.1559,
      "step": 890
    },
    {
      "epoch": 0.72,
      "grad_norm": 2.1388490200042725,
      "learning_rate": 7.808219178082192e-05,
      "loss": 0.1792,
      "step": 900
    },
    {
      "epoch": 0.72,
      "eval_loss": 0.0827462300658226,
      "eval_runtime": 151.6202,
      "eval_samples_per_second": 6.595,
      "eval_steps_per_second": 0.824,
      "step": 900
    },
    {
      "epoch": 0.728,
      "grad_norm": 2.444279193878174,
      "learning_rate": 7.78082191780822e-05,
      "loss": 0.148,
      "step": 910
    },
    {
      "epoch": 0.736,
      "grad_norm": 2.4813051223754883,
      "learning_rate": 7.753424657534247e-05,
      "loss": 0.1289,
      "step": 920
    },
    {
      "epoch": 0.744,
      "grad_norm": 1.4665697813034058,
      "learning_rate": 7.726027397260274e-05,
      "loss": 0.1461,
      "step": 930
    },
    {
      "epoch": 0.752,
      "grad_norm": 1.2613390684127808,
      "learning_rate": 7.698630136986301e-05,
      "loss": 0.2159,
      "step": 940
    },
    {
      "epoch": 0.76,
      "grad_norm": 1.175706386566162,
      "learning_rate": 7.671232876712329e-05,
      "loss": 0.1069,
      "step": 950
    },
    {
      "epoch": 0.76,
      "eval_loss": 0.07026417553424835,
      "eval_runtime": 151.6096,
      "eval_samples_per_second": 6.596,
      "eval_steps_per_second": 0.824,
      "step": 950
    },
    {
      "epoch": 0.768,
      "grad_norm": 3.6355140209198,
      "learning_rate": 7.643835616438356e-05,
      "loss": 0.1888,
      "step": 960
    },
    {
      "epoch": 0.776,
      "grad_norm": 2.9034554958343506,
      "learning_rate": 7.616438356164384e-05,
      "loss": 0.1297,
      "step": 970
    },
    {
      "epoch": 0.784,
      "grad_norm": 3.264570951461792,
      "learning_rate": 7.589041095890411e-05,
      "loss": 0.153,
      "step": 980
    },
    {
      "epoch": 0.792,
      "grad_norm": 3.355626106262207,
      "learning_rate": 7.561643835616439e-05,
      "loss": 0.1314,
      "step": 990
    },
    {
      "epoch": 0.8,
      "grad_norm": 1.5753358602523804,
      "learning_rate": 7.534246575342466e-05,
      "loss": 0.1564,
      "step": 1000
    },
    {
      "epoch": 0.8,
      "eval_loss": 0.06852728128433228,
      "eval_runtime": 151.5861,
      "eval_samples_per_second": 6.597,
      "eval_steps_per_second": 0.825,
      "step": 1000
    },
    {
      "epoch": 0.808,
      "grad_norm": 2.9317216873168945,
      "learning_rate": 7.506849315068494e-05,
      "loss": 0.1296,
      "step": 1010
    },
    {
      "epoch": 0.816,
      "grad_norm": 1.114302396774292,
      "learning_rate": 7.479452054794522e-05,
      "loss": 0.1453,
      "step": 1020
    },
    {
      "epoch": 0.824,
      "grad_norm": 2.8325111865997314,
      "learning_rate": 7.452054794520548e-05,
      "loss": 0.1515,
      "step": 1030
    },
    {
      "epoch": 0.832,
      "grad_norm": 0.9740990400314331,
      "learning_rate": 7.424657534246575e-05,
      "loss": 0.1214,
      "step": 1040
    },
    {
      "epoch": 0.84,
      "grad_norm": 1.7876876592636108,
      "learning_rate": 7.397260273972603e-05,
      "loss": 0.1882,
      "step": 1050
    },
    {
      "epoch": 0.84,
      "eval_loss": 0.059913672506809235,
      "eval_runtime": 151.6546,
      "eval_samples_per_second": 6.594,
      "eval_steps_per_second": 0.824,
      "step": 1050
    },
    {
      "epoch": 0.848,
      "grad_norm": 2.2477574348449707,
      "learning_rate": 7.36986301369863e-05,
      "loss": 0.1651,
      "step": 1060
    },
    {
      "epoch": 0.856,
      "grad_norm": 1.6520367860794067,
      "learning_rate": 7.342465753424658e-05,
      "loss": 0.1557,
      "step": 1070
    },
    {
      "epoch": 0.864,
      "grad_norm": 1.701543927192688,
      "learning_rate": 7.315068493150685e-05,
      "loss": 0.1175,
      "step": 1080
    },
    {
      "epoch": 0.872,
      "grad_norm": 2.0352771282196045,
      "learning_rate": 7.287671232876712e-05,
      "loss": 0.1463,
      "step": 1090
    },
    {
      "epoch": 0.88,
      "grad_norm": 2.6796300411224365,
      "learning_rate": 7.26027397260274e-05,
      "loss": 0.1097,
      "step": 1100
    },
    {
      "epoch": 0.88,
      "eval_loss": 0.060306381434202194,
      "eval_runtime": 151.6755,
      "eval_samples_per_second": 6.593,
      "eval_steps_per_second": 0.824,
      "step": 1100
    },
    {
      "epoch": 0.888,
      "grad_norm": 0.9427775740623474,
      "learning_rate": 7.232876712328768e-05,
      "loss": 0.1637,
      "step": 1110
    },
    {
      "epoch": 0.896,
      "grad_norm": 2.4238791465759277,
      "learning_rate": 7.205479452054796e-05,
      "loss": 0.1343,
      "step": 1120
    },
    {
      "epoch": 0.904,
      "grad_norm": 2.207228183746338,
      "learning_rate": 7.178082191780822e-05,
      "loss": 0.1436,
      "step": 1130
    },
    {
      "epoch": 0.912,
      "grad_norm": 1.9916924238204956,
      "learning_rate": 7.150684931506849e-05,
      "loss": 0.1206,
      "step": 1140
    },
    {
      "epoch": 0.92,
      "grad_norm": 2.7150442600250244,
      "learning_rate": 7.123287671232876e-05,
      "loss": 0.0871,
      "step": 1150
    },
    {
      "epoch": 0.92,
      "eval_loss": 0.06367865204811096,
      "eval_runtime": 151.8001,
      "eval_samples_per_second": 6.588,
      "eval_steps_per_second": 0.823,
      "step": 1150
    },
    {
      "epoch": 0.928,
      "grad_norm": 3.213660478591919,
      "learning_rate": 7.095890410958904e-05,
      "loss": 0.1166,
      "step": 1160
    },
    {
      "epoch": 0.936,
      "grad_norm": 1.816508412361145,
      "learning_rate": 7.068493150684932e-05,
      "loss": 0.1335,
      "step": 1170
    },
    {
      "epoch": 0.944,
      "grad_norm": 0.6028205156326294,
      "learning_rate": 7.04109589041096e-05,
      "loss": 0.1165,
      "step": 1180
    },
    {
      "epoch": 0.952,
      "grad_norm": 8.441987991333008,
      "learning_rate": 7.013698630136986e-05,
      "loss": 0.1474,
      "step": 1190
    },
    {
      "epoch": 0.96,
      "grad_norm": 0.9962316751480103,
      "learning_rate": 6.986301369863014e-05,
      "loss": 0.1413,
      "step": 1200
    },
    {
      "epoch": 0.96,
      "eval_loss": 0.05018254742026329,
      "eval_runtime": 151.6497,
      "eval_samples_per_second": 6.594,
      "eval_steps_per_second": 0.824,
      "step": 1200
    },
    {
      "epoch": 0.968,
      "grad_norm": 1.3092750310897827,
      "learning_rate": 6.958904109589042e-05,
      "loss": 0.1618,
      "step": 1210
    },
    {
      "epoch": 0.976,
      "grad_norm": 1.5713260173797607,
      "learning_rate": 6.93150684931507e-05,
      "loss": 0.0975,
      "step": 1220
    },
    {
      "epoch": 0.984,
      "grad_norm": 1.4062037467956543,
      "learning_rate": 6.904109589041097e-05,
      "loss": 0.1456,
      "step": 1230
    },
    {
      "epoch": 0.992,
      "grad_norm": 4.634402751922607,
      "learning_rate": 6.876712328767124e-05,
      "loss": 0.1263,
      "step": 1240
    },
    {
      "epoch": 1.0,
      "grad_norm": 2.1496994495391846,
      "learning_rate": 6.84931506849315e-05,
      "loss": 0.1377,
      "step": 1250
    },
    {
      "epoch": 1.0,
      "eval_loss": 0.05203860253095627,
      "eval_runtime": 151.5978,
      "eval_samples_per_second": 6.596,
      "eval_steps_per_second": 0.825,
      "step": 1250
    },
    {
      "epoch": 1.008,
      "grad_norm": 4.827048301696777,
      "learning_rate": 6.821917808219178e-05,
      "loss": 0.145,
      "step": 1260
    },
    {
      "epoch": 1.016,
      "grad_norm": 1.7151087522506714,
      "learning_rate": 6.794520547945206e-05,
      "loss": 0.1207,
      "step": 1270
    },
    {
      "epoch": 1.024,
      "grad_norm": 0.6808808445930481,
      "learning_rate": 6.767123287671234e-05,
      "loss": 0.0882,
      "step": 1280
    },
    {
      "epoch": 1.032,
      "grad_norm": 5.709651470184326,
      "learning_rate": 6.73972602739726e-05,
      "loss": 0.1004,
      "step": 1290
    },
    {
      "epoch": 1.04,
      "grad_norm": 0.9536964893341064,
      "learning_rate": 6.712328767123288e-05,
      "loss": 0.0904,
      "step": 1300
    },
    {
      "epoch": 1.04,
      "eval_loss": 0.051198478788137436,
      "eval_runtime": 151.6707,
      "eval_samples_per_second": 6.593,
      "eval_steps_per_second": 0.824,
      "step": 1300
    },
    {
      "epoch": 1.048,
      "grad_norm": 0.3635076582431793,
      "learning_rate": 6.684931506849316e-05,
      "loss": 0.1345,
      "step": 1310
    },
    {
      "epoch": 1.056,
      "grad_norm": 1.6633960008621216,
      "learning_rate": 6.657534246575343e-05,
      "loss": 0.147,
      "step": 1320
    },
    {
      "epoch": 1.064,
      "grad_norm": 1.036655068397522,
      "learning_rate": 6.630136986301371e-05,
      "loss": 0.1474,
      "step": 1330
    },
    {
      "epoch": 1.072,
      "grad_norm": 1.1241484880447388,
      "learning_rate": 6.602739726027398e-05,
      "loss": 0.093,
      "step": 1340
    },
    {
      "epoch": 1.08,
      "grad_norm": 1.5413795709609985,
      "learning_rate": 6.575342465753424e-05,
      "loss": 0.0814,
      "step": 1350
    },
    {
      "epoch": 1.08,
      "eval_loss": 0.04590927064418793,
      "eval_runtime": 151.5856,
      "eval_samples_per_second": 6.597,
      "eval_steps_per_second": 0.825,
      "step": 1350
    },
    {
      "epoch": 1.088,
      "grad_norm": 1.9375735521316528,
      "learning_rate": 6.547945205479452e-05,
      "loss": 0.1219,
      "step": 1360
    },
    {
      "epoch": 1.096,
      "grad_norm": 2.097515106201172,
      "learning_rate": 6.52054794520548e-05,
      "loss": 0.1193,
      "step": 1370
    },
    {
      "epoch": 1.104,
      "grad_norm": 1.6726874113082886,
      "learning_rate": 6.493150684931507e-05,
      "loss": 0.1282,
      "step": 1380
    },
    {
      "epoch": 1.112,
      "grad_norm": 1.6539485454559326,
      "learning_rate": 6.465753424657535e-05,
      "loss": 0.0912,
      "step": 1390
    },
    {
      "epoch": 1.12,
      "grad_norm": 5.623409748077393,
      "learning_rate": 6.438356164383562e-05,
      "loss": 0.1116,
      "step": 1400
    },
    {
      "epoch": 1.12,
      "eval_loss": 0.04714266583323479,
      "eval_runtime": 152.2874,
      "eval_samples_per_second": 6.567,
      "eval_steps_per_second": 0.821,
      "step": 1400
    },
    {
      "epoch": 1.1280000000000001,
      "grad_norm": 1.351474642753601,
      "learning_rate": 6.41095890410959e-05,
      "loss": 0.1082,
      "step": 1410
    },
    {
      "epoch": 1.1360000000000001,
      "grad_norm": 2.4194400310516357,
      "learning_rate": 6.383561643835617e-05,
      "loss": 0.0826,
      "step": 1420
    },
    {
      "epoch": 1.144,
      "grad_norm": 2.0695674419403076,
      "learning_rate": 6.356164383561645e-05,
      "loss": 0.1256,
      "step": 1430
    },
    {
      "epoch": 1.152,
      "grad_norm": 0.9871396422386169,
      "learning_rate": 6.328767123287671e-05,
      "loss": 0.123,
      "step": 1440
    },
    {
      "epoch": 1.16,
      "grad_norm": 1.5794395208358765,
      "learning_rate": 6.301369863013699e-05,
      "loss": 0.1496,
      "step": 1450
    },
    {
      "epoch": 1.16,
      "eval_loss": 0.03741839900612831,
      "eval_runtime": 151.6121,
      "eval_samples_per_second": 6.596,
      "eval_steps_per_second": 0.824,
      "step": 1450
    },
    {
      "epoch": 1.168,
      "grad_norm": 2.36849308013916,
      "learning_rate": 6.273972602739726e-05,
      "loss": 0.0827,
      "step": 1460
    },
    {
      "epoch": 1.176,
      "grad_norm": 0.9664414525032043,
      "learning_rate": 6.246575342465753e-05,
      "loss": 0.1033,
      "step": 1470
    },
    {
      "epoch": 1.184,
      "grad_norm": 1.1585967540740967,
      "learning_rate": 6.219178082191781e-05,
      "loss": 0.1072,
      "step": 1480
    },
    {
      "epoch": 1.192,
      "grad_norm": 1.3281774520874023,
      "learning_rate": 6.191780821917809e-05,
      "loss": 0.1513,
      "step": 1490
    },
    {
      "epoch": 1.2,
      "grad_norm": 2.2170026302337646,
      "learning_rate": 6.164383561643835e-05,
      "loss": 0.1326,
      "step": 1500
    },
    {
      "epoch": 1.2,
      "eval_loss": 0.038300931453704834,
      "eval_runtime": 151.6171,
      "eval_samples_per_second": 6.596,
      "eval_steps_per_second": 0.824,
      "step": 1500
    },
    {
      "epoch": 1.208,
      "grad_norm": 1.2548744678497314,
      "learning_rate": 6.136986301369863e-05,
      "loss": 0.0875,
      "step": 1510
    },
    {
      "epoch": 1.216,
      "grad_norm": 1.8370425701141357,
      "learning_rate": 6.109589041095891e-05,
      "loss": 0.0715,
      "step": 1520
    },
    {
      "epoch": 1.224,
      "grad_norm": 1.218570351600647,
      "learning_rate": 6.082191780821919e-05,
      "loss": 0.0946,
      "step": 1530
    },
    {
      "epoch": 1.232,
      "grad_norm": 2.1029820442199707,
      "learning_rate": 6.054794520547945e-05,
      "loss": 0.0902,
      "step": 1540
    },
    {
      "epoch": 1.24,
      "grad_norm": 0.4342300593852997,
      "learning_rate": 6.0273972602739724e-05,
      "loss": 0.082,
      "step": 1550
    },
    {
      "epoch": 1.24,
      "eval_loss": 0.04225090146064758,
      "eval_runtime": 151.6637,
      "eval_samples_per_second": 6.594,
      "eval_steps_per_second": 0.824,
      "step": 1550
    },
    {
      "epoch": 1.248,
      "grad_norm": 1.5699102878570557,
      "learning_rate": 6e-05,
      "loss": 0.066,
      "step": 1560
    },
    {
      "epoch": 1.256,
      "grad_norm": 1.4326878786087036,
      "learning_rate": 5.972602739726027e-05,
      "loss": 0.0611,
      "step": 1570
    },
    {
      "epoch": 1.264,
      "grad_norm": 0.914630115032196,
      "learning_rate": 5.945205479452055e-05,
      "loss": 0.0795,
      "step": 1580
    },
    {
      "epoch": 1.272,
      "grad_norm": 1.888694167137146,
      "learning_rate": 5.917808219178083e-05,
      "loss": 0.107,
      "step": 1590
    },
    {
      "epoch": 1.28,
      "grad_norm": 1.0453410148620605,
      "learning_rate": 5.89041095890411e-05,
      "loss": 0.0726,
      "step": 1600
    },
    {
      "epoch": 1.28,
      "eval_loss": 0.04022067040205002,
      "eval_runtime": 151.5932,
      "eval_samples_per_second": 6.597,
      "eval_steps_per_second": 0.825,
      "step": 1600
    },
    {
      "epoch": 1.288,
      "grad_norm": 1.3053284883499146,
      "learning_rate": 5.863013698630138e-05,
      "loss": 0.08,
      "step": 1610
    },
    {
      "epoch": 1.296,
      "grad_norm": 0.9110819697380066,
      "learning_rate": 5.835616438356165e-05,
      "loss": 0.0725,
      "step": 1620
    },
    {
      "epoch": 1.304,
      "grad_norm": 1.1319788694381714,
      "learning_rate": 5.808219178082191e-05,
      "loss": 0.0709,
      "step": 1630
    },
    {
      "epoch": 1.312,
      "grad_norm": 2.0053815841674805,
      "learning_rate": 5.780821917808219e-05,
      "loss": 0.0853,
      "step": 1640
    },
    {
      "epoch": 1.32,
      "grad_norm": 1.6860028505325317,
      "learning_rate": 5.753424657534247e-05,
      "loss": 0.1447,
      "step": 1650
    },
    {
      "epoch": 1.32,
      "eval_loss": 0.039434053003787994,
      "eval_runtime": 151.6419,
      "eval_samples_per_second": 6.594,
      "eval_steps_per_second": 0.824,
      "step": 1650
    },
    {
      "epoch": 1.328,
      "grad_norm": 1.135701298713684,
      "learning_rate": 5.726027397260274e-05,
      "loss": 0.119,
      "step": 1660
    },
    {
      "epoch": 1.336,
      "grad_norm": 6.9138007164001465,
      "learning_rate": 5.698630136986302e-05,
      "loss": 0.0923,
      "step": 1670
    },
    {
      "epoch": 1.3439999999999999,
      "grad_norm": 1.3648897409439087,
      "learning_rate": 5.671232876712329e-05,
      "loss": 0.0735,
      "step": 1680
    },
    {
      "epoch": 1.3519999999999999,
      "grad_norm": 0.5024760961532593,
      "learning_rate": 5.643835616438357e-05,
      "loss": 0.1182,
      "step": 1690
    },
    {
      "epoch": 1.3599999999999999,
      "grad_norm": 0.2777322232723236,
      "learning_rate": 5.616438356164384e-05,
      "loss": 0.0655,
      "step": 1700
    },
    {
      "epoch": 1.3599999999999999,
      "eval_loss": 0.03907589614391327,
      "eval_runtime": 151.65,
      "eval_samples_per_second": 6.594,
      "eval_steps_per_second": 0.824,
      "step": 1700
    },
    {
      "epoch": 1.3679999999999999,
      "grad_norm": 3.1028640270233154,
      "learning_rate": 5.5890410958904116e-05,
      "loss": 0.1125,
      "step": 1710
    },
    {
      "epoch": 1.376,
      "grad_norm": 3.719818115234375,
      "learning_rate": 5.5616438356164394e-05,
      "loss": 0.1009,
      "step": 1720
    },
    {
      "epoch": 1.384,
      "grad_norm": 0.9101502299308777,
      "learning_rate": 5.534246575342466e-05,
      "loss": 0.0775,
      "step": 1730
    },
    {
      "epoch": 1.392,
      "grad_norm": 1.5249415636062622,
      "learning_rate": 5.506849315068493e-05,
      "loss": 0.1112,
      "step": 1740
    },
    {
      "epoch": 1.4,
      "grad_norm": 1.40496027469635,
      "learning_rate": 5.479452054794521e-05,
      "loss": 0.1045,
      "step": 1750
    },
    {
      "epoch": 1.4,
      "eval_loss": 0.03013058938086033,
      "eval_runtime": 151.9141,
      "eval_samples_per_second": 6.583,
      "eval_steps_per_second": 0.823,
      "step": 1750
    },
    {
      "epoch": 1.408,
      "grad_norm": 2.0007171630859375,
      "learning_rate": 5.452054794520548e-05,
      "loss": 0.0781,
      "step": 1760
    },
    {
      "epoch": 1.416,
      "grad_norm": 0.22472810745239258,
      "learning_rate": 5.4246575342465756e-05,
      "loss": 0.0573,
      "step": 1770
    },
    {
      "epoch": 1.424,
      "grad_norm": 1.779203176498413,
      "learning_rate": 5.397260273972603e-05,
      "loss": 0.1059,
      "step": 1780
    },
    {
      "epoch": 1.432,
      "grad_norm": 1.2810580730438232,
      "learning_rate": 5.3698630136986305e-05,
      "loss": 0.0473,
      "step": 1790
    },
    {
      "epoch": 1.44,
      "grad_norm": 1.399487018585205,
      "learning_rate": 5.342465753424658e-05,
      "loss": 0.0724,
      "step": 1800
    },
    {
      "epoch": 1.44,
      "eval_loss": 0.03222149610519409,
      "eval_runtime": 152.3096,
      "eval_samples_per_second": 6.566,
      "eval_steps_per_second": 0.821,
      "step": 1800
    },
    {
      "epoch": 1.448,
      "grad_norm": 3.0364208221435547,
      "learning_rate": 5.3150684931506854e-05,
      "loss": 0.0489,
      "step": 1810
    },
    {
      "epoch": 1.456,
      "grad_norm": 2.7009081840515137,
      "learning_rate": 5.287671232876713e-05,
      "loss": 0.0798,
      "step": 1820
    },
    {
      "epoch": 1.464,
      "grad_norm": 13.240091323852539,
      "learning_rate": 5.2602739726027396e-05,
      "loss": 0.1311,
      "step": 1830
    },
    {
      "epoch": 1.472,
      "grad_norm": 1.3191215991973877,
      "learning_rate": 5.232876712328767e-05,
      "loss": 0.0571,
      "step": 1840
    },
    {
      "epoch": 1.48,
      "grad_norm": 1.2370073795318604,
      "learning_rate": 5.2054794520547945e-05,
      "loss": 0.0912,
      "step": 1850
    },
    {
      "epoch": 1.48,
      "eval_loss": 0.0300433486700058,
      "eval_runtime": 151.5615,
      "eval_samples_per_second": 6.598,
      "eval_steps_per_second": 0.825,
      "step": 1850
    },
    {
      "epoch": 1.488,
      "grad_norm": 0.8316535949707031,
      "learning_rate": 5.178082191780822e-05,
      "loss": 0.0686,
      "step": 1860
    },
    {
      "epoch": 1.496,
      "grad_norm": 0.385385125875473,
      "learning_rate": 5.1506849315068494e-05,
      "loss": 0.0862,
      "step": 1870
    },
    {
      "epoch": 1.504,
      "grad_norm": 0.7057093381881714,
      "learning_rate": 5.123287671232877e-05,
      "loss": 0.0666,
      "step": 1880
    },
    {
      "epoch": 1.512,
      "grad_norm": 0.4132567346096039,
      "learning_rate": 5.095890410958904e-05,
      "loss": 0.0517,
      "step": 1890
    },
    {
      "epoch": 1.52,
      "grad_norm": 0.8930286169052124,
      "learning_rate": 5.068493150684932e-05,
      "loss": 0.0682,
      "step": 1900
    },
    {
      "epoch": 1.52,
      "eval_loss": 0.026656173169612885,
      "eval_runtime": 151.6593,
      "eval_samples_per_second": 6.594,
      "eval_steps_per_second": 0.824,
      "step": 1900
    },
    {
      "epoch": 1.528,
      "grad_norm": 1.0141072273254395,
      "learning_rate": 5.041095890410959e-05,
      "loss": 0.0682,
      "step": 1910
    },
    {
      "epoch": 1.536,
      "grad_norm": 2.637566566467285,
      "learning_rate": 5.013698630136987e-05,
      "loss": 0.088,
      "step": 1920
    },
    {
      "epoch": 1.544,
      "grad_norm": 0.38905227184295654,
      "learning_rate": 4.986301369863014e-05,
      "loss": 0.0869,
      "step": 1930
    },
    {
      "epoch": 1.552,
      "grad_norm": 2.9471521377563477,
      "learning_rate": 4.958904109589041e-05,
      "loss": 0.0974,
      "step": 1940
    },
    {
      "epoch": 1.56,
      "grad_norm": 0.7595775723457336,
      "learning_rate": 4.9315068493150684e-05,
      "loss": 0.0814,
      "step": 1950
    },
    {
      "epoch": 1.56,
      "eval_loss": 0.027722494676709175,
      "eval_runtime": 151.6037,
      "eval_samples_per_second": 6.596,
      "eval_steps_per_second": 0.825,
      "step": 1950
    },
    {
      "epoch": 1.568,
      "grad_norm": 1.4184472560882568,
      "learning_rate": 4.904109589041096e-05,
      "loss": 0.099,
      "step": 1960
    },
    {
      "epoch": 1.576,
      "grad_norm": 0.6771255731582642,
      "learning_rate": 4.876712328767123e-05,
      "loss": 0.0704,
      "step": 1970
    },
    {
      "epoch": 1.584,
      "grad_norm": 0.9539465308189392,
      "learning_rate": 4.849315068493151e-05,
      "loss": 0.0377,
      "step": 1980
    },
    {
      "epoch": 1.592,
      "grad_norm": 0.8208433985710144,
      "learning_rate": 4.821917808219178e-05,
      "loss": 0.0491,
      "step": 1990
    },
    {
      "epoch": 1.6,
      "grad_norm": 1.6341674327850342,
      "learning_rate": 4.794520547945205e-05,
      "loss": 0.0637,
      "step": 2000
    },
    {
      "epoch": 1.6,
      "eval_loss": 0.026014752686023712,
      "eval_runtime": 151.6043,
      "eval_samples_per_second": 6.596,
      "eval_steps_per_second": 0.825,
      "step": 2000
    },
    {
      "epoch": 1.608,
      "grad_norm": 0.7984796166419983,
      "learning_rate": 4.767123287671233e-05,
      "loss": 0.0394,
      "step": 2010
    },
    {
      "epoch": 1.616,
      "grad_norm": 2.2652313709259033,
      "learning_rate": 4.73972602739726e-05,
      "loss": 0.0843,
      "step": 2020
    },
    {
      "epoch": 1.624,
      "grad_norm": 0.8778718709945679,
      "learning_rate": 4.712328767123288e-05,
      "loss": 0.0729,
      "step": 2030
    },
    {
      "epoch": 1.6320000000000001,
      "grad_norm": 1.1117192506790161,
      "learning_rate": 4.684931506849316e-05,
      "loss": 0.0913,
      "step": 2040
    },
    {
      "epoch": 1.6400000000000001,
      "grad_norm": 0.5873611569404602,
      "learning_rate": 4.657534246575342e-05,
      "loss": 0.0756,
      "step": 2050
    },
    {
      "epoch": 1.6400000000000001,
      "eval_loss": 0.021306466311216354,
      "eval_runtime": 151.5932,
      "eval_samples_per_second": 6.597,
      "eval_steps_per_second": 0.825,
      "step": 2050
    },
    {
      "epoch": 1.6480000000000001,
      "grad_norm": 0.5867145657539368,
      "learning_rate": 4.63013698630137e-05,
      "loss": 0.049,
      "step": 2060
    },
    {
      "epoch": 1.6560000000000001,
      "grad_norm": 0.7014798521995544,
      "learning_rate": 4.602739726027398e-05,
      "loss": 0.0551,
      "step": 2070
    },
    {
      "epoch": 1.6640000000000001,
      "grad_norm": 1.5778683423995972,
      "learning_rate": 4.575342465753425e-05,
      "loss": 0.0648,
      "step": 2080
    },
    {
      "epoch": 1.6720000000000002,
      "grad_norm": 0.8772918581962585,
      "learning_rate": 4.547945205479453e-05,
      "loss": 0.0466,
      "step": 2090
    },
    {
      "epoch": 1.6800000000000002,
      "grad_norm": 0.5173554420471191,
      "learning_rate": 4.520547945205479e-05,
      "loss": 0.0641,
      "step": 2100
    },
    {
      "epoch": 1.6800000000000002,
      "eval_loss": 0.02395830862224102,
      "eval_runtime": 151.6193,
      "eval_samples_per_second": 6.595,
      "eval_steps_per_second": 0.824,
      "step": 2100
    },
    {
      "epoch": 1.688,
      "grad_norm": 2.049327850341797,
      "learning_rate": 4.493150684931507e-05,
      "loss": 0.0591,
      "step": 2110
    },
    {
      "epoch": 1.696,
      "grad_norm": 1.2973850965499878,
      "learning_rate": 4.465753424657535e-05,
      "loss": 0.103,
      "step": 2120
    },
    {
      "epoch": 1.704,
      "grad_norm": 1.6017546653747559,
      "learning_rate": 4.438356164383562e-05,
      "loss": 0.0542,
      "step": 2130
    },
    {
      "epoch": 1.712,
      "grad_norm": 1.1270370483398438,
      "learning_rate": 4.4109589041095896e-05,
      "loss": 0.0446,
      "step": 2140
    },
    {
      "epoch": 1.72,
      "grad_norm": 0.8603224158287048,
      "learning_rate": 4.383561643835617e-05,
      "loss": 0.0499,
      "step": 2150
    },
    {
      "epoch": 1.72,
      "eval_loss": 0.029008224606513977,
      "eval_runtime": 151.6598,
      "eval_samples_per_second": 6.594,
      "eval_steps_per_second": 0.824,
      "step": 2150
    },
    {
      "epoch": 1.728,
      "grad_norm": 1.2351279258728027,
      "learning_rate": 4.356164383561644e-05,
      "loss": 0.0651,
      "step": 2160
    },
    {
      "epoch": 1.736,
      "grad_norm": 0.8837258815765381,
      "learning_rate": 4.3287671232876716e-05,
      "loss": 0.0405,
      "step": 2170
    },
    {
      "epoch": 1.744,
      "grad_norm": 1.7742750644683838,
      "learning_rate": 4.301369863013699e-05,
      "loss": 0.0532,
      "step": 2180
    },
    {
      "epoch": 1.752,
      "grad_norm": 0.5368234515190125,
      "learning_rate": 4.2739726027397265e-05,
      "loss": 0.0288,
      "step": 2190
    },
    {
      "epoch": 1.76,
      "grad_norm": 0.6619827151298523,
      "learning_rate": 4.2465753424657536e-05,
      "loss": 0.0581,
      "step": 2200
    },
    {
      "epoch": 1.76,
      "eval_loss": 0.0272468701004982,
      "eval_runtime": 151.5279,
      "eval_samples_per_second": 6.599,
      "eval_steps_per_second": 0.825,
      "step": 2200
    },
    {
      "epoch": 1.768,
      "grad_norm": 2.404492139816284,
      "learning_rate": 4.219178082191781e-05,
      "loss": 0.0863,
      "step": 2210
    },
    {
      "epoch": 1.776,
      "grad_norm": 1.083178997039795,
      "learning_rate": 4.1917808219178085e-05,
      "loss": 0.0691,
      "step": 2220
    },
    {
      "epoch": 1.784,
      "grad_norm": 1.8032499551773071,
      "learning_rate": 4.1643835616438356e-05,
      "loss": 0.0612,
      "step": 2230
    },
    {
      "epoch": 1.792,
      "grad_norm": 1.6221861839294434,
      "learning_rate": 4.1369863013698634e-05,
      "loss": 0.0517,
      "step": 2240
    },
    {
      "epoch": 1.8,
      "grad_norm": 2.3262734413146973,
      "learning_rate": 4.1095890410958905e-05,
      "loss": 0.054,
      "step": 2250
    },
    {
      "epoch": 1.8,
      "eval_loss": 0.024572424590587616,
      "eval_runtime": 151.4557,
      "eval_samples_per_second": 6.603,
      "eval_steps_per_second": 0.825,
      "step": 2250
    },
    {
      "epoch": 1.808,
      "grad_norm": 1.75326669216156,
      "learning_rate": 4.0821917808219176e-05,
      "loss": 0.0549,
      "step": 2260
    },
    {
      "epoch": 1.8159999999999998,
      "grad_norm": 1.8827154636383057,
      "learning_rate": 4.0547945205479454e-05,
      "loss": 0.0582,
      "step": 2270
    },
    {
      "epoch": 1.8239999999999998,
      "grad_norm": 1.4736891984939575,
      "learning_rate": 4.027397260273973e-05,
      "loss": 0.0939,
      "step": 2280
    },
    {
      "epoch": 1.8319999999999999,
      "grad_norm": 1.620284914970398,
      "learning_rate": 4e-05,
      "loss": 0.0549,
      "step": 2290
    },
    {
      "epoch": 1.8399999999999999,
      "grad_norm": 5.199363708496094,
      "learning_rate": 3.9726027397260274e-05,
      "loss": 0.0252,
      "step": 2300
    },
    {
      "epoch": 1.8399999999999999,
      "eval_loss": 0.02966296300292015,
      "eval_runtime": 151.6553,
      "eval_samples_per_second": 6.594,
      "eval_steps_per_second": 0.824,
      "step": 2300
    },
    {
      "epoch": 1.8479999999999999,
      "grad_norm": 0.6137276887893677,
      "learning_rate": 3.9452054794520546e-05,
      "loss": 0.0392,
      "step": 2310
    },
    {
      "epoch": 1.8559999999999999,
      "grad_norm": 0.9602599740028381,
      "learning_rate": 3.9178082191780823e-05,
      "loss": 0.0482,
      "step": 2320
    },
    {
      "epoch": 1.8639999999999999,
      "grad_norm": 2.274354934692383,
      "learning_rate": 3.89041095890411e-05,
      "loss": 0.0552,
      "step": 2330
    },
    {
      "epoch": 1.8719999999999999,
      "grad_norm": 0.6457303762435913,
      "learning_rate": 3.863013698630137e-05,
      "loss": 0.0486,
      "step": 2340
    },
    {
      "epoch": 1.88,
      "grad_norm": 0.7338441014289856,
      "learning_rate": 3.8356164383561644e-05,
      "loss": 0.066,
      "step": 2350
    },
    {
      "epoch": 1.88,
      "eval_loss": 0.030180875211954117,
      "eval_runtime": 152.9033,
      "eval_samples_per_second": 6.54,
      "eval_steps_per_second": 0.818,
      "step": 2350
    },
    {
      "epoch": 1.888,
      "grad_norm": 0.821628212928772,
      "learning_rate": 3.808219178082192e-05,
      "loss": 0.0445,
      "step": 2360
    },
    {
      "epoch": 1.896,
      "grad_norm": 2.2537119388580322,
      "learning_rate": 3.780821917808219e-05,
      "loss": 0.0847,
      "step": 2370
    },
    {
      "epoch": 1.904,
      "grad_norm": 4.551086902618408,
      "learning_rate": 3.753424657534247e-05,
      "loss": 0.1062,
      "step": 2380
    },
    {
      "epoch": 1.912,
      "grad_norm": 0.9535849690437317,
      "learning_rate": 3.726027397260274e-05,
      "loss": 0.0377,
      "step": 2390
    },
    {
      "epoch": 1.92,
      "grad_norm": 1.3393959999084473,
      "learning_rate": 3.698630136986301e-05,
      "loss": 0.0894,
      "step": 2400
    },
    {
      "epoch": 1.92,
      "eval_loss": 0.024797027930617332,
      "eval_runtime": 151.663,
      "eval_samples_per_second": 6.594,
      "eval_steps_per_second": 0.824,
      "step": 2400
    },
    {
      "epoch": 1.928,
      "grad_norm": 1.6456127166748047,
      "learning_rate": 3.671232876712329e-05,
      "loss": 0.058,
      "step": 2410
    },
    {
      "epoch": 1.936,
      "grad_norm": 1.4587665796279907,
      "learning_rate": 3.643835616438356e-05,
      "loss": 0.0508,
      "step": 2420
    },
    {
      "epoch": 1.944,
      "grad_norm": 1.6080820560455322,
      "learning_rate": 3.616438356164384e-05,
      "loss": 0.0735,
      "step": 2430
    },
    {
      "epoch": 1.952,
      "grad_norm": 1.1531568765640259,
      "learning_rate": 3.589041095890411e-05,
      "loss": 0.043,
      "step": 2440
    },
    {
      "epoch": 1.96,
      "grad_norm": 0.24241037666797638,
      "learning_rate": 3.561643835616438e-05,
      "loss": 0.0481,
      "step": 2450
    },
    {
      "epoch": 1.96,
      "eval_loss": 0.022091209888458252,
      "eval_runtime": 151.6899,
      "eval_samples_per_second": 6.592,
      "eval_steps_per_second": 0.824,
      "step": 2450
    },
    {
      "epoch": 1.968,
      "grad_norm": 0.7883796095848083,
      "learning_rate": 3.534246575342466e-05,
      "loss": 0.0331,
      "step": 2460
    },
    {
      "epoch": 1.976,
      "grad_norm": 0.13827729225158691,
      "learning_rate": 3.506849315068493e-05,
      "loss": 0.036,
      "step": 2470
    },
    {
      "epoch": 1.984,
      "grad_norm": 0.7191653251647949,
      "learning_rate": 3.479452054794521e-05,
      "loss": 0.0665,
      "step": 2480
    },
    {
      "epoch": 1.992,
      "grad_norm": 2.505990982055664,
      "learning_rate": 3.452054794520549e-05,
      "loss": 0.0692,
      "step": 2490
    },
    {
      "epoch": 2.0,
      "grad_norm": 1.2869579792022705,
      "learning_rate": 3.424657534246575e-05,
      "loss": 0.0457,
      "step": 2500
    },
    {
      "epoch": 2.0,
      "eval_loss": 0.020927097648382187,
      "eval_runtime": 151.5964,
      "eval_samples_per_second": 6.596,
      "eval_steps_per_second": 0.825,
      "step": 2500
    },
    {
      "epoch": 2.008,
      "grad_norm": 0.8180481195449829,
      "learning_rate": 3.397260273972603e-05,
      "loss": 0.0786,
      "step": 2510
    },
    {
      "epoch": 2.016,
      "grad_norm": 0.4002639055252075,
      "learning_rate": 3.36986301369863e-05,
      "loss": 0.0528,
      "step": 2520
    },
    {
      "epoch": 2.024,
      "grad_norm": 0.5794337391853333,
      "learning_rate": 3.342465753424658e-05,
      "loss": 0.026,
      "step": 2530
    },
    {
      "epoch": 2.032,
      "grad_norm": 1.0454254150390625,
      "learning_rate": 3.3150684931506856e-05,
      "loss": 0.0686,
      "step": 2540
    },
    {
      "epoch": 2.04,
      "grad_norm": 0.3794173300266266,
      "learning_rate": 3.287671232876712e-05,
      "loss": 0.0777,
      "step": 2550
    },
    {
      "epoch": 2.04,
      "eval_loss": 0.019912905991077423,
      "eval_runtime": 152.9712,
      "eval_samples_per_second": 6.537,
      "eval_steps_per_second": 0.817,
      "step": 2550
    },
    {
      "epoch": 2.048,
      "grad_norm": 1.1376004219055176,
      "learning_rate": 3.26027397260274e-05,
      "loss": 0.0404,
      "step": 2560
    },
    {
      "epoch": 2.056,
      "grad_norm": 0.43132463097572327,
      "learning_rate": 3.2328767123287676e-05,
      "loss": 0.039,
      "step": 2570
    },
    {
      "epoch": 2.064,
      "grad_norm": 0.8754494190216064,
      "learning_rate": 3.205479452054795e-05,
      "loss": 0.0378,
      "step": 2580
    },
    {
      "epoch": 2.072,
      "grad_norm": 0.9680449366569519,
      "learning_rate": 3.1780821917808225e-05,
      "loss": 0.0351,
      "step": 2590
    },
    {
      "epoch": 2.08,
      "grad_norm": 4.028409957885742,
      "learning_rate": 3.1506849315068496e-05,
      "loss": 0.0503,
      "step": 2600
    },
    {
      "epoch": 2.08,
      "eval_loss": 0.02152809128165245,
      "eval_runtime": 151.7133,
      "eval_samples_per_second": 6.591,
      "eval_steps_per_second": 0.824,
      "step": 2600
    },
    {
      "epoch": 2.088,
      "grad_norm": 1.534597635269165,
      "learning_rate": 3.123287671232877e-05,
      "loss": 0.0514,
      "step": 2610
    },
    {
      "epoch": 2.096,
      "grad_norm": 1.5760735273361206,
      "learning_rate": 3.0958904109589045e-05,
      "loss": 0.0616,
      "step": 2620
    },
    {
      "epoch": 2.104,
      "grad_norm": 0.08791323006153107,
      "learning_rate": 3.0684931506849316e-05,
      "loss": 0.0441,
      "step": 2630
    },
    {
      "epoch": 2.112,
      "grad_norm": 1.4847877025604248,
      "learning_rate": 3.0410958904109594e-05,
      "loss": 0.0463,
      "step": 2640
    },
    {
      "epoch": 2.12,
      "grad_norm": 0.7520050406455994,
      "learning_rate": 3.0136986301369862e-05,
      "loss": 0.0285,
      "step": 2650
    },
    {
      "epoch": 2.12,
      "eval_loss": 0.018634678795933723,
      "eval_runtime": 151.6907,
      "eval_samples_per_second": 6.592,
      "eval_steps_per_second": 0.824,
      "step": 2650
    },
    {
      "epoch": 2.128,
      "grad_norm": 1.1852107048034668,
      "learning_rate": 2.9863013698630136e-05,
      "loss": 0.0275,
      "step": 2660
    },
    {
      "epoch": 2.136,
      "grad_norm": 7.072668552398682,
      "learning_rate": 2.9589041095890414e-05,
      "loss": 0.0484,
      "step": 2670
    },
    {
      "epoch": 2.144,
      "grad_norm": 0.7138960957527161,
      "learning_rate": 2.931506849315069e-05,
      "loss": 0.0521,
      "step": 2680
    },
    {
      "epoch": 2.152,
      "grad_norm": 1.7963248491287231,
      "learning_rate": 2.9041095890410956e-05,
      "loss": 0.0335,
      "step": 2690
    },
    {
      "epoch": 2.16,
      "grad_norm": 1.135267734527588,
      "learning_rate": 2.8767123287671234e-05,
      "loss": 0.0592,
      "step": 2700
    },
    {
      "epoch": 2.16,
      "eval_loss": 0.019648704677820206,
      "eval_runtime": 151.634,
      "eval_samples_per_second": 6.595,
      "eval_steps_per_second": 0.824,
      "step": 2700
    },
    {
      "epoch": 2.168,
      "grad_norm": 1.4318064451217651,
      "learning_rate": 2.849315068493151e-05,
      "loss": 0.0402,
      "step": 2710
    },
    {
      "epoch": 2.176,
      "grad_norm": 3.0212478637695312,
      "learning_rate": 2.8219178082191783e-05,
      "loss": 0.07,
      "step": 2720
    },
    {
      "epoch": 2.184,
      "grad_norm": 3.9226880073547363,
      "learning_rate": 2.7945205479452058e-05,
      "loss": 0.0397,
      "step": 2730
    },
    {
      "epoch": 2.192,
      "grad_norm": 3.637977123260498,
      "learning_rate": 2.767123287671233e-05,
      "loss": 0.0451,
      "step": 2740
    },
    {
      "epoch": 2.2,
      "grad_norm": 0.1445624977350235,
      "learning_rate": 2.7397260273972603e-05,
      "loss": 0.0338,
      "step": 2750
    },
    {
      "epoch": 2.2,
      "eval_loss": 0.022685738280415535,
      "eval_runtime": 151.5616,
      "eval_samples_per_second": 6.598,
      "eval_steps_per_second": 0.825,
      "step": 2750
    },
    {
      "epoch": 2.208,
      "grad_norm": 0.4597229063510895,
      "learning_rate": 2.7123287671232878e-05,
      "loss": 0.0272,
      "step": 2760
    },
    {
      "epoch": 2.216,
      "grad_norm": 0.8008188605308533,
      "learning_rate": 2.6849315068493153e-05,
      "loss": 0.0346,
      "step": 2770
    },
    {
      "epoch": 2.224,
      "grad_norm": 0.9788293838500977,
      "learning_rate": 2.6575342465753427e-05,
      "loss": 0.0312,
      "step": 2780
    },
    {
      "epoch": 2.232,
      "grad_norm": 1.963165283203125,
      "learning_rate": 2.6301369863013698e-05,
      "loss": 0.0423,
      "step": 2790
    },
    {
      "epoch": 2.24,
      "grad_norm": 2.1469695568084717,
      "learning_rate": 2.6027397260273973e-05,
      "loss": 0.0242,
      "step": 2800
    },
    {
      "epoch": 2.24,
      "eval_loss": 0.019992094486951828,
      "eval_runtime": 151.613,
      "eval_samples_per_second": 6.596,
      "eval_steps_per_second": 0.824,
      "step": 2800
    },
    {
      "epoch": 2.248,
      "grad_norm": 0.6660459637641907,
      "learning_rate": 2.5753424657534247e-05,
      "loss": 0.0409,
      "step": 2810
    },
    {
      "epoch": 2.2560000000000002,
      "grad_norm": 0.10677190124988556,
      "learning_rate": 2.547945205479452e-05,
      "loss": 0.0502,
      "step": 2820
    },
    {
      "epoch": 2.2640000000000002,
      "grad_norm": 0.3709983825683594,
      "learning_rate": 2.5205479452054796e-05,
      "loss": 0.0385,
      "step": 2830
    },
    {
      "epoch": 2.2720000000000002,
      "grad_norm": 0.8731529712677002,
      "learning_rate": 2.493150684931507e-05,
      "loss": 0.0419,
      "step": 2840
    },
    {
      "epoch": 2.2800000000000002,
      "grad_norm": 0.6987985968589783,
      "learning_rate": 2.4657534246575342e-05,
      "loss": 0.0272,
      "step": 2850
    },
    {
      "epoch": 2.2800000000000002,
      "eval_loss": 0.02250443957746029,
      "eval_runtime": 151.7686,
      "eval_samples_per_second": 6.589,
      "eval_steps_per_second": 0.824,
      "step": 2850
    },
    {
      "epoch": 2.288,
      "grad_norm": 1.132643699645996,
      "learning_rate": 2.4383561643835616e-05,
      "loss": 0.047,
      "step": 2860
    },
    {
      "epoch": 2.296,
      "grad_norm": 1.484281063079834,
      "learning_rate": 2.410958904109589e-05,
      "loss": 0.0468,
      "step": 2870
    },
    {
      "epoch": 2.304,
      "grad_norm": 0.3550022840499878,
      "learning_rate": 2.3835616438356165e-05,
      "loss": 0.0212,
      "step": 2880
    },
    {
      "epoch": 2.312,
      "grad_norm": 2.330826997756958,
      "learning_rate": 2.356164383561644e-05,
      "loss": 0.0518,
      "step": 2890
    },
    {
      "epoch": 2.32,
      "grad_norm": 0.4516685903072357,
      "learning_rate": 2.328767123287671e-05,
      "loss": 0.0404,
      "step": 2900
    },
    {
      "epoch": 2.32,
      "eval_loss": 0.02170676738023758,
      "eval_runtime": 151.566,
      "eval_samples_per_second": 6.598,
      "eval_steps_per_second": 0.825,
      "step": 2900
    },
    {
      "epoch": 2.328,
      "grad_norm": 0.41401204466819763,
      "learning_rate": 2.301369863013699e-05,
      "loss": 0.0479,
      "step": 2910
    },
    {
      "epoch": 2.336,
      "grad_norm": 1.548948884010315,
      "learning_rate": 2.2739726027397263e-05,
      "loss": 0.0677,
      "step": 2920
    },
    {
      "epoch": 2.344,
      "grad_norm": 0.25845882296562195,
      "learning_rate": 2.2465753424657534e-05,
      "loss": 0.0336,
      "step": 2930
    },
    {
      "epoch": 2.352,
      "grad_norm": 0.7794516682624817,
      "learning_rate": 2.219178082191781e-05,
      "loss": 0.0507,
      "step": 2940
    },
    {
      "epoch": 2.36,
      "grad_norm": 1.7464135885238647,
      "learning_rate": 2.1917808219178083e-05,
      "loss": 0.03,
      "step": 2950
    },
    {
      "epoch": 2.36,
      "eval_loss": 0.023860391229391098,
      "eval_runtime": 151.6869,
      "eval_samples_per_second": 6.593,
      "eval_steps_per_second": 0.824,
      "step": 2950
    },
    {
      "epoch": 2.368,
      "grad_norm": 2.585756778717041,
      "learning_rate": 2.1643835616438358e-05,
      "loss": 0.0663,
      "step": 2960
    },
    {
      "epoch": 2.376,
      "grad_norm": 2.9544589519500732,
      "learning_rate": 2.1369863013698632e-05,
      "loss": 0.0455,
      "step": 2970
    },
    {
      "epoch": 2.384,
      "grad_norm": 2.4210753440856934,
      "learning_rate": 2.1095890410958904e-05,
      "loss": 0.0439,
      "step": 2980
    },
    {
      "epoch": 2.392,
      "grad_norm": 0.30375024676322937,
      "learning_rate": 2.0821917808219178e-05,
      "loss": 0.0672,
      "step": 2990
    },
    {
      "epoch": 2.4,
      "grad_norm": 0.9656882882118225,
      "learning_rate": 2.0547945205479453e-05,
      "loss": 0.0355,
      "step": 3000
    },
    {
      "epoch": 2.4,
      "eval_loss": 0.022906262427568436,
      "eval_runtime": 151.7423,
      "eval_samples_per_second": 6.59,
      "eval_steps_per_second": 0.824,
      "step": 3000
    },
    {
      "epoch": 2.408,
      "grad_norm": 0.20300522446632385,
      "learning_rate": 2.0273972602739727e-05,
      "loss": 0.0312,
      "step": 3010
    },
    {
      "epoch": 2.416,
      "grad_norm": 0.8318269848823547,
      "learning_rate": 2e-05,
      "loss": 0.0382,
      "step": 3020
    },
    {
      "epoch": 2.424,
      "grad_norm": 1.1963917016983032,
      "learning_rate": 1.9726027397260273e-05,
      "loss": 0.0455,
      "step": 3030
    },
    {
      "epoch": 2.432,
      "grad_norm": 1.1220641136169434,
      "learning_rate": 1.945205479452055e-05,
      "loss": 0.0349,
      "step": 3040
    },
    {
      "epoch": 2.44,
      "grad_norm": 0.15850111842155457,
      "learning_rate": 1.9178082191780822e-05,
      "loss": 0.0437,
      "step": 3050
    },
    {
      "epoch": 2.44,
      "eval_loss": 0.024031003937125206,
      "eval_runtime": 151.6401,
      "eval_samples_per_second": 6.595,
      "eval_steps_per_second": 0.824,
      "step": 3050
    },
    {
      "epoch": 2.448,
      "grad_norm": 0.12684205174446106,
      "learning_rate": 1.8904109589041096e-05,
      "loss": 0.0239,
      "step": 3060
    },
    {
      "epoch": 2.456,
      "grad_norm": 0.8776719570159912,
      "learning_rate": 1.863013698630137e-05,
      "loss": 0.0363,
      "step": 3070
    },
    {
      "epoch": 2.464,
      "grad_norm": 0.8527880311012268,
      "learning_rate": 1.8356164383561645e-05,
      "loss": 0.0582,
      "step": 3080
    },
    {
      "epoch": 2.472,
      "grad_norm": 0.5176323652267456,
      "learning_rate": 1.808219178082192e-05,
      "loss": 0.0482,
      "step": 3090
    },
    {
      "epoch": 2.48,
      "grad_norm": 1.6554021835327148,
      "learning_rate": 1.780821917808219e-05,
      "loss": 0.0274,
      "step": 3100
    },
    {
      "epoch": 2.48,
      "eval_loss": 0.023579662665724754,
      "eval_runtime": 151.7488,
      "eval_samples_per_second": 6.59,
      "eval_steps_per_second": 0.824,
      "step": 3100
    },
    {
      "epoch": 2.488,
      "grad_norm": 1.3815973997116089,
      "learning_rate": 1.7534246575342465e-05,
      "loss": 0.0389,
      "step": 3110
    },
    {
      "epoch": 2.496,
      "grad_norm": 1.3177127838134766,
      "learning_rate": 1.7260273972602743e-05,
      "loss": 0.0418,
      "step": 3120
    },
    {
      "epoch": 2.504,
      "grad_norm": 0.09086146205663681,
      "learning_rate": 1.6986301369863014e-05,
      "loss": 0.0257,
      "step": 3130
    },
    {
      "epoch": 2.512,
      "grad_norm": 0.5245444774627686,
      "learning_rate": 1.671232876712329e-05,
      "loss": 0.0518,
      "step": 3140
    },
    {
      "epoch": 2.52,
      "grad_norm": 1.3401626348495483,
      "learning_rate": 1.643835616438356e-05,
      "loss": 0.0462,
      "step": 3150
    },
    {
      "epoch": 2.52,
      "eval_loss": 0.02168835513293743,
      "eval_runtime": 151.71,
      "eval_samples_per_second": 6.592,
      "eval_steps_per_second": 0.824,
      "step": 3150
    },
    {
      "epoch": 2.528,
      "grad_norm": 1.1089518070220947,
      "learning_rate": 1.6164383561643838e-05,
      "loss": 0.0351,
      "step": 3160
    },
    {
      "epoch": 2.536,
      "grad_norm": 1.2992647886276245,
      "learning_rate": 1.5890410958904112e-05,
      "loss": 0.0505,
      "step": 3170
    },
    {
      "epoch": 2.544,
      "grad_norm": 1.3973766565322876,
      "learning_rate": 1.5616438356164384e-05,
      "loss": 0.038,
      "step": 3180
    },
    {
      "epoch": 2.552,
      "grad_norm": 1.15162992477417,
      "learning_rate": 1.5342465753424658e-05,
      "loss": 0.033,
      "step": 3190
    },
    {
      "epoch": 2.56,
      "grad_norm": 1.3932210206985474,
      "learning_rate": 1.5068493150684931e-05,
      "loss": 0.0188,
      "step": 3200
    },
    {
      "epoch": 2.56,
      "eval_loss": 0.020066192373633385,
      "eval_runtime": 151.66,
      "eval_samples_per_second": 6.594,
      "eval_steps_per_second": 0.824,
      "step": 3200
    },
    {
      "epoch": 2.568,
      "grad_norm": 1.3425321578979492,
      "learning_rate": 1.4794520547945207e-05,
      "loss": 0.0196,
      "step": 3210
    },
    {
      "epoch": 2.576,
      "grad_norm": 0.5197652578353882,
      "learning_rate": 1.4520547945205478e-05,
      "loss": 0.0242,
      "step": 3220
    },
    {
      "epoch": 2.584,
      "grad_norm": 2.4876089096069336,
      "learning_rate": 1.4246575342465754e-05,
      "loss": 0.0419,
      "step": 3230
    },
    {
      "epoch": 2.592,
      "grad_norm": 1.3092076778411865,
      "learning_rate": 1.3972602739726029e-05,
      "loss": 0.0316,
      "step": 3240
    },
    {
      "epoch": 2.6,
      "grad_norm": 0.5418318510055542,
      "learning_rate": 1.3698630136986302e-05,
      "loss": 0.0434,
      "step": 3250
    },
    {
      "epoch": 2.6,
      "eval_loss": 0.02287939377129078,
      "eval_runtime": 151.6316,
      "eval_samples_per_second": 6.595,
      "eval_steps_per_second": 0.824,
      "step": 3250
    },
    {
      "epoch": 2.608,
      "grad_norm": 3.137234687805176,
      "learning_rate": 1.3424657534246576e-05,
      "loss": 0.0501,
      "step": 3260
    },
    {
      "epoch": 2.616,
      "grad_norm": 1.6329312324523926,
      "learning_rate": 1.3150684931506849e-05,
      "loss": 0.0408,
      "step": 3270
    },
    {
      "epoch": 2.624,
      "grad_norm": 0.4385315179824829,
      "learning_rate": 1.2876712328767124e-05,
      "loss": 0.0298,
      "step": 3280
    },
    {
      "epoch": 2.632,
      "grad_norm": 1.288231611251831,
      "learning_rate": 1.2602739726027398e-05,
      "loss": 0.06,
      "step": 3290
    },
    {
      "epoch": 2.64,
      "grad_norm": 0.20752505958080292,
      "learning_rate": 1.2328767123287671e-05,
      "loss": 0.043,
      "step": 3300
    },
    {
      "epoch": 2.64,
      "eval_loss": 0.021235531195998192,
      "eval_runtime": 151.6681,
      "eval_samples_per_second": 6.593,
      "eval_steps_per_second": 0.824,
      "step": 3300
    },
    {
      "epoch": 2.648,
      "grad_norm": 0.6002157330513,
      "learning_rate": 1.2054794520547945e-05,
      "loss": 0.0426,
      "step": 3310
    },
    {
      "epoch": 2.656,
      "grad_norm": 5.582460880279541,
      "learning_rate": 1.178082191780822e-05,
      "loss": 0.0504,
      "step": 3320
    },
    {
      "epoch": 2.664,
      "grad_norm": 1.178131103515625,
      "learning_rate": 1.1506849315068494e-05,
      "loss": 0.0355,
      "step": 3330
    },
    {
      "epoch": 2.672,
      "grad_norm": 0.4892362654209137,
      "learning_rate": 1.1232876712328767e-05,
      "loss": 0.0566,
      "step": 3340
    },
    {
      "epoch": 2.68,
      "grad_norm": 2.8391528129577637,
      "learning_rate": 1.0958904109589042e-05,
      "loss": 0.0689,
      "step": 3350
    },
    {
      "epoch": 2.68,
      "eval_loss": 0.018401553854346275,
      "eval_runtime": 151.6472,
      "eval_samples_per_second": 6.594,
      "eval_steps_per_second": 0.824,
      "step": 3350
    },
    {
      "epoch": 2.6879999999999997,
      "grad_norm": 1.5638452768325806,
      "learning_rate": 1.0684931506849316e-05,
      "loss": 0.0379,
      "step": 3360
    },
    {
      "epoch": 2.6959999999999997,
      "grad_norm": 1.1441236734390259,
      "learning_rate": 1.0410958904109589e-05,
      "loss": 0.0293,
      "step": 3370
    },
    {
      "epoch": 2.7039999999999997,
      "grad_norm": 1.1868925094604492,
      "learning_rate": 1.0136986301369864e-05,
      "loss": 0.0244,
      "step": 3380
    },
    {
      "epoch": 2.7119999999999997,
      "grad_norm": 0.2531038522720337,
      "learning_rate": 9.863013698630136e-06,
      "loss": 0.0298,
      "step": 3390
    },
    {
      "epoch": 2.7199999999999998,
      "grad_norm": 0.9073572158813477,
      "learning_rate": 9.589041095890411e-06,
      "loss": 0.0483,
      "step": 3400
    },
    {
      "epoch": 2.7199999999999998,
      "eval_loss": 0.018459144979715347,
      "eval_runtime": 151.7993,
      "eval_samples_per_second": 6.588,
      "eval_steps_per_second": 0.823,
      "step": 3400
    },
    {
      "epoch": 2.7279999999999998,
      "grad_norm": 0.5449960231781006,
      "learning_rate": 9.315068493150685e-06,
      "loss": 0.0464,
      "step": 3410
    },
    {
      "epoch": 2.7359999999999998,
      "grad_norm": 0.6786317825317383,
      "learning_rate": 9.04109589041096e-06,
      "loss": 0.024,
      "step": 3420
    },
    {
      "epoch": 2.7439999999999998,
      "grad_norm": 0.5641959309577942,
      "learning_rate": 8.767123287671233e-06,
      "loss": 0.0518,
      "step": 3430
    },
    {
      "epoch": 2.752,
      "grad_norm": 1.51552152633667,
      "learning_rate": 8.493150684931507e-06,
      "loss": 0.0299,
      "step": 3440
    },
    {
      "epoch": 2.76,
      "grad_norm": 2.1700212955474854,
      "learning_rate": 8.21917808219178e-06,
      "loss": 0.0341,
      "step": 3450
    },
    {
      "epoch": 2.76,
      "eval_loss": 0.020466580986976624,
      "eval_runtime": 151.6435,
      "eval_samples_per_second": 6.594,
      "eval_steps_per_second": 0.824,
      "step": 3450
    },
    {
      "epoch": 2.768,
      "grad_norm": 0.10757183283567429,
      "learning_rate": 7.945205479452056e-06,
      "loss": 0.0294,
      "step": 3460
    },
    {
      "epoch": 2.776,
      "grad_norm": 1.0318719148635864,
      "learning_rate": 7.671232876712329e-06,
      "loss": 0.043,
      "step": 3470
    },
    {
      "epoch": 2.784,
      "grad_norm": 0.14182302355766296,
      "learning_rate": 7.3972602739726036e-06,
      "loss": 0.0432,
      "step": 3480
    },
    {
      "epoch": 2.792,
      "grad_norm": 0.44093266129493713,
      "learning_rate": 7.123287671232877e-06,
      "loss": 0.0275,
      "step": 3490
    },
    {
      "epoch": 2.8,
      "grad_norm": 1.3206769227981567,
      "learning_rate": 6.849315068493151e-06,
      "loss": 0.0309,
      "step": 3500
    },
    {
      "epoch": 2.8,
      "eval_loss": 0.02166667766869068,
      "eval_runtime": 151.6614,
      "eval_samples_per_second": 6.594,
      "eval_steps_per_second": 0.824,
      "step": 3500
    },
    {
      "epoch": 2.808,
      "grad_norm": 0.4385565519332886,
      "learning_rate": 6.5753424657534245e-06,
      "loss": 0.0233,
      "step": 3510
    },
    {
      "epoch": 2.816,
      "grad_norm": 0.3696240484714508,
      "learning_rate": 6.301369863013699e-06,
      "loss": 0.0216,
      "step": 3520
    },
    {
      "epoch": 2.824,
      "grad_norm": 0.18175160884857178,
      "learning_rate": 6.027397260273973e-06,
      "loss": 0.0216,
      "step": 3530
    },
    {
      "epoch": 2.832,
      "grad_norm": 2.302055597305298,
      "learning_rate": 5.753424657534247e-06,
      "loss": 0.0218,
      "step": 3540
    },
    {
      "epoch": 2.84,
      "grad_norm": 1.057432770729065,
      "learning_rate": 5.479452054794521e-06,
      "loss": 0.038,
      "step": 3550
    },
    {
      "epoch": 2.84,
      "eval_loss": 0.022077135741710663,
      "eval_runtime": 152.1317,
      "eval_samples_per_second": 6.573,
      "eval_steps_per_second": 0.822,
      "step": 3550
    },
    {
      "epoch": 2.848,
      "grad_norm": 2.035381555557251,
      "learning_rate": 5.2054794520547945e-06,
      "loss": 0.039,
      "step": 3560
    },
    {
      "epoch": 2.856,
      "grad_norm": 0.9850253462791443,
      "learning_rate": 4.931506849315068e-06,
      "loss": 0.0446,
      "step": 3570
    },
    {
      "epoch": 2.864,
      "grad_norm": 0.7689424157142639,
      "learning_rate": 4.657534246575343e-06,
      "loss": 0.0487,
      "step": 3580
    },
    {
      "epoch": 2.872,
      "grad_norm": 2.1401124000549316,
      "learning_rate": 4.383561643835616e-06,
      "loss": 0.0363,
      "step": 3590
    },
    {
      "epoch": 2.88,
      "grad_norm": 0.1589365154504776,
      "learning_rate": 4.10958904109589e-06,
      "loss": 0.0282,
      "step": 3600
    },
    {
      "epoch": 2.88,
      "eval_loss": 0.02125280722975731,
      "eval_runtime": 151.811,
      "eval_samples_per_second": 6.587,
      "eval_steps_per_second": 0.823,
      "step": 3600
    },
    {
      "epoch": 2.888,
      "grad_norm": 0.5642897486686707,
      "learning_rate": 3.8356164383561645e-06,
      "loss": 0.0592,
      "step": 3610
    },
    {
      "epoch": 2.896,
      "grad_norm": 1.7916654348373413,
      "learning_rate": 3.5616438356164386e-06,
      "loss": 0.0372,
      "step": 3620
    },
    {
      "epoch": 2.904,
      "grad_norm": 0.4531151056289673,
      "learning_rate": 3.2876712328767123e-06,
      "loss": 0.059,
      "step": 3630
    },
    {
      "epoch": 2.912,
      "grad_norm": 3.0479955673217773,
      "learning_rate": 3.0136986301369864e-06,
      "loss": 0.0343,
      "step": 3640
    },
    {
      "epoch": 2.92,
      "grad_norm": 4.554259777069092,
      "learning_rate": 2.7397260273972604e-06,
      "loss": 0.0491,
      "step": 3650
    },
    {
      "epoch": 2.92,
      "eval_loss": 0.021392779424786568,
      "eval_runtime": 152.8284,
      "eval_samples_per_second": 6.543,
      "eval_steps_per_second": 0.818,
      "step": 3650
    },
    {
      "epoch": 2.928,
      "grad_norm": 0.5796236991882324,
      "learning_rate": 2.465753424657534e-06,
      "loss": 0.0456,
      "step": 3660
    },
    {
      "epoch": 2.936,
      "grad_norm": 0.7850148677825928,
      "learning_rate": 2.191780821917808e-06,
      "loss": 0.0353,
      "step": 3670
    },
    {
      "epoch": 2.944,
      "grad_norm": 0.9855867624282837,
      "learning_rate": 1.9178082191780823e-06,
      "loss": 0.027,
      "step": 3680
    },
    {
      "epoch": 2.952,
      "grad_norm": 0.2451908439397812,
      "learning_rate": 1.6438356164383561e-06,
      "loss": 0.0392,
      "step": 3690
    },
    {
      "epoch": 2.96,
      "grad_norm": 0.38270848989486694,
      "learning_rate": 1.3698630136986302e-06,
      "loss": 0.0335,
      "step": 3700
    },
    {
      "epoch": 2.96,
      "eval_loss": 0.021200133487582207,
      "eval_runtime": 152.0802,
      "eval_samples_per_second": 6.575,
      "eval_steps_per_second": 0.822,
      "step": 3700
    },
    {
      "epoch": 2.968,
      "grad_norm": 1.291527509689331,
      "learning_rate": 1.095890410958904e-06,
      "loss": 0.0273,
      "step": 3710
    },
    {
      "epoch": 2.976,
      "grad_norm": 1.38857901096344,
      "learning_rate": 8.219178082191781e-07,
      "loss": 0.0574,
      "step": 3720
    },
    {
      "epoch": 2.984,
      "grad_norm": 1.098345160484314,
      "learning_rate": 5.47945205479452e-07,
      "loss": 0.0252,
      "step": 3730
    },
    {
      "epoch": 2.992,
      "grad_norm": 1.0119602680206299,
      "learning_rate": 2.73972602739726e-07,
      "loss": 0.016,
      "step": 3740
    },
    {
      "epoch": 3.0,
      "grad_norm": 0.21482929587364197,
      "learning_rate": 0.0,
      "loss": 0.0272,
      "step": 3750
    },
    {
      "epoch": 3.0,
      "eval_loss": 0.02116500400006771,
      "eval_runtime": 152.4388,
      "eval_samples_per_second": 6.56,
      "eval_steps_per_second": 0.82,
      "step": 3750
    }
  ],
  "logging_steps": 10,
  "max_steps": 3750,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 3,
  "save_steps": 100,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 3735047207012352.0,
  "train_batch_size": 8,
  "trial_name": null,
  "trial_params": null
}
