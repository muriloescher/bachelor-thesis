{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 3.0,
  "eval_steps": 50,
  "global_step": 3750,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.008,
      "grad_norm": 201.71827697753906,
      "learning_rate": 1e-05,
      "loss": 2.5602,
      "step": 10
    },
    {
      "epoch": 0.016,
      "grad_norm": 27.747678756713867,
      "learning_rate": 2e-05,
      "loss": 2.4133,
      "step": 20
    },
    {
      "epoch": 0.024,
      "grad_norm": 17.449687957763672,
      "learning_rate": 3e-05,
      "loss": 2.087,
      "step": 30
    },
    {
      "epoch": 0.032,
      "grad_norm": 28.993865966796875,
      "learning_rate": 4e-05,
      "loss": 1.9426,
      "step": 40
    },
    {
      "epoch": 0.04,
      "grad_norm": 13.673271179199219,
      "learning_rate": 5e-05,
      "loss": 1.6507,
      "step": 50
    },
    {
      "epoch": 0.04,
      "eval_loss": 1.2188212871551514,
      "eval_runtime": 20.2323,
      "eval_samples_per_second": 49.426,
      "eval_steps_per_second": 6.178,
      "step": 50
    },
    {
      "epoch": 0.048,
      "grad_norm": 16.218843460083008,
      "learning_rate": 6e-05,
      "loss": 1.3953,
      "step": 60
    },
    {
      "epoch": 0.056,
      "grad_norm": 8.652817726135254,
      "learning_rate": 7e-05,
      "loss": 1.0372,
      "step": 70
    },
    {
      "epoch": 0.064,
      "grad_norm": 32.35573959350586,
      "learning_rate": 8e-05,
      "loss": 0.8537,
      "step": 80
    },
    {
      "epoch": 0.072,
      "grad_norm": 13.366192817687988,
      "learning_rate": 9e-05,
      "loss": 0.6413,
      "step": 90
    },
    {
      "epoch": 0.08,
      "grad_norm": 5.1796441078186035,
      "learning_rate": 0.0001,
      "loss": 0.5787,
      "step": 100
    },
    {
      "epoch": 0.08,
      "eval_loss": 0.35528334975242615,
      "eval_runtime": 20.5601,
      "eval_samples_per_second": 48.638,
      "eval_steps_per_second": 6.08,
      "step": 100
    },
    {
      "epoch": 0.088,
      "grad_norm": 9.811683654785156,
      "learning_rate": 9.972602739726028e-05,
      "loss": 0.5347,
      "step": 110
    },
    {
      "epoch": 0.096,
      "grad_norm": 5.34541654586792,
      "learning_rate": 9.945205479452056e-05,
      "loss": 0.4574,
      "step": 120
    },
    {
      "epoch": 0.104,
      "grad_norm": 5.283333778381348,
      "learning_rate": 9.917808219178082e-05,
      "loss": 0.4237,
      "step": 130
    },
    {
      "epoch": 0.112,
      "grad_norm": 3.355750322341919,
      "learning_rate": 9.89041095890411e-05,
      "loss": 0.3974,
      "step": 140
    },
    {
      "epoch": 0.12,
      "grad_norm": 3.123666524887085,
      "learning_rate": 9.863013698630137e-05,
      "loss": 0.4137,
      "step": 150
    },
    {
      "epoch": 0.12,
      "eval_loss": 0.2789768576622009,
      "eval_runtime": 20.7524,
      "eval_samples_per_second": 48.187,
      "eval_steps_per_second": 6.023,
      "step": 150
    },
    {
      "epoch": 0.128,
      "grad_norm": 3.534550189971924,
      "learning_rate": 9.835616438356165e-05,
      "loss": 0.3358,
      "step": 160
    },
    {
      "epoch": 0.136,
      "grad_norm": 2.5217506885528564,
      "learning_rate": 9.808219178082192e-05,
      "loss": 0.3156,
      "step": 170
    },
    {
      "epoch": 0.144,
      "grad_norm": 3.2975776195526123,
      "learning_rate": 9.78082191780822e-05,
      "loss": 0.341,
      "step": 180
    },
    {
      "epoch": 0.152,
      "grad_norm": 2.5641674995422363,
      "learning_rate": 9.753424657534247e-05,
      "loss": 0.356,
      "step": 190
    },
    {
      "epoch": 0.16,
      "grad_norm": 7.092322826385498,
      "learning_rate": 9.726027397260274e-05,
      "loss": 0.3434,
      "step": 200
    },
    {
      "epoch": 0.16,
      "eval_loss": 0.25677546858787537,
      "eval_runtime": 21.0423,
      "eval_samples_per_second": 47.523,
      "eval_steps_per_second": 5.94,
      "step": 200
    },
    {
      "epoch": 0.168,
      "grad_norm": 1.9008005857467651,
      "learning_rate": 9.698630136986302e-05,
      "loss": 0.3177,
      "step": 210
    },
    {
      "epoch": 0.176,
      "grad_norm": 2.140294313430786,
      "learning_rate": 9.67123287671233e-05,
      "loss": 0.3253,
      "step": 220
    },
    {
      "epoch": 0.184,
      "grad_norm": 3.3215017318725586,
      "learning_rate": 9.643835616438356e-05,
      "loss": 0.3452,
      "step": 230
    },
    {
      "epoch": 0.192,
      "grad_norm": 2.1404237747192383,
      "learning_rate": 9.616438356164384e-05,
      "loss": 0.309,
      "step": 240
    },
    {
      "epoch": 0.2,
      "grad_norm": 1.947688341140747,
      "learning_rate": 9.58904109589041e-05,
      "loss": 0.291,
      "step": 250
    },
    {
      "epoch": 0.2,
      "eval_loss": 0.24170318245887756,
      "eval_runtime": 21.0379,
      "eval_samples_per_second": 47.533,
      "eval_steps_per_second": 5.942,
      "step": 250
    },
    {
      "epoch": 0.208,
      "grad_norm": 2.337775707244873,
      "learning_rate": 9.561643835616438e-05,
      "loss": 0.3034,
      "step": 260
    },
    {
      "epoch": 0.216,
      "grad_norm": 3.745076894760132,
      "learning_rate": 9.534246575342466e-05,
      "loss": 0.274,
      "step": 270
    },
    {
      "epoch": 0.224,
      "grad_norm": 2.6870272159576416,
      "learning_rate": 9.506849315068494e-05,
      "loss": 0.2864,
      "step": 280
    },
    {
      "epoch": 0.232,
      "grad_norm": 1.7296055555343628,
      "learning_rate": 9.47945205479452e-05,
      "loss": 0.2909,
      "step": 290
    },
    {
      "epoch": 0.24,
      "grad_norm": 1.6772637367248535,
      "learning_rate": 9.452054794520548e-05,
      "loss": 0.327,
      "step": 300
    },
    {
      "epoch": 0.24,
      "eval_loss": 0.21583272516727448,
      "eval_runtime": 21.146,
      "eval_samples_per_second": 47.29,
      "eval_steps_per_second": 5.911,
      "step": 300
    },
    {
      "epoch": 0.248,
      "grad_norm": 1.389702558517456,
      "learning_rate": 9.424657534246576e-05,
      "loss": 0.2699,
      "step": 310
    },
    {
      "epoch": 0.256,
      "grad_norm": 6.0771284103393555,
      "learning_rate": 9.397260273972604e-05,
      "loss": 0.2731,
      "step": 320
    },
    {
      "epoch": 0.264,
      "grad_norm": 1.7160284519195557,
      "learning_rate": 9.369863013698632e-05,
      "loss": 0.2535,
      "step": 330
    },
    {
      "epoch": 0.272,
      "grad_norm": 2.2595760822296143,
      "learning_rate": 9.342465753424658e-05,
      "loss": 0.2849,
      "step": 340
    },
    {
      "epoch": 0.28,
      "grad_norm": 1.2874919176101685,
      "learning_rate": 9.315068493150684e-05,
      "loss": 0.2287,
      "step": 350
    },
    {
      "epoch": 0.28,
      "eval_loss": 0.20088675618171692,
      "eval_runtime": 21.1283,
      "eval_samples_per_second": 47.33,
      "eval_steps_per_second": 5.916,
      "step": 350
    },
    {
      "epoch": 0.288,
      "grad_norm": 2.0896687507629395,
      "learning_rate": 9.287671232876712e-05,
      "loss": 0.2487,
      "step": 360
    },
    {
      "epoch": 0.296,
      "grad_norm": 2.8493459224700928,
      "learning_rate": 9.26027397260274e-05,
      "loss": 0.2579,
      "step": 370
    },
    {
      "epoch": 0.304,
      "grad_norm": 1.4294716119766235,
      "learning_rate": 9.232876712328768e-05,
      "loss": 0.2491,
      "step": 380
    },
    {
      "epoch": 0.312,
      "grad_norm": 1.3230592012405396,
      "learning_rate": 9.205479452054796e-05,
      "loss": 0.2622,
      "step": 390
    },
    {
      "epoch": 0.32,
      "grad_norm": 1.7611147165298462,
      "learning_rate": 9.178082191780822e-05,
      "loss": 0.258,
      "step": 400
    },
    {
      "epoch": 0.32,
      "eval_loss": 0.17531676590442657,
      "eval_runtime": 25.6666,
      "eval_samples_per_second": 38.961,
      "eval_steps_per_second": 4.87,
      "step": 400
    },
    {
      "epoch": 0.328,
      "grad_norm": 1.3950996398925781,
      "learning_rate": 9.15068493150685e-05,
      "loss": 0.2331,
      "step": 410
    },
    {
      "epoch": 0.336,
      "grad_norm": 2.775132656097412,
      "learning_rate": 9.123287671232878e-05,
      "loss": 0.2559,
      "step": 420
    },
    {
      "epoch": 0.344,
      "grad_norm": 1.9628080129623413,
      "learning_rate": 9.095890410958905e-05,
      "loss": 0.2345,
      "step": 430
    },
    {
      "epoch": 0.352,
      "grad_norm": 1.4772534370422363,
      "learning_rate": 9.068493150684932e-05,
      "loss": 0.2552,
      "step": 440
    },
    {
      "epoch": 0.36,
      "grad_norm": 1.678432822227478,
      "learning_rate": 9.041095890410958e-05,
      "loss": 0.2426,
      "step": 450
    },
    {
      "epoch": 0.36,
      "eval_loss": 0.17672774195671082,
      "eval_runtime": 25.7399,
      "eval_samples_per_second": 38.85,
      "eval_steps_per_second": 4.856,
      "step": 450
    },
    {
      "epoch": 0.368,
      "grad_norm": 0.7886468768119812,
      "learning_rate": 9.013698630136986e-05,
      "loss": 0.2259,
      "step": 460
    },
    {
      "epoch": 0.376,
      "grad_norm": 2.038827657699585,
      "learning_rate": 8.986301369863014e-05,
      "loss": 0.2352,
      "step": 470
    },
    {
      "epoch": 0.384,
      "grad_norm": 2.0870168209075928,
      "learning_rate": 8.958904109589042e-05,
      "loss": 0.2311,
      "step": 480
    },
    {
      "epoch": 0.392,
      "grad_norm": 1.2024168968200684,
      "learning_rate": 8.93150684931507e-05,
      "loss": 0.2235,
      "step": 490
    },
    {
      "epoch": 0.4,
      "grad_norm": 1.059086799621582,
      "learning_rate": 8.904109589041096e-05,
      "loss": 0.1888,
      "step": 500
    },
    {
      "epoch": 0.4,
      "eval_loss": 0.16110840439796448,
      "eval_runtime": 28.1591,
      "eval_samples_per_second": 35.512,
      "eval_steps_per_second": 4.439,
      "step": 500
    },
    {
      "epoch": 0.408,
      "grad_norm": 1.2582730054855347,
      "learning_rate": 8.876712328767124e-05,
      "loss": 0.2214,
      "step": 510
    },
    {
      "epoch": 0.416,
      "grad_norm": 1.2890596389770508,
      "learning_rate": 8.849315068493151e-05,
      "loss": 0.2271,
      "step": 520
    },
    {
      "epoch": 0.424,
      "grad_norm": 1.61000657081604,
      "learning_rate": 8.821917808219179e-05,
      "loss": 0.1814,
      "step": 530
    },
    {
      "epoch": 0.432,
      "grad_norm": 1.2985894680023193,
      "learning_rate": 8.794520547945207e-05,
      "loss": 0.2392,
      "step": 540
    },
    {
      "epoch": 0.44,
      "grad_norm": 1.1427769660949707,
      "learning_rate": 8.767123287671233e-05,
      "loss": 0.2356,
      "step": 550
    },
    {
      "epoch": 0.44,
      "eval_loss": 0.14577743411064148,
      "eval_runtime": 27.6645,
      "eval_samples_per_second": 36.147,
      "eval_steps_per_second": 4.518,
      "step": 550
    },
    {
      "epoch": 0.448,
      "grad_norm": 1.212315559387207,
      "learning_rate": 8.73972602739726e-05,
      "loss": 0.2147,
      "step": 560
    },
    {
      "epoch": 0.456,
      "grad_norm": 1.121647596359253,
      "learning_rate": 8.712328767123288e-05,
      "loss": 0.2409,
      "step": 570
    },
    {
      "epoch": 0.464,
      "grad_norm": 0.964879035949707,
      "learning_rate": 8.684931506849315e-05,
      "loss": 0.1995,
      "step": 580
    },
    {
      "epoch": 0.472,
      "grad_norm": 1.3119115829467773,
      "learning_rate": 8.657534246575343e-05,
      "loss": 0.2455,
      "step": 590
    },
    {
      "epoch": 0.48,
      "grad_norm": 1.830560326576233,
      "learning_rate": 8.630136986301371e-05,
      "loss": 0.2062,
      "step": 600
    },
    {
      "epoch": 0.48,
      "eval_loss": 0.12863479554653168,
      "eval_runtime": 28.3161,
      "eval_samples_per_second": 35.316,
      "eval_steps_per_second": 4.414,
      "step": 600
    },
    {
      "epoch": 0.488,
      "grad_norm": 1.0610815286636353,
      "learning_rate": 8.602739726027397e-05,
      "loss": 0.1728,
      "step": 610
    },
    {
      "epoch": 0.496,
      "grad_norm": 1.7058748006820679,
      "learning_rate": 8.575342465753425e-05,
      "loss": 0.2063,
      "step": 620
    },
    {
      "epoch": 0.504,
      "grad_norm": 1.458940863609314,
      "learning_rate": 8.547945205479453e-05,
      "loss": 0.1778,
      "step": 630
    },
    {
      "epoch": 0.512,
      "grad_norm": 0.5515244603157043,
      "learning_rate": 8.520547945205481e-05,
      "loss": 0.1688,
      "step": 640
    },
    {
      "epoch": 0.52,
      "grad_norm": 1.1650457382202148,
      "learning_rate": 8.493150684931507e-05,
      "loss": 0.1863,
      "step": 650
    },
    {
      "epoch": 0.52,
      "eval_loss": 0.1468365639448166,
      "eval_runtime": 28.2198,
      "eval_samples_per_second": 35.436,
      "eval_steps_per_second": 4.43,
      "step": 650
    },
    {
      "epoch": 0.528,
      "grad_norm": 1.9412143230438232,
      "learning_rate": 8.465753424657534e-05,
      "loss": 0.2135,
      "step": 660
    },
    {
      "epoch": 0.536,
      "grad_norm": 0.9830278158187866,
      "learning_rate": 8.438356164383561e-05,
      "loss": 0.156,
      "step": 670
    },
    {
      "epoch": 0.544,
      "grad_norm": 1.5893644094467163,
      "learning_rate": 8.410958904109589e-05,
      "loss": 0.1931,
      "step": 680
    },
    {
      "epoch": 0.552,
      "grad_norm": 1.1066975593566895,
      "learning_rate": 8.383561643835617e-05,
      "loss": 0.205,
      "step": 690
    },
    {
      "epoch": 0.56,
      "grad_norm": 1.6480647325515747,
      "learning_rate": 8.356164383561645e-05,
      "loss": 0.1768,
      "step": 700
    },
    {
      "epoch": 0.56,
      "eval_loss": 0.12233009189367294,
      "eval_runtime": 28.1925,
      "eval_samples_per_second": 35.47,
      "eval_steps_per_second": 4.434,
      "step": 700
    },
    {
      "epoch": 0.568,
      "grad_norm": 1.5358270406723022,
      "learning_rate": 8.328767123287671e-05,
      "loss": 0.1841,
      "step": 710
    },
    {
      "epoch": 0.576,
      "grad_norm": 0.7720862030982971,
      "learning_rate": 8.301369863013699e-05,
      "loss": 0.1562,
      "step": 720
    },
    {
      "epoch": 0.584,
      "grad_norm": 1.458979606628418,
      "learning_rate": 8.273972602739727e-05,
      "loss": 0.1503,
      "step": 730
    },
    {
      "epoch": 0.592,
      "grad_norm": 1.5727767944335938,
      "learning_rate": 8.246575342465755e-05,
      "loss": 0.1911,
      "step": 740
    },
    {
      "epoch": 0.6,
      "grad_norm": 1.6614990234375,
      "learning_rate": 8.219178082191781e-05,
      "loss": 0.1544,
      "step": 750
    },
    {
      "epoch": 0.6,
      "eval_loss": 0.1328343152999878,
      "eval_runtime": 28.1339,
      "eval_samples_per_second": 35.544,
      "eval_steps_per_second": 4.443,
      "step": 750
    },
    {
      "epoch": 0.608,
      "grad_norm": 1.1304187774658203,
      "learning_rate": 8.191780821917809e-05,
      "loss": 0.1423,
      "step": 760
    },
    {
      "epoch": 0.616,
      "grad_norm": 1.4971811771392822,
      "learning_rate": 8.164383561643835e-05,
      "loss": 0.1624,
      "step": 770
    },
    {
      "epoch": 0.624,
      "grad_norm": 0.9394375681877136,
      "learning_rate": 8.136986301369863e-05,
      "loss": 0.1691,
      "step": 780
    },
    {
      "epoch": 0.632,
      "grad_norm": 1.147831916809082,
      "learning_rate": 8.109589041095891e-05,
      "loss": 0.1697,
      "step": 790
    },
    {
      "epoch": 0.64,
      "grad_norm": 1.638273000717163,
      "learning_rate": 8.082191780821919e-05,
      "loss": 0.1804,
      "step": 800
    },
    {
      "epoch": 0.64,
      "eval_loss": 0.12847284972667694,
      "eval_runtime": 28.1962,
      "eval_samples_per_second": 35.466,
      "eval_steps_per_second": 4.433,
      "step": 800
    },
    {
      "epoch": 0.648,
      "grad_norm": 1.2507622241973877,
      "learning_rate": 8.054794520547946e-05,
      "loss": 0.1788,
      "step": 810
    },
    {
      "epoch": 0.656,
      "grad_norm": 1.3187079429626465,
      "learning_rate": 8.027397260273973e-05,
      "loss": 0.1878,
      "step": 820
    },
    {
      "epoch": 0.664,
      "grad_norm": 0.565312922000885,
      "learning_rate": 8e-05,
      "loss": 0.1558,
      "step": 830
    },
    {
      "epoch": 0.672,
      "grad_norm": 1.6613366603851318,
      "learning_rate": 7.972602739726027e-05,
      "loss": 0.1815,
      "step": 840
    },
    {
      "epoch": 0.68,
      "grad_norm": 1.7992054224014282,
      "learning_rate": 7.945205479452055e-05,
      "loss": 0.1785,
      "step": 850
    },
    {
      "epoch": 0.68,
      "eval_loss": 0.10924133658409119,
      "eval_runtime": 28.3151,
      "eval_samples_per_second": 35.317,
      "eval_steps_per_second": 4.415,
      "step": 850
    },
    {
      "epoch": 0.688,
      "grad_norm": 3.6420319080352783,
      "learning_rate": 7.917808219178083e-05,
      "loss": 0.1616,
      "step": 860
    },
    {
      "epoch": 0.696,
      "grad_norm": 1.0487664937973022,
      "learning_rate": 7.890410958904109e-05,
      "loss": 0.181,
      "step": 870
    },
    {
      "epoch": 0.704,
      "grad_norm": 2.476149797439575,
      "learning_rate": 7.863013698630137e-05,
      "loss": 0.1528,
      "step": 880
    },
    {
      "epoch": 0.712,
      "grad_norm": 1.3406480550765991,
      "learning_rate": 7.835616438356165e-05,
      "loss": 0.1315,
      "step": 890
    },
    {
      "epoch": 0.72,
      "grad_norm": 0.8249708414077759,
      "learning_rate": 7.808219178082192e-05,
      "loss": 0.1278,
      "step": 900
    },
    {
      "epoch": 0.72,
      "eval_loss": 0.11543167382478714,
      "eval_runtime": 28.3339,
      "eval_samples_per_second": 35.293,
      "eval_steps_per_second": 4.412,
      "step": 900
    },
    {
      "epoch": 0.728,
      "grad_norm": 1.5009112358093262,
      "learning_rate": 7.78082191780822e-05,
      "loss": 0.154,
      "step": 910
    },
    {
      "epoch": 0.736,
      "grad_norm": 1.2453393936157227,
      "learning_rate": 7.753424657534247e-05,
      "loss": 0.1344,
      "step": 920
    },
    {
      "epoch": 0.744,
      "grad_norm": 1.0573465824127197,
      "learning_rate": 7.726027397260274e-05,
      "loss": 0.1474,
      "step": 930
    },
    {
      "epoch": 0.752,
      "grad_norm": 1.1966944932937622,
      "learning_rate": 7.698630136986301e-05,
      "loss": 0.1413,
      "step": 940
    },
    {
      "epoch": 0.76,
      "grad_norm": 0.7933737635612488,
      "learning_rate": 7.671232876712329e-05,
      "loss": 0.1378,
      "step": 950
    },
    {
      "epoch": 0.76,
      "eval_loss": 0.10939634591341019,
      "eval_runtime": 28.2161,
      "eval_samples_per_second": 35.441,
      "eval_steps_per_second": 4.43,
      "step": 950
    },
    {
      "epoch": 0.768,
      "grad_norm": 1.1400856971740723,
      "learning_rate": 7.643835616438356e-05,
      "loss": 0.175,
      "step": 960
    },
    {
      "epoch": 0.776,
      "grad_norm": 1.77446448802948,
      "learning_rate": 7.616438356164384e-05,
      "loss": 0.161,
      "step": 970
    },
    {
      "epoch": 0.784,
      "grad_norm": 1.4092737436294556,
      "learning_rate": 7.589041095890411e-05,
      "loss": 0.1601,
      "step": 980
    },
    {
      "epoch": 0.792,
      "grad_norm": 1.17460036277771,
      "learning_rate": 7.561643835616439e-05,
      "loss": 0.1579,
      "step": 990
    },
    {
      "epoch": 0.8,
      "grad_norm": 1.3089299201965332,
      "learning_rate": 7.534246575342466e-05,
      "loss": 0.1282,
      "step": 1000
    },
    {
      "epoch": 0.8,
      "eval_loss": 0.1042303591966629,
      "eval_runtime": 28.1481,
      "eval_samples_per_second": 35.526,
      "eval_steps_per_second": 4.441,
      "step": 1000
    },
    {
      "epoch": 0.808,
      "grad_norm": 0.7800904512405396,
      "learning_rate": 7.506849315068494e-05,
      "loss": 0.1404,
      "step": 1010
    },
    {
      "epoch": 0.816,
      "grad_norm": 1.6856608390808105,
      "learning_rate": 7.479452054794522e-05,
      "loss": 0.1454,
      "step": 1020
    },
    {
      "epoch": 0.824,
      "grad_norm": 1.8679176568984985,
      "learning_rate": 7.452054794520548e-05,
      "loss": 0.1531,
      "step": 1030
    },
    {
      "epoch": 0.832,
      "grad_norm": 1.4522955417633057,
      "learning_rate": 7.424657534246575e-05,
      "loss": 0.1648,
      "step": 1040
    },
    {
      "epoch": 0.84,
      "grad_norm": 1.8483304977416992,
      "learning_rate": 7.397260273972603e-05,
      "loss": 0.1478,
      "step": 1050
    },
    {
      "epoch": 0.84,
      "eval_loss": 0.10973475873470306,
      "eval_runtime": 28.1688,
      "eval_samples_per_second": 35.5,
      "eval_steps_per_second": 4.438,
      "step": 1050
    },
    {
      "epoch": 0.848,
      "grad_norm": 1.4760934114456177,
      "learning_rate": 7.36986301369863e-05,
      "loss": 0.1368,
      "step": 1060
    },
    {
      "epoch": 0.856,
      "grad_norm": 1.266526222229004,
      "learning_rate": 7.342465753424658e-05,
      "loss": 0.1665,
      "step": 1070
    },
    {
      "epoch": 0.864,
      "grad_norm": 1.3288697004318237,
      "learning_rate": 7.315068493150685e-05,
      "loss": 0.1249,
      "step": 1080
    },
    {
      "epoch": 0.872,
      "grad_norm": 1.0517661571502686,
      "learning_rate": 7.287671232876712e-05,
      "loss": 0.1538,
      "step": 1090
    },
    {
      "epoch": 0.88,
      "grad_norm": 1.3312914371490479,
      "learning_rate": 7.26027397260274e-05,
      "loss": 0.1291,
      "step": 1100
    },
    {
      "epoch": 0.88,
      "eval_loss": 0.10931483656167984,
      "eval_runtime": 28.0886,
      "eval_samples_per_second": 35.602,
      "eval_steps_per_second": 4.45,
      "step": 1100
    },
    {
      "epoch": 0.888,
      "grad_norm": 1.3791123628616333,
      "learning_rate": 7.232876712328768e-05,
      "loss": 0.1449,
      "step": 1110
    },
    {
      "epoch": 0.896,
      "grad_norm": 2.0700652599334717,
      "learning_rate": 7.205479452054796e-05,
      "loss": 0.1418,
      "step": 1120
    },
    {
      "epoch": 0.904,
      "grad_norm": 1.180432915687561,
      "learning_rate": 7.178082191780822e-05,
      "loss": 0.1245,
      "step": 1130
    },
    {
      "epoch": 0.912,
      "grad_norm": 1.4075875282287598,
      "learning_rate": 7.150684931506849e-05,
      "loss": 0.1469,
      "step": 1140
    },
    {
      "epoch": 0.92,
      "grad_norm": 1.0383448600769043,
      "learning_rate": 7.123287671232876e-05,
      "loss": 0.1252,
      "step": 1150
    },
    {
      "epoch": 0.92,
      "eval_loss": 0.09579616039991379,
      "eval_runtime": 28.1554,
      "eval_samples_per_second": 35.517,
      "eval_steps_per_second": 4.44,
      "step": 1150
    },
    {
      "epoch": 0.928,
      "grad_norm": 0.9432961940765381,
      "learning_rate": 7.095890410958904e-05,
      "loss": 0.1423,
      "step": 1160
    },
    {
      "epoch": 0.936,
      "grad_norm": 0.7254536151885986,
      "learning_rate": 7.068493150684932e-05,
      "loss": 0.1476,
      "step": 1170
    },
    {
      "epoch": 0.944,
      "grad_norm": 0.7283443212509155,
      "learning_rate": 7.04109589041096e-05,
      "loss": 0.1332,
      "step": 1180
    },
    {
      "epoch": 0.952,
      "grad_norm": 1.9813976287841797,
      "learning_rate": 7.013698630136986e-05,
      "loss": 0.1328,
      "step": 1190
    },
    {
      "epoch": 0.96,
      "grad_norm": 0.656124472618103,
      "learning_rate": 6.986301369863014e-05,
      "loss": 0.1264,
      "step": 1200
    },
    {
      "epoch": 0.96,
      "eval_loss": 0.1067185029387474,
      "eval_runtime": 28.1658,
      "eval_samples_per_second": 35.504,
      "eval_steps_per_second": 4.438,
      "step": 1200
    },
    {
      "epoch": 0.968,
      "grad_norm": 1.1268062591552734,
      "learning_rate": 6.958904109589042e-05,
      "loss": 0.116,
      "step": 1210
    },
    {
      "epoch": 0.976,
      "grad_norm": 1.2000283002853394,
      "learning_rate": 6.93150684931507e-05,
      "loss": 0.1212,
      "step": 1220
    },
    {
      "epoch": 0.984,
      "grad_norm": 0.800096869468689,
      "learning_rate": 6.904109589041097e-05,
      "loss": 0.1291,
      "step": 1230
    },
    {
      "epoch": 0.992,
      "grad_norm": 1.3615225553512573,
      "learning_rate": 6.876712328767124e-05,
      "loss": 0.1383,
      "step": 1240
    },
    {
      "epoch": 1.0,
      "grad_norm": 1.285873532295227,
      "learning_rate": 6.84931506849315e-05,
      "loss": 0.1229,
      "step": 1250
    },
    {
      "epoch": 1.0,
      "eval_loss": 0.09595294296741486,
      "eval_runtime": 28.1776,
      "eval_samples_per_second": 35.489,
      "eval_steps_per_second": 4.436,
      "step": 1250
    },
    {
      "epoch": 1.008,
      "grad_norm": 0.8499026298522949,
      "learning_rate": 6.821917808219178e-05,
      "loss": 0.1331,
      "step": 1260
    },
    {
      "epoch": 1.016,
      "grad_norm": 1.0801547765731812,
      "learning_rate": 6.794520547945206e-05,
      "loss": 0.1178,
      "step": 1270
    },
    {
      "epoch": 1.024,
      "grad_norm": 0.8671740293502808,
      "learning_rate": 6.767123287671234e-05,
      "loss": 0.1132,
      "step": 1280
    },
    {
      "epoch": 1.032,
      "grad_norm": 0.8647852540016174,
      "learning_rate": 6.73972602739726e-05,
      "loss": 0.097,
      "step": 1290
    },
    {
      "epoch": 1.04,
      "grad_norm": 1.0874439477920532,
      "learning_rate": 6.712328767123288e-05,
      "loss": 0.1379,
      "step": 1300
    },
    {
      "epoch": 1.04,
      "eval_loss": 0.09094467759132385,
      "eval_runtime": 28.1878,
      "eval_samples_per_second": 35.476,
      "eval_steps_per_second": 4.435,
      "step": 1300
    },
    {
      "epoch": 1.048,
      "grad_norm": 0.841215968132019,
      "learning_rate": 6.684931506849316e-05,
      "loss": 0.0964,
      "step": 1310
    },
    {
      "epoch": 1.056,
      "grad_norm": 12.242186546325684,
      "learning_rate": 6.657534246575343e-05,
      "loss": 0.1317,
      "step": 1320
    },
    {
      "epoch": 1.064,
      "grad_norm": 0.8645535707473755,
      "learning_rate": 6.630136986301371e-05,
      "loss": 0.1301,
      "step": 1330
    },
    {
      "epoch": 1.072,
      "grad_norm": 1.1869678497314453,
      "learning_rate": 6.602739726027398e-05,
      "loss": 0.1047,
      "step": 1340
    },
    {
      "epoch": 1.08,
      "grad_norm": 1.9911541938781738,
      "learning_rate": 6.575342465753424e-05,
      "loss": 0.1346,
      "step": 1350
    },
    {
      "epoch": 1.08,
      "eval_loss": 0.08950575441122055,
      "eval_runtime": 28.207,
      "eval_samples_per_second": 35.452,
      "eval_steps_per_second": 4.432,
      "step": 1350
    },
    {
      "epoch": 1.088,
      "grad_norm": 1.0525051355361938,
      "learning_rate": 6.547945205479452e-05,
      "loss": 0.1076,
      "step": 1360
    },
    {
      "epoch": 1.096,
      "grad_norm": 0.9754319787025452,
      "learning_rate": 6.52054794520548e-05,
      "loss": 0.1156,
      "step": 1370
    },
    {
      "epoch": 1.104,
      "grad_norm": 0.6564377546310425,
      "learning_rate": 6.493150684931507e-05,
      "loss": 0.1287,
      "step": 1380
    },
    {
      "epoch": 1.112,
      "grad_norm": 1.6018601655960083,
      "learning_rate": 6.465753424657535e-05,
      "loss": 0.1301,
      "step": 1390
    },
    {
      "epoch": 1.12,
      "grad_norm": 1.6440585851669312,
      "learning_rate": 6.438356164383562e-05,
      "loss": 0.0984,
      "step": 1400
    },
    {
      "epoch": 1.12,
      "eval_loss": 0.08566618710756302,
      "eval_runtime": 28.212,
      "eval_samples_per_second": 35.446,
      "eval_steps_per_second": 4.431,
      "step": 1400
    },
    {
      "epoch": 1.1280000000000001,
      "grad_norm": 1.2645565271377563,
      "learning_rate": 6.41095890410959e-05,
      "loss": 0.1154,
      "step": 1410
    },
    {
      "epoch": 1.1360000000000001,
      "grad_norm": 0.9855694770812988,
      "learning_rate": 6.383561643835617e-05,
      "loss": 0.1201,
      "step": 1420
    },
    {
      "epoch": 1.144,
      "grad_norm": 0.625691294670105,
      "learning_rate": 6.356164383561645e-05,
      "loss": 0.0779,
      "step": 1430
    },
    {
      "epoch": 1.152,
      "grad_norm": 1.1018543243408203,
      "learning_rate": 6.328767123287671e-05,
      "loss": 0.1131,
      "step": 1440
    },
    {
      "epoch": 1.16,
      "grad_norm": 0.6576698422431946,
      "learning_rate": 6.301369863013699e-05,
      "loss": 0.1281,
      "step": 1450
    },
    {
      "epoch": 1.16,
      "eval_loss": 0.10558993369340897,
      "eval_runtime": 28.1726,
      "eval_samples_per_second": 35.496,
      "eval_steps_per_second": 4.437,
      "step": 1450
    },
    {
      "epoch": 1.168,
      "grad_norm": 1.5969315767288208,
      "learning_rate": 6.273972602739726e-05,
      "loss": 0.1314,
      "step": 1460
    },
    {
      "epoch": 1.176,
      "grad_norm": 1.2515983581542969,
      "learning_rate": 6.246575342465753e-05,
      "loss": 0.1001,
      "step": 1470
    },
    {
      "epoch": 1.184,
      "grad_norm": 0.9697507619857788,
      "learning_rate": 6.219178082191781e-05,
      "loss": 0.0894,
      "step": 1480
    },
    {
      "epoch": 1.192,
      "grad_norm": 0.975051999092102,
      "learning_rate": 6.191780821917809e-05,
      "loss": 0.1059,
      "step": 1490
    },
    {
      "epoch": 1.2,
      "grad_norm": 1.318050742149353,
      "learning_rate": 6.164383561643835e-05,
      "loss": 0.1229,
      "step": 1500
    },
    {
      "epoch": 1.2,
      "eval_loss": 0.09164740145206451,
      "eval_runtime": 28.1664,
      "eval_samples_per_second": 35.503,
      "eval_steps_per_second": 4.438,
      "step": 1500
    },
    {
      "epoch": 1.208,
      "grad_norm": 1.434568166732788,
      "learning_rate": 6.136986301369863e-05,
      "loss": 0.1157,
      "step": 1510
    },
    {
      "epoch": 1.216,
      "grad_norm": 1.322519063949585,
      "learning_rate": 6.109589041095891e-05,
      "loss": 0.1238,
      "step": 1520
    },
    {
      "epoch": 1.224,
      "grad_norm": 0.43235471844673157,
      "learning_rate": 6.082191780821919e-05,
      "loss": 0.1271,
      "step": 1530
    },
    {
      "epoch": 1.232,
      "grad_norm": 0.8355951905250549,
      "learning_rate": 6.054794520547945e-05,
      "loss": 0.0869,
      "step": 1540
    },
    {
      "epoch": 1.24,
      "grad_norm": 1.48939847946167,
      "learning_rate": 6.0273972602739724e-05,
      "loss": 0.132,
      "step": 1550
    },
    {
      "epoch": 1.24,
      "eval_loss": 0.09991570562124252,
      "eval_runtime": 28.1419,
      "eval_samples_per_second": 35.534,
      "eval_steps_per_second": 4.442,
      "step": 1550
    },
    {
      "epoch": 1.248,
      "grad_norm": 1.582044005393982,
      "learning_rate": 6e-05,
      "loss": 0.1016,
      "step": 1560
    },
    {
      "epoch": 1.256,
      "grad_norm": 1.2242417335510254,
      "learning_rate": 5.972602739726027e-05,
      "loss": 0.1073,
      "step": 1570
    },
    {
      "epoch": 1.264,
      "grad_norm": 1.7315982580184937,
      "learning_rate": 5.945205479452055e-05,
      "loss": 0.108,
      "step": 1580
    },
    {
      "epoch": 1.272,
      "grad_norm": 1.1078495979309082,
      "learning_rate": 5.917808219178083e-05,
      "loss": 0.1129,
      "step": 1590
    },
    {
      "epoch": 1.28,
      "grad_norm": 0.9154053926467896,
      "learning_rate": 5.89041095890411e-05,
      "loss": 0.1035,
      "step": 1600
    },
    {
      "epoch": 1.28,
      "eval_loss": 0.08872752636671066,
      "eval_runtime": 28.1723,
      "eval_samples_per_second": 35.496,
      "eval_steps_per_second": 4.437,
      "step": 1600
    },
    {
      "epoch": 1.288,
      "grad_norm": 1.090798020362854,
      "learning_rate": 5.863013698630138e-05,
      "loss": 0.1172,
      "step": 1610
    },
    {
      "epoch": 1.296,
      "grad_norm": 0.8581380844116211,
      "learning_rate": 5.835616438356165e-05,
      "loss": 0.1035,
      "step": 1620
    },
    {
      "epoch": 1.304,
      "grad_norm": 1.7718281745910645,
      "learning_rate": 5.808219178082191e-05,
      "loss": 0.0917,
      "step": 1630
    },
    {
      "epoch": 1.312,
      "grad_norm": 0.7911683320999146,
      "learning_rate": 5.780821917808219e-05,
      "loss": 0.0943,
      "step": 1640
    },
    {
      "epoch": 1.32,
      "grad_norm": 1.7801333665847778,
      "learning_rate": 5.753424657534247e-05,
      "loss": 0.1631,
      "step": 1650
    },
    {
      "epoch": 1.32,
      "eval_loss": 0.07930377125740051,
      "eval_runtime": 28.1907,
      "eval_samples_per_second": 35.473,
      "eval_steps_per_second": 4.434,
      "step": 1650
    },
    {
      "epoch": 1.328,
      "grad_norm": 26.182687759399414,
      "learning_rate": 5.726027397260274e-05,
      "loss": 0.1119,
      "step": 1660
    },
    {
      "epoch": 1.336,
      "grad_norm": 0.7014349699020386,
      "learning_rate": 5.698630136986302e-05,
      "loss": 0.0895,
      "step": 1670
    },
    {
      "epoch": 1.3439999999999999,
      "grad_norm": 1.2478080987930298,
      "learning_rate": 5.671232876712329e-05,
      "loss": 0.1049,
      "step": 1680
    },
    {
      "epoch": 1.3519999999999999,
      "grad_norm": 1.5312501192092896,
      "learning_rate": 5.643835616438357e-05,
      "loss": 0.0843,
      "step": 1690
    },
    {
      "epoch": 1.3599999999999999,
      "grad_norm": 1.399295449256897,
      "learning_rate": 5.616438356164384e-05,
      "loss": 0.1259,
      "step": 1700
    },
    {
      "epoch": 1.3599999999999999,
      "eval_loss": 0.09713178873062134,
      "eval_runtime": 28.1766,
      "eval_samples_per_second": 35.49,
      "eval_steps_per_second": 4.436,
      "step": 1700
    },
    {
      "epoch": 1.3679999999999999,
      "grad_norm": 0.4575923979282379,
      "learning_rate": 5.5890410958904116e-05,
      "loss": 0.0657,
      "step": 1710
    },
    {
      "epoch": 1.376,
      "grad_norm": 1.0326274633407593,
      "learning_rate": 5.5616438356164394e-05,
      "loss": 0.1019,
      "step": 1720
    },
    {
      "epoch": 1.384,
      "grad_norm": 1.7475346326828003,
      "learning_rate": 5.534246575342466e-05,
      "loss": 0.1021,
      "step": 1730
    },
    {
      "epoch": 1.392,
      "grad_norm": 0.8315441012382507,
      "learning_rate": 5.506849315068493e-05,
      "loss": 0.1159,
      "step": 1740
    },
    {
      "epoch": 1.4,
      "grad_norm": 0.8041362166404724,
      "learning_rate": 5.479452054794521e-05,
      "loss": 0.1076,
      "step": 1750
    },
    {
      "epoch": 1.4,
      "eval_loss": 0.0796314924955368,
      "eval_runtime": 28.237,
      "eval_samples_per_second": 35.415,
      "eval_steps_per_second": 4.427,
      "step": 1750
    },
    {
      "epoch": 1.408,
      "grad_norm": 0.5496647953987122,
      "learning_rate": 5.452054794520548e-05,
      "loss": 0.0987,
      "step": 1760
    },
    {
      "epoch": 1.416,
      "grad_norm": 1.0602785348892212,
      "learning_rate": 5.4246575342465756e-05,
      "loss": 0.0872,
      "step": 1770
    },
    {
      "epoch": 1.424,
      "grad_norm": 1.6297566890716553,
      "learning_rate": 5.397260273972603e-05,
      "loss": 0.0924,
      "step": 1780
    },
    {
      "epoch": 1.432,
      "grad_norm": 2.6610796451568604,
      "learning_rate": 5.3698630136986305e-05,
      "loss": 0.0861,
      "step": 1790
    },
    {
      "epoch": 1.44,
      "grad_norm": 0.8362051844596863,
      "learning_rate": 5.342465753424658e-05,
      "loss": 0.0783,
      "step": 1800
    },
    {
      "epoch": 1.44,
      "eval_loss": 0.08323980122804642,
      "eval_runtime": 28.1803,
      "eval_samples_per_second": 35.486,
      "eval_steps_per_second": 4.436,
      "step": 1800
    },
    {
      "epoch": 1.448,
      "grad_norm": 1.3186795711517334,
      "learning_rate": 5.3150684931506854e-05,
      "loss": 0.1165,
      "step": 1810
    },
    {
      "epoch": 1.456,
      "grad_norm": 0.9515243768692017,
      "learning_rate": 5.287671232876713e-05,
      "loss": 0.1074,
      "step": 1820
    },
    {
      "epoch": 1.464,
      "grad_norm": 1.0222084522247314,
      "learning_rate": 5.2602739726027396e-05,
      "loss": 0.0973,
      "step": 1830
    },
    {
      "epoch": 1.472,
      "grad_norm": 0.9185013771057129,
      "learning_rate": 5.232876712328767e-05,
      "loss": 0.0844,
      "step": 1840
    },
    {
      "epoch": 1.48,
      "grad_norm": 0.5027890205383301,
      "learning_rate": 5.2054794520547945e-05,
      "loss": 0.0885,
      "step": 1850
    },
    {
      "epoch": 1.48,
      "eval_loss": 0.08465497195720673,
      "eval_runtime": 28.173,
      "eval_samples_per_second": 35.495,
      "eval_steps_per_second": 4.437,
      "step": 1850
    },
    {
      "epoch": 1.488,
      "grad_norm": 1.0625015497207642,
      "learning_rate": 5.178082191780822e-05,
      "loss": 0.0753,
      "step": 1860
    },
    {
      "epoch": 1.496,
      "grad_norm": 1.1282418966293335,
      "learning_rate": 5.1506849315068494e-05,
      "loss": 0.1179,
      "step": 1870
    },
    {
      "epoch": 1.504,
      "grad_norm": 1.7546112537384033,
      "learning_rate": 5.123287671232877e-05,
      "loss": 0.1097,
      "step": 1880
    },
    {
      "epoch": 1.512,
      "grad_norm": 1.2686495780944824,
      "learning_rate": 5.095890410958904e-05,
      "loss": 0.0664,
      "step": 1890
    },
    {
      "epoch": 1.52,
      "grad_norm": 0.721281886100769,
      "learning_rate": 5.068493150684932e-05,
      "loss": 0.1109,
      "step": 1900
    },
    {
      "epoch": 1.52,
      "eval_loss": 0.07848089188337326,
      "eval_runtime": 28.0713,
      "eval_samples_per_second": 35.624,
      "eval_steps_per_second": 4.453,
      "step": 1900
    },
    {
      "epoch": 1.528,
      "grad_norm": 0.9931783080101013,
      "learning_rate": 5.041095890410959e-05,
      "loss": 0.0827,
      "step": 1910
    },
    {
      "epoch": 1.536,
      "grad_norm": 0.8816090226173401,
      "learning_rate": 5.013698630136987e-05,
      "loss": 0.092,
      "step": 1920
    },
    {
      "epoch": 1.544,
      "grad_norm": 1.4330508708953857,
      "learning_rate": 4.986301369863014e-05,
      "loss": 0.091,
      "step": 1930
    },
    {
      "epoch": 1.552,
      "grad_norm": 0.7035465836524963,
      "learning_rate": 4.958904109589041e-05,
      "loss": 0.0797,
      "step": 1940
    },
    {
      "epoch": 1.56,
      "grad_norm": 0.6271556615829468,
      "learning_rate": 4.9315068493150684e-05,
      "loss": 0.0858,
      "step": 1950
    },
    {
      "epoch": 1.56,
      "eval_loss": 0.08379055559635162,
      "eval_runtime": 21.0949,
      "eval_samples_per_second": 47.405,
      "eval_steps_per_second": 5.926,
      "step": 1950
    },
    {
      "epoch": 1.568,
      "grad_norm": 0.8256680965423584,
      "learning_rate": 4.904109589041096e-05,
      "loss": 0.0844,
      "step": 1960
    },
    {
      "epoch": 1.576,
      "grad_norm": 1.1457782983779907,
      "learning_rate": 4.876712328767123e-05,
      "loss": 0.0761,
      "step": 1970
    },
    {
      "epoch": 1.584,
      "grad_norm": 1.077720284461975,
      "learning_rate": 4.849315068493151e-05,
      "loss": 0.0631,
      "step": 1980
    },
    {
      "epoch": 1.592,
      "grad_norm": 1.009195327758789,
      "learning_rate": 4.821917808219178e-05,
      "loss": 0.0862,
      "step": 1990
    },
    {
      "epoch": 1.6,
      "grad_norm": 0.6677879691123962,
      "learning_rate": 4.794520547945205e-05,
      "loss": 0.0761,
      "step": 2000
    },
    {
      "epoch": 1.6,
      "eval_loss": 0.08538015931844711,
      "eval_runtime": 20.7868,
      "eval_samples_per_second": 48.107,
      "eval_steps_per_second": 6.013,
      "step": 2000
    },
    {
      "epoch": 1.608,
      "grad_norm": 1.0143795013427734,
      "learning_rate": 4.767123287671233e-05,
      "loss": 0.0808,
      "step": 2010
    },
    {
      "epoch": 1.616,
      "grad_norm": 1.2311840057373047,
      "learning_rate": 4.73972602739726e-05,
      "loss": 0.0841,
      "step": 2020
    },
    {
      "epoch": 1.624,
      "grad_norm": 1.0351908206939697,
      "learning_rate": 4.712328767123288e-05,
      "loss": 0.1024,
      "step": 2030
    },
    {
      "epoch": 1.6320000000000001,
      "grad_norm": 0.6365451812744141,
      "learning_rate": 4.684931506849316e-05,
      "loss": 0.0785,
      "step": 2040
    },
    {
      "epoch": 1.6400000000000001,
      "grad_norm": 0.7404559254646301,
      "learning_rate": 4.657534246575342e-05,
      "loss": 0.0889,
      "step": 2050
    },
    {
      "epoch": 1.6400000000000001,
      "eval_loss": 0.07405295968055725,
      "eval_runtime": 21.7042,
      "eval_samples_per_second": 46.074,
      "eval_steps_per_second": 5.759,
      "step": 2050
    },
    {
      "epoch": 1.6480000000000001,
      "grad_norm": 0.8060479164123535,
      "learning_rate": 4.63013698630137e-05,
      "loss": 0.0888,
      "step": 2060
    },
    {
      "epoch": 1.6560000000000001,
      "grad_norm": 0.8980129361152649,
      "learning_rate": 4.602739726027398e-05,
      "loss": 0.0711,
      "step": 2070
    },
    {
      "epoch": 1.6640000000000001,
      "grad_norm": 0.7626920938491821,
      "learning_rate": 4.575342465753425e-05,
      "loss": 0.0855,
      "step": 2080
    },
    {
      "epoch": 1.6720000000000002,
      "grad_norm": 1.120815634727478,
      "learning_rate": 4.547945205479453e-05,
      "loss": 0.09,
      "step": 2090
    },
    {
      "epoch": 1.6800000000000002,
      "grad_norm": 0.7735428810119629,
      "learning_rate": 4.520547945205479e-05,
      "loss": 0.0581,
      "step": 2100
    },
    {
      "epoch": 1.6800000000000002,
      "eval_loss": 0.0734989196062088,
      "eval_runtime": 28.3778,
      "eval_samples_per_second": 35.239,
      "eval_steps_per_second": 4.405,
      "step": 2100
    },
    {
      "epoch": 1.688,
      "grad_norm": 1.2723965644836426,
      "learning_rate": 4.493150684931507e-05,
      "loss": 0.0917,
      "step": 2110
    },
    {
      "epoch": 1.696,
      "grad_norm": 2.1511800289154053,
      "learning_rate": 4.465753424657535e-05,
      "loss": 0.0646,
      "step": 2120
    },
    {
      "epoch": 1.704,
      "grad_norm": 0.6209521889686584,
      "learning_rate": 4.438356164383562e-05,
      "loss": 0.0767,
      "step": 2130
    },
    {
      "epoch": 1.712,
      "grad_norm": 1.2078468799591064,
      "learning_rate": 4.4109589041095896e-05,
      "loss": 0.1002,
      "step": 2140
    },
    {
      "epoch": 1.72,
      "grad_norm": 0.6788073182106018,
      "learning_rate": 4.383561643835617e-05,
      "loss": 0.0872,
      "step": 2150
    },
    {
      "epoch": 1.72,
      "eval_loss": 0.07876986265182495,
      "eval_runtime": 28.0084,
      "eval_samples_per_second": 35.704,
      "eval_steps_per_second": 4.463,
      "step": 2150
    },
    {
      "epoch": 1.728,
      "grad_norm": 0.8959750533103943,
      "learning_rate": 4.356164383561644e-05,
      "loss": 0.0887,
      "step": 2160
    },
    {
      "epoch": 1.736,
      "grad_norm": 1.4459739923477173,
      "learning_rate": 4.3287671232876716e-05,
      "loss": 0.0907,
      "step": 2170
    },
    {
      "epoch": 1.744,
      "grad_norm": 0.8038070201873779,
      "learning_rate": 4.301369863013699e-05,
      "loss": 0.0907,
      "step": 2180
    },
    {
      "epoch": 1.752,
      "grad_norm": 1.749549388885498,
      "learning_rate": 4.2739726027397265e-05,
      "loss": 0.0763,
      "step": 2190
    },
    {
      "epoch": 1.76,
      "grad_norm": 0.6700865626335144,
      "learning_rate": 4.2465753424657536e-05,
      "loss": 0.085,
      "step": 2200
    },
    {
      "epoch": 1.76,
      "eval_loss": 0.07278751581907272,
      "eval_runtime": 28.3556,
      "eval_samples_per_second": 35.266,
      "eval_steps_per_second": 4.408,
      "step": 2200
    },
    {
      "epoch": 1.768,
      "grad_norm": 0.7507139444351196,
      "learning_rate": 4.219178082191781e-05,
      "loss": 0.0811,
      "step": 2210
    },
    {
      "epoch": 1.776,
      "grad_norm": 1.2726446390151978,
      "learning_rate": 4.1917808219178085e-05,
      "loss": 0.1006,
      "step": 2220
    },
    {
      "epoch": 1.784,
      "grad_norm": 0.7279408574104309,
      "learning_rate": 4.1643835616438356e-05,
      "loss": 0.065,
      "step": 2230
    },
    {
      "epoch": 1.792,
      "grad_norm": 0.6409218311309814,
      "learning_rate": 4.1369863013698634e-05,
      "loss": 0.0748,
      "step": 2240
    },
    {
      "epoch": 1.8,
      "grad_norm": 1.943647027015686,
      "learning_rate": 4.1095890410958905e-05,
      "loss": 0.1007,
      "step": 2250
    },
    {
      "epoch": 1.8,
      "eval_loss": 0.08099979162216187,
      "eval_runtime": 23.4057,
      "eval_samples_per_second": 42.725,
      "eval_steps_per_second": 5.341,
      "step": 2250
    },
    {
      "epoch": 1.808,
      "grad_norm": 1.2265040874481201,
      "learning_rate": 4.0821917808219176e-05,
      "loss": 0.0746,
      "step": 2260
    },
    {
      "epoch": 1.8159999999999998,
      "grad_norm": 1.040269374847412,
      "learning_rate": 4.0547945205479454e-05,
      "loss": 0.0619,
      "step": 2270
    },
    {
      "epoch": 1.8239999999999998,
      "grad_norm": 1.1650822162628174,
      "learning_rate": 4.027397260273973e-05,
      "loss": 0.0867,
      "step": 2280
    },
    {
      "epoch": 1.8319999999999999,
      "grad_norm": 1.3092972040176392,
      "learning_rate": 4e-05,
      "loss": 0.0768,
      "step": 2290
    },
    {
      "epoch": 1.8399999999999999,
      "grad_norm": 0.7238919734954834,
      "learning_rate": 3.9726027397260274e-05,
      "loss": 0.085,
      "step": 2300
    },
    {
      "epoch": 1.8399999999999999,
      "eval_loss": 0.08182911574840546,
      "eval_runtime": 25.3901,
      "eval_samples_per_second": 39.385,
      "eval_steps_per_second": 4.923,
      "step": 2300
    },
    {
      "epoch": 1.8479999999999999,
      "grad_norm": 0.760617733001709,
      "learning_rate": 3.9452054794520546e-05,
      "loss": 0.076,
      "step": 2310
    },
    {
      "epoch": 1.8559999999999999,
      "grad_norm": 0.9336748123168945,
      "learning_rate": 3.9178082191780823e-05,
      "loss": 0.0563,
      "step": 2320
    },
    {
      "epoch": 1.8639999999999999,
      "grad_norm": 0.9709240794181824,
      "learning_rate": 3.89041095890411e-05,
      "loss": 0.0668,
      "step": 2330
    },
    {
      "epoch": 1.8719999999999999,
      "grad_norm": 0.6128865480422974,
      "learning_rate": 3.863013698630137e-05,
      "loss": 0.0544,
      "step": 2340
    },
    {
      "epoch": 1.88,
      "grad_norm": 0.7215607166290283,
      "learning_rate": 3.8356164383561644e-05,
      "loss": 0.0789,
      "step": 2350
    },
    {
      "epoch": 1.88,
      "eval_loss": 0.07574450224637985,
      "eval_runtime": 25.8494,
      "eval_samples_per_second": 38.686,
      "eval_steps_per_second": 4.836,
      "step": 2350
    },
    {
      "epoch": 1.888,
      "grad_norm": 1.0516997575759888,
      "learning_rate": 3.808219178082192e-05,
      "loss": 0.07,
      "step": 2360
    },
    {
      "epoch": 1.896,
      "grad_norm": 1.4455739259719849,
      "learning_rate": 3.780821917808219e-05,
      "loss": 0.078,
      "step": 2370
    },
    {
      "epoch": 1.904,
      "grad_norm": 0.5019510984420776,
      "learning_rate": 3.753424657534247e-05,
      "loss": 0.0795,
      "step": 2380
    },
    {
      "epoch": 1.912,
      "grad_norm": 1.490597128868103,
      "learning_rate": 3.726027397260274e-05,
      "loss": 0.0663,
      "step": 2390
    },
    {
      "epoch": 1.92,
      "grad_norm": 1.5718835592269897,
      "learning_rate": 3.698630136986301e-05,
      "loss": 0.0719,
      "step": 2400
    },
    {
      "epoch": 1.92,
      "eval_loss": 0.07715289294719696,
      "eval_runtime": 27.0091,
      "eval_samples_per_second": 37.025,
      "eval_steps_per_second": 4.628,
      "step": 2400
    },
    {
      "epoch": 1.928,
      "grad_norm": 0.9475317597389221,
      "learning_rate": 3.671232876712329e-05,
      "loss": 0.0778,
      "step": 2410
    },
    {
      "epoch": 1.936,
      "grad_norm": 0.7669209837913513,
      "learning_rate": 3.643835616438356e-05,
      "loss": 0.0545,
      "step": 2420
    },
    {
      "epoch": 1.944,
      "grad_norm": 0.8730910420417786,
      "learning_rate": 3.616438356164384e-05,
      "loss": 0.0928,
      "step": 2430
    },
    {
      "epoch": 1.952,
      "grad_norm": 1.8409007787704468,
      "learning_rate": 3.589041095890411e-05,
      "loss": 0.0728,
      "step": 2440
    },
    {
      "epoch": 1.96,
      "grad_norm": 0.8131881952285767,
      "learning_rate": 3.561643835616438e-05,
      "loss": 0.077,
      "step": 2450
    },
    {
      "epoch": 1.96,
      "eval_loss": 0.07346261292695999,
      "eval_runtime": 22.8656,
      "eval_samples_per_second": 43.734,
      "eval_steps_per_second": 5.467,
      "step": 2450
    },
    {
      "epoch": 1.968,
      "grad_norm": 1.1596051454544067,
      "learning_rate": 3.534246575342466e-05,
      "loss": 0.0788,
      "step": 2460
    },
    {
      "epoch": 1.976,
      "grad_norm": 0.6882070302963257,
      "learning_rate": 3.506849315068493e-05,
      "loss": 0.0599,
      "step": 2470
    },
    {
      "epoch": 1.984,
      "grad_norm": 2.2709944248199463,
      "learning_rate": 3.479452054794521e-05,
      "loss": 0.0775,
      "step": 2480
    },
    {
      "epoch": 1.992,
      "grad_norm": 1.1318466663360596,
      "learning_rate": 3.452054794520549e-05,
      "loss": 0.0659,
      "step": 2490
    },
    {
      "epoch": 2.0,
      "grad_norm": 1.3578864336013794,
      "learning_rate": 3.424657534246575e-05,
      "loss": 0.0649,
      "step": 2500
    },
    {
      "epoch": 2.0,
      "eval_loss": 0.07358593493700027,
      "eval_runtime": 27.757,
      "eval_samples_per_second": 36.027,
      "eval_steps_per_second": 4.503,
      "step": 2500
    },
    {
      "epoch": 2.008,
      "grad_norm": 1.3992345333099365,
      "learning_rate": 3.397260273972603e-05,
      "loss": 0.0731,
      "step": 2510
    },
    {
      "epoch": 2.016,
      "grad_norm": 0.939490795135498,
      "learning_rate": 3.36986301369863e-05,
      "loss": 0.0794,
      "step": 2520
    },
    {
      "epoch": 2.024,
      "grad_norm": 1.0379542112350464,
      "learning_rate": 3.342465753424658e-05,
      "loss": 0.0577,
      "step": 2530
    },
    {
      "epoch": 2.032,
      "grad_norm": 0.7803760766983032,
      "learning_rate": 3.3150684931506856e-05,
      "loss": 0.0802,
      "step": 2540
    },
    {
      "epoch": 2.04,
      "grad_norm": 0.5178189277648926,
      "learning_rate": 3.287671232876712e-05,
      "loss": 0.0697,
      "step": 2550
    },
    {
      "epoch": 2.04,
      "eval_loss": 0.0732647106051445,
      "eval_runtime": 21.3193,
      "eval_samples_per_second": 46.906,
      "eval_steps_per_second": 5.863,
      "step": 2550
    },
    {
      "epoch": 2.048,
      "grad_norm": 0.9957634806632996,
      "learning_rate": 3.26027397260274e-05,
      "loss": 0.0532,
      "step": 2560
    },
    {
      "epoch": 2.056,
      "grad_norm": 0.7789929509162903,
      "learning_rate": 3.2328767123287676e-05,
      "loss": 0.0797,
      "step": 2570
    },
    {
      "epoch": 2.064,
      "grad_norm": 1.199987769126892,
      "learning_rate": 3.205479452054795e-05,
      "loss": 0.0782,
      "step": 2580
    },
    {
      "epoch": 2.072,
      "grad_norm": 1.1846801042556763,
      "learning_rate": 3.1780821917808225e-05,
      "loss": 0.0717,
      "step": 2590
    },
    {
      "epoch": 2.08,
      "grad_norm": 1.2156087160110474,
      "learning_rate": 3.1506849315068496e-05,
      "loss": 0.0759,
      "step": 2600
    },
    {
      "epoch": 2.08,
      "eval_loss": 0.08412562310695648,
      "eval_runtime": 24.1359,
      "eval_samples_per_second": 41.432,
      "eval_steps_per_second": 5.179,
      "step": 2600
    },
    {
      "epoch": 2.088,
      "grad_norm": 0.49475863575935364,
      "learning_rate": 3.123287671232877e-05,
      "loss": 0.0521,
      "step": 2610
    },
    {
      "epoch": 2.096,
      "grad_norm": 1.0311695337295532,
      "learning_rate": 3.0958904109589045e-05,
      "loss": 0.0678,
      "step": 2620
    },
    {
      "epoch": 2.104,
      "grad_norm": 1.2524863481521606,
      "learning_rate": 3.0684931506849316e-05,
      "loss": 0.0614,
      "step": 2630
    },
    {
      "epoch": 2.112,
      "grad_norm": 0.8930814266204834,
      "learning_rate": 3.0410958904109594e-05,
      "loss": 0.0601,
      "step": 2640
    },
    {
      "epoch": 2.12,
      "grad_norm": 1.0607593059539795,
      "learning_rate": 3.0136986301369862e-05,
      "loss": 0.0785,
      "step": 2650
    },
    {
      "epoch": 2.12,
      "eval_loss": 0.07417958974838257,
      "eval_runtime": 21.3013,
      "eval_samples_per_second": 46.945,
      "eval_steps_per_second": 5.868,
      "step": 2650
    },
    {
      "epoch": 2.128,
      "grad_norm": 1.131692886352539,
      "learning_rate": 2.9863013698630136e-05,
      "loss": 0.0643,
      "step": 2660
    },
    {
      "epoch": 2.136,
      "grad_norm": 1.4610873460769653,
      "learning_rate": 2.9589041095890414e-05,
      "loss": 0.0633,
      "step": 2670
    },
    {
      "epoch": 2.144,
      "grad_norm": 1.8186776638031006,
      "learning_rate": 2.931506849315069e-05,
      "loss": 0.0643,
      "step": 2680
    },
    {
      "epoch": 2.152,
      "grad_norm": 0.3792404532432556,
      "learning_rate": 2.9041095890410956e-05,
      "loss": 0.0637,
      "step": 2690
    },
    {
      "epoch": 2.16,
      "grad_norm": 0.9899280667304993,
      "learning_rate": 2.8767123287671234e-05,
      "loss": 0.0482,
      "step": 2700
    },
    {
      "epoch": 2.16,
      "eval_loss": 0.07788441330194473,
      "eval_runtime": 26.1667,
      "eval_samples_per_second": 38.217,
      "eval_steps_per_second": 4.777,
      "step": 2700
    },
    {
      "epoch": 2.168,
      "grad_norm": 1.1095852851867676,
      "learning_rate": 2.849315068493151e-05,
      "loss": 0.0647,
      "step": 2710
    },
    {
      "epoch": 2.176,
      "grad_norm": 0.6428847312927246,
      "learning_rate": 2.8219178082191783e-05,
      "loss": 0.0711,
      "step": 2720
    },
    {
      "epoch": 2.184,
      "grad_norm": 0.8361815810203552,
      "learning_rate": 2.7945205479452058e-05,
      "loss": 0.0645,
      "step": 2730
    },
    {
      "epoch": 2.192,
      "grad_norm": 1.112998366355896,
      "learning_rate": 2.767123287671233e-05,
      "loss": 0.0811,
      "step": 2740
    },
    {
      "epoch": 2.2,
      "grad_norm": 1.1057673692703247,
      "learning_rate": 2.7397260273972603e-05,
      "loss": 0.0747,
      "step": 2750
    },
    {
      "epoch": 2.2,
      "eval_loss": 0.0875755175948143,
      "eval_runtime": 21.2723,
      "eval_samples_per_second": 47.009,
      "eval_steps_per_second": 5.876,
      "step": 2750
    },
    {
      "epoch": 2.208,
      "grad_norm": 2.2340025901794434,
      "learning_rate": 2.7123287671232878e-05,
      "loss": 0.0666,
      "step": 2760
    },
    {
      "epoch": 2.216,
      "grad_norm": 1.2236347198486328,
      "learning_rate": 2.6849315068493153e-05,
      "loss": 0.0648,
      "step": 2770
    },
    {
      "epoch": 2.224,
      "grad_norm": 0.8737649321556091,
      "learning_rate": 2.6575342465753427e-05,
      "loss": 0.0541,
      "step": 2780
    },
    {
      "epoch": 2.232,
      "grad_norm": 0.34838786721229553,
      "learning_rate": 2.6301369863013698e-05,
      "loss": 0.0565,
      "step": 2790
    },
    {
      "epoch": 2.24,
      "grad_norm": 1.205905795097351,
      "learning_rate": 2.6027397260273973e-05,
      "loss": 0.0553,
      "step": 2800
    },
    {
      "epoch": 2.24,
      "eval_loss": 0.07313043624162674,
      "eval_runtime": 24.1815,
      "eval_samples_per_second": 41.354,
      "eval_steps_per_second": 5.169,
      "step": 2800
    },
    {
      "epoch": 2.248,
      "grad_norm": 1.6920890808105469,
      "learning_rate": 2.5753424657534247e-05,
      "loss": 0.0751,
      "step": 2810
    },
    {
      "epoch": 2.2560000000000002,
      "grad_norm": 1.1228349208831787,
      "learning_rate": 2.547945205479452e-05,
      "loss": 0.0773,
      "step": 2820
    },
    {
      "epoch": 2.2640000000000002,
      "grad_norm": 1.5875276327133179,
      "learning_rate": 2.5205479452054796e-05,
      "loss": 0.0711,
      "step": 2830
    },
    {
      "epoch": 2.2720000000000002,
      "grad_norm": 1.100090503692627,
      "learning_rate": 2.493150684931507e-05,
      "loss": 0.0749,
      "step": 2840
    },
    {
      "epoch": 2.2800000000000002,
      "grad_norm": 0.7795864939689636,
      "learning_rate": 2.4657534246575342e-05,
      "loss": 0.0634,
      "step": 2850
    },
    {
      "epoch": 2.2800000000000002,
      "eval_loss": 0.07080110162496567,
      "eval_runtime": 21.2707,
      "eval_samples_per_second": 47.013,
      "eval_steps_per_second": 5.877,
      "step": 2850
    },
    {
      "epoch": 2.288,
      "grad_norm": 0.9094109535217285,
      "learning_rate": 2.4383561643835616e-05,
      "loss": 0.0523,
      "step": 2860
    },
    {
      "epoch": 2.296,
      "grad_norm": 1.5612109899520874,
      "learning_rate": 2.410958904109589e-05,
      "loss": 0.0456,
      "step": 2870
    },
    {
      "epoch": 2.304,
      "grad_norm": 0.9405341148376465,
      "learning_rate": 2.3835616438356165e-05,
      "loss": 0.0487,
      "step": 2880
    },
    {
      "epoch": 2.312,
      "grad_norm": 0.6188758015632629,
      "learning_rate": 2.356164383561644e-05,
      "loss": 0.0626,
      "step": 2890
    },
    {
      "epoch": 2.32,
      "grad_norm": 1.570373773574829,
      "learning_rate": 2.328767123287671e-05,
      "loss": 0.0646,
      "step": 2900
    },
    {
      "epoch": 2.32,
      "eval_loss": 0.07838147133588791,
      "eval_runtime": 22.9074,
      "eval_samples_per_second": 43.654,
      "eval_steps_per_second": 5.457,
      "step": 2900
    },
    {
      "epoch": 2.328,
      "grad_norm": 0.25492703914642334,
      "learning_rate": 2.301369863013699e-05,
      "loss": 0.0456,
      "step": 2910
    },
    {
      "epoch": 2.336,
      "grad_norm": 0.9828417897224426,
      "learning_rate": 2.2739726027397263e-05,
      "loss": 0.069,
      "step": 2920
    },
    {
      "epoch": 2.344,
      "grad_norm": 1.2036198377609253,
      "learning_rate": 2.2465753424657534e-05,
      "loss": 0.0408,
      "step": 2930
    },
    {
      "epoch": 2.352,
      "grad_norm": 0.7698054909706116,
      "learning_rate": 2.219178082191781e-05,
      "loss": 0.056,
      "step": 2940
    },
    {
      "epoch": 2.36,
      "grad_norm": 1.0769925117492676,
      "learning_rate": 2.1917808219178083e-05,
      "loss": 0.0489,
      "step": 2950
    },
    {
      "epoch": 2.36,
      "eval_loss": 0.08132126182317734,
      "eval_runtime": 21.2413,
      "eval_samples_per_second": 47.078,
      "eval_steps_per_second": 5.885,
      "step": 2950
    },
    {
      "epoch": 2.368,
      "grad_norm": 0.837098240852356,
      "learning_rate": 2.1643835616438358e-05,
      "loss": 0.0664,
      "step": 2960
    },
    {
      "epoch": 2.376,
      "grad_norm": 0.6278063654899597,
      "learning_rate": 2.1369863013698632e-05,
      "loss": 0.0514,
      "step": 2970
    },
    {
      "epoch": 2.384,
      "grad_norm": 1.2170597314834595,
      "learning_rate": 2.1095890410958904e-05,
      "loss": 0.0597,
      "step": 2980
    },
    {
      "epoch": 2.392,
      "grad_norm": 0.9432615041732788,
      "learning_rate": 2.0821917808219178e-05,
      "loss": 0.0548,
      "step": 2990
    },
    {
      "epoch": 2.4,
      "grad_norm": 0.4730060398578644,
      "learning_rate": 2.0547945205479453e-05,
      "loss": 0.0432,
      "step": 3000
    },
    {
      "epoch": 2.4,
      "eval_loss": 0.07349462807178497,
      "eval_runtime": 24.9356,
      "eval_samples_per_second": 40.103,
      "eval_steps_per_second": 5.013,
      "step": 3000
    },
    {
      "epoch": 2.408,
      "grad_norm": 1.0375620126724243,
      "learning_rate": 2.0273972602739727e-05,
      "loss": 0.0654,
      "step": 3010
    },
    {
      "epoch": 2.416,
      "grad_norm": 1.0727165937423706,
      "learning_rate": 2e-05,
      "loss": 0.0767,
      "step": 3020
    },
    {
      "epoch": 2.424,
      "grad_norm": 1.2139906883239746,
      "learning_rate": 1.9726027397260273e-05,
      "loss": 0.0495,
      "step": 3030
    },
    {
      "epoch": 2.432,
      "grad_norm": 0.38574331998825073,
      "learning_rate": 1.945205479452055e-05,
      "loss": 0.0444,
      "step": 3040
    },
    {
      "epoch": 2.44,
      "grad_norm": 0.903919517993927,
      "learning_rate": 1.9178082191780822e-05,
      "loss": 0.0595,
      "step": 3050
    },
    {
      "epoch": 2.44,
      "eval_loss": 0.0757783055305481,
      "eval_runtime": 21.2158,
      "eval_samples_per_second": 47.135,
      "eval_steps_per_second": 5.892,
      "step": 3050
    },
    {
      "epoch": 2.448,
      "grad_norm": 0.946124792098999,
      "learning_rate": 1.8904109589041096e-05,
      "loss": 0.0542,
      "step": 3060
    },
    {
      "epoch": 2.456,
      "grad_norm": 1.1267518997192383,
      "learning_rate": 1.863013698630137e-05,
      "loss": 0.0622,
      "step": 3070
    },
    {
      "epoch": 2.464,
      "grad_norm": 1.1738067865371704,
      "learning_rate": 1.8356164383561645e-05,
      "loss": 0.0565,
      "step": 3080
    },
    {
      "epoch": 2.472,
      "grad_norm": 1.4237116575241089,
      "learning_rate": 1.808219178082192e-05,
      "loss": 0.0734,
      "step": 3090
    },
    {
      "epoch": 2.48,
      "grad_norm": 1.2737714052200317,
      "learning_rate": 1.780821917808219e-05,
      "loss": 0.0526,
      "step": 3100
    },
    {
      "epoch": 2.48,
      "eval_loss": 0.08040988445281982,
      "eval_runtime": 22.6699,
      "eval_samples_per_second": 44.111,
      "eval_steps_per_second": 5.514,
      "step": 3100
    },
    {
      "epoch": 2.488,
      "grad_norm": 1.2844059467315674,
      "learning_rate": 1.7534246575342465e-05,
      "loss": 0.0584,
      "step": 3110
    },
    {
      "epoch": 2.496,
      "grad_norm": 1.1170053482055664,
      "learning_rate": 1.7260273972602743e-05,
      "loss": 0.075,
      "step": 3120
    },
    {
      "epoch": 2.504,
      "grad_norm": 0.5048978924751282,
      "learning_rate": 1.6986301369863014e-05,
      "loss": 0.0583,
      "step": 3130
    },
    {
      "epoch": 2.512,
      "grad_norm": 0.8789260983467102,
      "learning_rate": 1.671232876712329e-05,
      "loss": 0.0485,
      "step": 3140
    },
    {
      "epoch": 2.52,
      "grad_norm": 1.5990062952041626,
      "learning_rate": 1.643835616438356e-05,
      "loss": 0.0382,
      "step": 3150
    },
    {
      "epoch": 2.52,
      "eval_loss": 0.07367081940174103,
      "eval_runtime": 21.1933,
      "eval_samples_per_second": 47.185,
      "eval_steps_per_second": 5.898,
      "step": 3150
    },
    {
      "epoch": 2.528,
      "grad_norm": 1.025818109512329,
      "learning_rate": 1.6164383561643838e-05,
      "loss": 0.0688,
      "step": 3160
    },
    {
      "epoch": 2.536,
      "grad_norm": 0.8666490912437439,
      "learning_rate": 1.5890410958904112e-05,
      "loss": 0.0612,
      "step": 3170
    },
    {
      "epoch": 2.544,
      "grad_norm": 1.1632826328277588,
      "learning_rate": 1.5616438356164384e-05,
      "loss": 0.0717,
      "step": 3180
    },
    {
      "epoch": 2.552,
      "grad_norm": 1.3949648141860962,
      "learning_rate": 1.5342465753424658e-05,
      "loss": 0.0612,
      "step": 3190
    },
    {
      "epoch": 2.56,
      "grad_norm": 0.6361100077629089,
      "learning_rate": 1.5068493150684931e-05,
      "loss": 0.0512,
      "step": 3200
    },
    {
      "epoch": 2.56,
      "eval_loss": 0.07017913460731506,
      "eval_runtime": 21.7799,
      "eval_samples_per_second": 45.914,
      "eval_steps_per_second": 5.739,
      "step": 3200
    },
    {
      "epoch": 2.568,
      "grad_norm": 1.036832571029663,
      "learning_rate": 1.4794520547945207e-05,
      "loss": 0.0752,
      "step": 3210
    },
    {
      "epoch": 2.576,
      "grad_norm": 1.4844326972961426,
      "learning_rate": 1.4520547945205478e-05,
      "loss": 0.0499,
      "step": 3220
    },
    {
      "epoch": 2.584,
      "grad_norm": 1.3016223907470703,
      "learning_rate": 1.4246575342465754e-05,
      "loss": 0.0693,
      "step": 3230
    },
    {
      "epoch": 2.592,
      "grad_norm": 1.1411525011062622,
      "learning_rate": 1.3972602739726029e-05,
      "loss": 0.0626,
      "step": 3240
    },
    {
      "epoch": 2.6,
      "grad_norm": 1.3435298204421997,
      "learning_rate": 1.3698630136986302e-05,
      "loss": 0.0863,
      "step": 3250
    },
    {
      "epoch": 2.6,
      "eval_loss": 0.07598274201154709,
      "eval_runtime": 21.1607,
      "eval_samples_per_second": 47.257,
      "eval_steps_per_second": 5.907,
      "step": 3250
    },
    {
      "epoch": 2.608,
      "grad_norm": 0.898640513420105,
      "learning_rate": 1.3424657534246576e-05,
      "loss": 0.0606,
      "step": 3260
    },
    {
      "epoch": 2.616,
      "grad_norm": 0.4321126639842987,
      "learning_rate": 1.3150684931506849e-05,
      "loss": 0.0656,
      "step": 3270
    },
    {
      "epoch": 2.624,
      "grad_norm": 1.259407639503479,
      "learning_rate": 1.2876712328767124e-05,
      "loss": 0.0768,
      "step": 3280
    },
    {
      "epoch": 2.632,
      "grad_norm": 0.5912024974822998,
      "learning_rate": 1.2602739726027398e-05,
      "loss": 0.0509,
      "step": 3290
    },
    {
      "epoch": 2.64,
      "grad_norm": 0.3940187394618988,
      "learning_rate": 1.2328767123287671e-05,
      "loss": 0.0598,
      "step": 3300
    },
    {
      "epoch": 2.64,
      "eval_loss": 0.07953660935163498,
      "eval_runtime": 21.5799,
      "eval_samples_per_second": 46.339,
      "eval_steps_per_second": 5.792,
      "step": 3300
    },
    {
      "epoch": 2.648,
      "grad_norm": 1.5994631052017212,
      "learning_rate": 1.2054794520547945e-05,
      "loss": 0.0752,
      "step": 3310
    },
    {
      "epoch": 2.656,
      "grad_norm": 0.7736765742301941,
      "learning_rate": 1.178082191780822e-05,
      "loss": 0.0489,
      "step": 3320
    },
    {
      "epoch": 2.664,
      "grad_norm": 1.2608373165130615,
      "learning_rate": 1.1506849315068494e-05,
      "loss": 0.0736,
      "step": 3330
    },
    {
      "epoch": 2.672,
      "grad_norm": 1.2277199029922485,
      "learning_rate": 1.1232876712328767e-05,
      "loss": 0.0553,
      "step": 3340
    },
    {
      "epoch": 2.68,
      "grad_norm": 1.2781788110733032,
      "learning_rate": 1.0958904109589042e-05,
      "loss": 0.0485,
      "step": 3350
    },
    {
      "epoch": 2.68,
      "eval_loss": 0.07453451305627823,
      "eval_runtime": 23.9662,
      "eval_samples_per_second": 41.725,
      "eval_steps_per_second": 5.216,
      "step": 3350
    },
    {
      "epoch": 2.6879999999999997,
      "grad_norm": 1.0797392129898071,
      "learning_rate": 1.0684931506849316e-05,
      "loss": 0.0691,
      "step": 3360
    },
    {
      "epoch": 2.6959999999999997,
      "grad_norm": 1.1174019575119019,
      "learning_rate": 1.0410958904109589e-05,
      "loss": 0.0605,
      "step": 3370
    },
    {
      "epoch": 2.7039999999999997,
      "grad_norm": 1.1081383228302002,
      "learning_rate": 1.0136986301369864e-05,
      "loss": 0.0613,
      "step": 3380
    },
    {
      "epoch": 2.7119999999999997,
      "grad_norm": 0.452335923910141,
      "learning_rate": 9.863013698630136e-06,
      "loss": 0.0699,
      "step": 3390
    },
    {
      "epoch": 2.7199999999999998,
      "grad_norm": 0.2341422289609909,
      "learning_rate": 9.589041095890411e-06,
      "loss": 0.0534,
      "step": 3400
    },
    {
      "epoch": 2.7199999999999998,
      "eval_loss": 0.07631205022335052,
      "eval_runtime": 26.2159,
      "eval_samples_per_second": 38.145,
      "eval_steps_per_second": 4.768,
      "step": 3400
    },
    {
      "epoch": 2.7279999999999998,
      "grad_norm": 0.7509540319442749,
      "learning_rate": 9.315068493150685e-06,
      "loss": 0.0473,
      "step": 3410
    },
    {
      "epoch": 2.7359999999999998,
      "grad_norm": 0.6138253211975098,
      "learning_rate": 9.04109589041096e-06,
      "loss": 0.0437,
      "step": 3420
    },
    {
      "epoch": 2.7439999999999998,
      "grad_norm": 0.6206238269805908,
      "learning_rate": 8.767123287671233e-06,
      "loss": 0.0583,
      "step": 3430
    },
    {
      "epoch": 2.752,
      "grad_norm": 1.3301291465759277,
      "learning_rate": 8.493150684931507e-06,
      "loss": 0.0533,
      "step": 3440
    },
    {
      "epoch": 2.76,
      "grad_norm": 1.2195779085159302,
      "learning_rate": 8.21917808219178e-06,
      "loss": 0.0465,
      "step": 3450
    },
    {
      "epoch": 2.76,
      "eval_loss": 0.07512922585010529,
      "eval_runtime": 25.363,
      "eval_samples_per_second": 39.428,
      "eval_steps_per_second": 4.928,
      "step": 3450
    },
    {
      "epoch": 2.768,
      "grad_norm": 0.8902655839920044,
      "learning_rate": 7.945205479452056e-06,
      "loss": 0.0566,
      "step": 3460
    },
    {
      "epoch": 2.776,
      "grad_norm": 1.2187368869781494,
      "learning_rate": 7.671232876712329e-06,
      "loss": 0.0633,
      "step": 3470
    },
    {
      "epoch": 2.784,
      "grad_norm": 1.0439895391464233,
      "learning_rate": 7.3972602739726036e-06,
      "loss": 0.0566,
      "step": 3480
    },
    {
      "epoch": 2.792,
      "grad_norm": 1.1517468690872192,
      "learning_rate": 7.123287671232877e-06,
      "loss": 0.0626,
      "step": 3490
    },
    {
      "epoch": 2.8,
      "grad_norm": 1.2717385292053223,
      "learning_rate": 6.849315068493151e-06,
      "loss": 0.0613,
      "step": 3500
    },
    {
      "epoch": 2.8,
      "eval_loss": 0.07417804002761841,
      "eval_runtime": 25.7951,
      "eval_samples_per_second": 38.767,
      "eval_steps_per_second": 4.846,
      "step": 3500
    },
    {
      "epoch": 2.808,
      "grad_norm": 1.1033183336257935,
      "learning_rate": 6.5753424657534245e-06,
      "loss": 0.0684,
      "step": 3510
    },
    {
      "epoch": 2.816,
      "grad_norm": 0.5943980813026428,
      "learning_rate": 6.301369863013699e-06,
      "loss": 0.0365,
      "step": 3520
    },
    {
      "epoch": 2.824,
      "grad_norm": 0.6899091601371765,
      "learning_rate": 6.027397260273973e-06,
      "loss": 0.046,
      "step": 3530
    },
    {
      "epoch": 2.832,
      "grad_norm": 1.0029593706130981,
      "learning_rate": 5.753424657534247e-06,
      "loss": 0.0475,
      "step": 3540
    },
    {
      "epoch": 2.84,
      "grad_norm": 0.9179275035858154,
      "learning_rate": 5.479452054794521e-06,
      "loss": 0.0563,
      "step": 3550
    },
    {
      "epoch": 2.84,
      "eval_loss": 0.07404320687055588,
      "eval_runtime": 25.4121,
      "eval_samples_per_second": 39.351,
      "eval_steps_per_second": 4.919,
      "step": 3550
    },
    {
      "epoch": 2.848,
      "grad_norm": 0.9469447135925293,
      "learning_rate": 5.2054794520547945e-06,
      "loss": 0.074,
      "step": 3560
    },
    {
      "epoch": 2.856,
      "grad_norm": 0.7913358211517334,
      "learning_rate": 4.931506849315068e-06,
      "loss": 0.0616,
      "step": 3570
    },
    {
      "epoch": 2.864,
      "grad_norm": 0.552422285079956,
      "learning_rate": 4.657534246575343e-06,
      "loss": 0.0711,
      "step": 3580
    },
    {
      "epoch": 2.872,
      "grad_norm": 1.1250964403152466,
      "learning_rate": 4.383561643835616e-06,
      "loss": 0.0582,
      "step": 3590
    },
    {
      "epoch": 2.88,
      "grad_norm": 0.7006968855857849,
      "learning_rate": 4.10958904109589e-06,
      "loss": 0.0531,
      "step": 3600
    },
    {
      "epoch": 2.88,
      "eval_loss": 0.07523413002490997,
      "eval_runtime": 28.2272,
      "eval_samples_per_second": 35.427,
      "eval_steps_per_second": 4.428,
      "step": 3600
    },
    {
      "epoch": 2.888,
      "grad_norm": 0.7255940437316895,
      "learning_rate": 3.8356164383561645e-06,
      "loss": 0.0895,
      "step": 3610
    },
    {
      "epoch": 2.896,
      "grad_norm": 0.30036401748657227,
      "learning_rate": 3.5616438356164386e-06,
      "loss": 0.0544,
      "step": 3620
    },
    {
      "epoch": 2.904,
      "grad_norm": 1.3800764083862305,
      "learning_rate": 3.2876712328767123e-06,
      "loss": 0.05,
      "step": 3630
    },
    {
      "epoch": 2.912,
      "grad_norm": 0.7761391401290894,
      "learning_rate": 3.0136986301369864e-06,
      "loss": 0.0615,
      "step": 3640
    },
    {
      "epoch": 2.92,
      "grad_norm": 0.9109655618667603,
      "learning_rate": 2.7397260273972604e-06,
      "loss": 0.066,
      "step": 3650
    },
    {
      "epoch": 2.92,
      "eval_loss": 0.07456237077713013,
      "eval_runtime": 28.0684,
      "eval_samples_per_second": 35.627,
      "eval_steps_per_second": 4.453,
      "step": 3650
    },
    {
      "epoch": 2.928,
      "grad_norm": 0.6804625391960144,
      "learning_rate": 2.465753424657534e-06,
      "loss": 0.0418,
      "step": 3660
    },
    {
      "epoch": 2.936,
      "grad_norm": 0.3218683898448944,
      "learning_rate": 2.191780821917808e-06,
      "loss": 0.0479,
      "step": 3670
    },
    {
      "epoch": 2.944,
      "grad_norm": 0.6608006358146667,
      "learning_rate": 1.9178082191780823e-06,
      "loss": 0.0718,
      "step": 3680
    },
    {
      "epoch": 2.952,
      "grad_norm": 0.5601940751075745,
      "learning_rate": 1.6438356164383561e-06,
      "loss": 0.0567,
      "step": 3690
    },
    {
      "epoch": 2.96,
      "grad_norm": 0.6024381518363953,
      "learning_rate": 1.3698630136986302e-06,
      "loss": 0.0507,
      "step": 3700
    },
    {
      "epoch": 2.96,
      "eval_loss": 0.07519543170928955,
      "eval_runtime": 28.3466,
      "eval_samples_per_second": 35.278,
      "eval_steps_per_second": 4.41,
      "step": 3700
    },
    {
      "epoch": 2.968,
      "grad_norm": 0.6315475106239319,
      "learning_rate": 1.095890410958904e-06,
      "loss": 0.0501,
      "step": 3710
    },
    {
      "epoch": 2.976,
      "grad_norm": 0.9953911900520325,
      "learning_rate": 8.219178082191781e-07,
      "loss": 0.048,
      "step": 3720
    },
    {
      "epoch": 2.984,
      "grad_norm": 0.7173187136650085,
      "learning_rate": 5.47945205479452e-07,
      "loss": 0.0838,
      "step": 3730
    },
    {
      "epoch": 2.992,
      "grad_norm": 0.7803404927253723,
      "learning_rate": 2.73972602739726e-07,
      "loss": 0.0621,
      "step": 3740
    },
    {
      "epoch": 3.0,
      "grad_norm": 0.9559292793273926,
      "learning_rate": 0.0,
      "loss": 0.0613,
      "step": 3750
    },
    {
      "epoch": 3.0,
      "eval_loss": 0.07502872496843338,
      "eval_runtime": 28.1287,
      "eval_samples_per_second": 35.551,
      "eval_steps_per_second": 4.444,
      "step": 3750
    }
  ],
  "logging_steps": 10,
  "max_steps": 3750,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 3,
  "save_steps": 100,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 4645269639714816.0,
  "train_batch_size": 8,
  "trial_name": null,
  "trial_params": null
}
