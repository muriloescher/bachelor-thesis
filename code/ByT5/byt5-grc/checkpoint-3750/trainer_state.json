{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 3.0,
  "eval_steps": 50,
  "global_step": 3750,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.008,
      "grad_norm": 190.16751098632812,
      "learning_rate": 1e-05,
      "loss": 4.175,
      "step": 10
    },
    {
      "epoch": 0.016,
      "grad_norm": 46.562530517578125,
      "learning_rate": 2e-05,
      "loss": 3.9151,
      "step": 20
    },
    {
      "epoch": 0.024,
      "grad_norm": 98.30742645263672,
      "learning_rate": 3e-05,
      "loss": 3.5299,
      "step": 30
    },
    {
      "epoch": 0.032,
      "grad_norm": 68.6258544921875,
      "learning_rate": 4e-05,
      "loss": 3.0831,
      "step": 40
    },
    {
      "epoch": 0.04,
      "grad_norm": 28.20149803161621,
      "learning_rate": 5e-05,
      "loss": 2.5191,
      "step": 50
    },
    {
      "epoch": 0.04,
      "eval_loss": 2.0291216373443604,
      "eval_runtime": 24.8063,
      "eval_samples_per_second": 40.312,
      "eval_steps_per_second": 5.039,
      "step": 50
    },
    {
      "epoch": 0.048,
      "grad_norm": 27.131832122802734,
      "learning_rate": 6e-05,
      "loss": 2.3605,
      "step": 60
    },
    {
      "epoch": 0.056,
      "grad_norm": 37.01333999633789,
      "learning_rate": 7e-05,
      "loss": 2.0064,
      "step": 70
    },
    {
      "epoch": 0.064,
      "grad_norm": 30.682138442993164,
      "learning_rate": 8e-05,
      "loss": 1.5341,
      "step": 80
    },
    {
      "epoch": 0.072,
      "grad_norm": 12.231621742248535,
      "learning_rate": 9e-05,
      "loss": 1.1959,
      "step": 90
    },
    {
      "epoch": 0.08,
      "grad_norm": 16.866317749023438,
      "learning_rate": 0.0001,
      "loss": 1.0226,
      "step": 100
    },
    {
      "epoch": 0.08,
      "eval_loss": 0.7262290120124817,
      "eval_runtime": 24.6736,
      "eval_samples_per_second": 40.529,
      "eval_steps_per_second": 5.066,
      "step": 100
    },
    {
      "epoch": 0.088,
      "grad_norm": 25.195688247680664,
      "learning_rate": 9.972602739726028e-05,
      "loss": 0.9553,
      "step": 110
    },
    {
      "epoch": 0.096,
      "grad_norm": 11.055680274963379,
      "learning_rate": 9.945205479452056e-05,
      "loss": 0.774,
      "step": 120
    },
    {
      "epoch": 0.104,
      "grad_norm": 6.549143314361572,
      "learning_rate": 9.917808219178082e-05,
      "loss": 0.7316,
      "step": 130
    },
    {
      "epoch": 0.112,
      "grad_norm": 4.972931861877441,
      "learning_rate": 9.89041095890411e-05,
      "loss": 0.8207,
      "step": 140
    },
    {
      "epoch": 0.12,
      "grad_norm": 29.150293350219727,
      "learning_rate": 9.863013698630137e-05,
      "loss": 0.6895,
      "step": 150
    },
    {
      "epoch": 0.12,
      "eval_loss": 0.5861185193061829,
      "eval_runtime": 24.7246,
      "eval_samples_per_second": 40.446,
      "eval_steps_per_second": 5.056,
      "step": 150
    },
    {
      "epoch": 0.128,
      "grad_norm": 7.905642509460449,
      "learning_rate": 9.835616438356165e-05,
      "loss": 0.6694,
      "step": 160
    },
    {
      "epoch": 0.136,
      "grad_norm": 3.9250292778015137,
      "learning_rate": 9.808219178082192e-05,
      "loss": 0.6475,
      "step": 170
    },
    {
      "epoch": 0.144,
      "grad_norm": 3.2224645614624023,
      "learning_rate": 9.78082191780822e-05,
      "loss": 0.6019,
      "step": 180
    },
    {
      "epoch": 0.152,
      "grad_norm": 2.5677969455718994,
      "learning_rate": 9.753424657534247e-05,
      "loss": 0.5969,
      "step": 190
    },
    {
      "epoch": 0.16,
      "grad_norm": 3.5142672061920166,
      "learning_rate": 9.726027397260274e-05,
      "loss": 0.6049,
      "step": 200
    },
    {
      "epoch": 0.16,
      "eval_loss": 0.5077057480812073,
      "eval_runtime": 24.7535,
      "eval_samples_per_second": 40.398,
      "eval_steps_per_second": 5.05,
      "step": 200
    },
    {
      "epoch": 0.168,
      "grad_norm": 4.963808059692383,
      "learning_rate": 9.698630136986302e-05,
      "loss": 0.552,
      "step": 210
    },
    {
      "epoch": 0.176,
      "grad_norm": 2.549574613571167,
      "learning_rate": 9.67123287671233e-05,
      "loss": 0.5476,
      "step": 220
    },
    {
      "epoch": 0.184,
      "grad_norm": 2.8788981437683105,
      "learning_rate": 9.643835616438356e-05,
      "loss": 0.4853,
      "step": 230
    },
    {
      "epoch": 0.192,
      "grad_norm": 3.048614263534546,
      "learning_rate": 9.616438356164384e-05,
      "loss": 0.4355,
      "step": 240
    },
    {
      "epoch": 0.2,
      "grad_norm": 4.360311031341553,
      "learning_rate": 9.58904109589041e-05,
      "loss": 0.4547,
      "step": 250
    },
    {
      "epoch": 0.2,
      "eval_loss": 0.4620150625705719,
      "eval_runtime": 24.9155,
      "eval_samples_per_second": 40.136,
      "eval_steps_per_second": 5.017,
      "step": 250
    },
    {
      "epoch": 0.208,
      "grad_norm": 2.6847853660583496,
      "learning_rate": 9.561643835616438e-05,
      "loss": 0.5238,
      "step": 260
    },
    {
      "epoch": 0.216,
      "grad_norm": 2.5516843795776367,
      "learning_rate": 9.534246575342466e-05,
      "loss": 0.4525,
      "step": 270
    },
    {
      "epoch": 0.224,
      "grad_norm": 3.1952896118164062,
      "learning_rate": 9.506849315068494e-05,
      "loss": 0.4073,
      "step": 280
    },
    {
      "epoch": 0.232,
      "grad_norm": 1.9874589443206787,
      "learning_rate": 9.47945205479452e-05,
      "loss": 0.4425,
      "step": 290
    },
    {
      "epoch": 0.24,
      "grad_norm": 2.4354403018951416,
      "learning_rate": 9.452054794520548e-05,
      "loss": 0.4118,
      "step": 300
    },
    {
      "epoch": 0.24,
      "eval_loss": 0.3987208902835846,
      "eval_runtime": 24.8187,
      "eval_samples_per_second": 40.292,
      "eval_steps_per_second": 5.037,
      "step": 300
    },
    {
      "epoch": 0.248,
      "grad_norm": 1.5243362188339233,
      "learning_rate": 9.424657534246576e-05,
      "loss": 0.419,
      "step": 310
    },
    {
      "epoch": 0.256,
      "grad_norm": 3.425227165222168,
      "learning_rate": 9.397260273972604e-05,
      "loss": 0.3721,
      "step": 320
    },
    {
      "epoch": 0.264,
      "grad_norm": 2.5395472049713135,
      "learning_rate": 9.369863013698632e-05,
      "loss": 0.3712,
      "step": 330
    },
    {
      "epoch": 0.272,
      "grad_norm": 2.026486396789551,
      "learning_rate": 9.342465753424658e-05,
      "loss": 0.4303,
      "step": 340
    },
    {
      "epoch": 0.28,
      "grad_norm": 3.258517265319824,
      "learning_rate": 9.315068493150684e-05,
      "loss": 0.3018,
      "step": 350
    },
    {
      "epoch": 0.28,
      "eval_loss": 0.41356950998306274,
      "eval_runtime": 24.7885,
      "eval_samples_per_second": 40.341,
      "eval_steps_per_second": 5.043,
      "step": 350
    },
    {
      "epoch": 0.288,
      "grad_norm": 1.5445647239685059,
      "learning_rate": 9.287671232876712e-05,
      "loss": 0.4111,
      "step": 360
    },
    {
      "epoch": 0.296,
      "grad_norm": 1.846657395362854,
      "learning_rate": 9.26027397260274e-05,
      "loss": 0.3867,
      "step": 370
    },
    {
      "epoch": 0.304,
      "grad_norm": 3.859447479248047,
      "learning_rate": 9.232876712328768e-05,
      "loss": 0.3468,
      "step": 380
    },
    {
      "epoch": 0.312,
      "grad_norm": 1.9044228792190552,
      "learning_rate": 9.205479452054796e-05,
      "loss": 0.3641,
      "step": 390
    },
    {
      "epoch": 0.32,
      "grad_norm": 1.6703596115112305,
      "learning_rate": 9.178082191780822e-05,
      "loss": 0.3455,
      "step": 400
    },
    {
      "epoch": 0.32,
      "eval_loss": 0.3708334267139435,
      "eval_runtime": 24.7434,
      "eval_samples_per_second": 40.415,
      "eval_steps_per_second": 5.052,
      "step": 400
    },
    {
      "epoch": 0.328,
      "grad_norm": 4.374824523925781,
      "learning_rate": 9.15068493150685e-05,
      "loss": 0.3531,
      "step": 410
    },
    {
      "epoch": 0.336,
      "grad_norm": 1.697788953781128,
      "learning_rate": 9.123287671232878e-05,
      "loss": 0.3416,
      "step": 420
    },
    {
      "epoch": 0.344,
      "grad_norm": 2.3812129497528076,
      "learning_rate": 9.095890410958905e-05,
      "loss": 0.3841,
      "step": 430
    },
    {
      "epoch": 0.352,
      "grad_norm": 1.8174185752868652,
      "learning_rate": 9.068493150684932e-05,
      "loss": 0.3081,
      "step": 440
    },
    {
      "epoch": 0.36,
      "grad_norm": 1.3508046865463257,
      "learning_rate": 9.041095890410958e-05,
      "loss": 0.3191,
      "step": 450
    },
    {
      "epoch": 0.36,
      "eval_loss": 0.34883204102516174,
      "eval_runtime": 18.668,
      "eval_samples_per_second": 53.568,
      "eval_steps_per_second": 6.696,
      "step": 450
    },
    {
      "epoch": 0.368,
      "grad_norm": 1.3691033124923706,
      "learning_rate": 9.013698630136986e-05,
      "loss": 0.309,
      "step": 460
    },
    {
      "epoch": 0.376,
      "grad_norm": 1.2073757648468018,
      "learning_rate": 8.986301369863014e-05,
      "loss": 0.2978,
      "step": 470
    },
    {
      "epoch": 0.384,
      "grad_norm": 2.1590511798858643,
      "learning_rate": 8.958904109589042e-05,
      "loss": 0.2976,
      "step": 480
    },
    {
      "epoch": 0.392,
      "grad_norm": 1.16413414478302,
      "learning_rate": 8.93150684931507e-05,
      "loss": 0.2922,
      "step": 490
    },
    {
      "epoch": 0.4,
      "grad_norm": 3.9341678619384766,
      "learning_rate": 8.904109589041096e-05,
      "loss": 0.2941,
      "step": 500
    },
    {
      "epoch": 0.4,
      "eval_loss": 0.3859642446041107,
      "eval_runtime": 24.9489,
      "eval_samples_per_second": 40.082,
      "eval_steps_per_second": 5.01,
      "step": 500
    },
    {
      "epoch": 0.408,
      "grad_norm": 2.6154589653015137,
      "learning_rate": 8.876712328767124e-05,
      "loss": 0.2876,
      "step": 510
    },
    {
      "epoch": 0.416,
      "grad_norm": 2.497248649597168,
      "learning_rate": 8.849315068493151e-05,
      "loss": 0.3119,
      "step": 520
    },
    {
      "epoch": 0.424,
      "grad_norm": 1.472633719444275,
      "learning_rate": 8.821917808219179e-05,
      "loss": 0.2989,
      "step": 530
    },
    {
      "epoch": 0.432,
      "grad_norm": 1.8502038717269897,
      "learning_rate": 8.794520547945207e-05,
      "loss": 0.3137,
      "step": 540
    },
    {
      "epoch": 0.44,
      "grad_norm": 1.050938367843628,
      "learning_rate": 8.767123287671233e-05,
      "loss": 0.3037,
      "step": 550
    },
    {
      "epoch": 0.44,
      "eval_loss": 0.35872435569763184,
      "eval_runtime": 18.806,
      "eval_samples_per_second": 53.174,
      "eval_steps_per_second": 6.647,
      "step": 550
    },
    {
      "epoch": 0.448,
      "grad_norm": 1.5282026529312134,
      "learning_rate": 8.73972602739726e-05,
      "loss": 0.2948,
      "step": 560
    },
    {
      "epoch": 0.456,
      "grad_norm": 2.145148515701294,
      "learning_rate": 8.712328767123288e-05,
      "loss": 0.3266,
      "step": 570
    },
    {
      "epoch": 0.464,
      "grad_norm": 1.8586273193359375,
      "learning_rate": 8.684931506849315e-05,
      "loss": 0.3038,
      "step": 580
    },
    {
      "epoch": 0.472,
      "grad_norm": 1.7039552927017212,
      "learning_rate": 8.657534246575343e-05,
      "loss": 0.2691,
      "step": 590
    },
    {
      "epoch": 0.48,
      "grad_norm": 2.2973456382751465,
      "learning_rate": 8.630136986301371e-05,
      "loss": 0.3184,
      "step": 600
    },
    {
      "epoch": 0.48,
      "eval_loss": 0.3362461030483246,
      "eval_runtime": 24.9498,
      "eval_samples_per_second": 40.08,
      "eval_steps_per_second": 5.01,
      "step": 600
    },
    {
      "epoch": 0.488,
      "grad_norm": 1.7062853574752808,
      "learning_rate": 8.602739726027397e-05,
      "loss": 0.2559,
      "step": 610
    },
    {
      "epoch": 0.496,
      "grad_norm": 1.8234792947769165,
      "learning_rate": 8.575342465753425e-05,
      "loss": 0.2518,
      "step": 620
    },
    {
      "epoch": 0.504,
      "grad_norm": 1.6400330066680908,
      "learning_rate": 8.547945205479453e-05,
      "loss": 0.2925,
      "step": 630
    },
    {
      "epoch": 0.512,
      "grad_norm": 2.214301347732544,
      "learning_rate": 8.520547945205481e-05,
      "loss": 0.2854,
      "step": 640
    },
    {
      "epoch": 0.52,
      "grad_norm": 1.364565134048462,
      "learning_rate": 8.493150684931507e-05,
      "loss": 0.2295,
      "step": 650
    },
    {
      "epoch": 0.52,
      "eval_loss": 0.3094405233860016,
      "eval_runtime": 21.9023,
      "eval_samples_per_second": 45.657,
      "eval_steps_per_second": 5.707,
      "step": 650
    },
    {
      "epoch": 0.528,
      "grad_norm": 1.9325617551803589,
      "learning_rate": 8.465753424657534e-05,
      "loss": 0.2335,
      "step": 660
    },
    {
      "epoch": 0.536,
      "grad_norm": 1.4986159801483154,
      "learning_rate": 8.438356164383561e-05,
      "loss": 0.245,
      "step": 670
    },
    {
      "epoch": 0.544,
      "grad_norm": 1.392870306968689,
      "learning_rate": 8.410958904109589e-05,
      "loss": 0.2247,
      "step": 680
    },
    {
      "epoch": 0.552,
      "grad_norm": 2.7593588829040527,
      "learning_rate": 8.383561643835617e-05,
      "loss": 0.2295,
      "step": 690
    },
    {
      "epoch": 0.56,
      "grad_norm": 1.4241386651992798,
      "learning_rate": 8.356164383561645e-05,
      "loss": 0.2364,
      "step": 700
    },
    {
      "epoch": 0.56,
      "eval_loss": 0.2930518388748169,
      "eval_runtime": 24.8604,
      "eval_samples_per_second": 40.225,
      "eval_steps_per_second": 5.028,
      "step": 700
    },
    {
      "epoch": 0.568,
      "grad_norm": 1.4733610153198242,
      "learning_rate": 8.328767123287671e-05,
      "loss": 0.2114,
      "step": 710
    },
    {
      "epoch": 0.576,
      "grad_norm": 1.6124286651611328,
      "learning_rate": 8.301369863013699e-05,
      "loss": 0.2448,
      "step": 720
    },
    {
      "epoch": 0.584,
      "grad_norm": 1.3921416997909546,
      "learning_rate": 8.273972602739727e-05,
      "loss": 0.2658,
      "step": 730
    },
    {
      "epoch": 0.592,
      "grad_norm": 1.6910688877105713,
      "learning_rate": 8.246575342465755e-05,
      "loss": 0.1985,
      "step": 740
    },
    {
      "epoch": 0.6,
      "grad_norm": 1.8038325309753418,
      "learning_rate": 8.219178082191781e-05,
      "loss": 0.2066,
      "step": 750
    },
    {
      "epoch": 0.6,
      "eval_loss": 0.29361531138420105,
      "eval_runtime": 24.9499,
      "eval_samples_per_second": 40.08,
      "eval_steps_per_second": 5.01,
      "step": 750
    },
    {
      "epoch": 0.608,
      "grad_norm": 1.8469599485397339,
      "learning_rate": 8.191780821917809e-05,
      "loss": 0.2488,
      "step": 760
    },
    {
      "epoch": 0.616,
      "grad_norm": 1.635629653930664,
      "learning_rate": 8.164383561643835e-05,
      "loss": 0.1893,
      "step": 770
    },
    {
      "epoch": 0.624,
      "grad_norm": 1.888275384902954,
      "learning_rate": 8.136986301369863e-05,
      "loss": 0.2127,
      "step": 780
    },
    {
      "epoch": 0.632,
      "grad_norm": 1.1600341796875,
      "learning_rate": 8.109589041095891e-05,
      "loss": 0.2283,
      "step": 790
    },
    {
      "epoch": 0.64,
      "grad_norm": 1.9781181812286377,
      "learning_rate": 8.082191780821919e-05,
      "loss": 0.2176,
      "step": 800
    },
    {
      "epoch": 0.64,
      "eval_loss": 0.27110937237739563,
      "eval_runtime": 24.837,
      "eval_samples_per_second": 40.263,
      "eval_steps_per_second": 5.033,
      "step": 800
    },
    {
      "epoch": 0.648,
      "grad_norm": 1.8670518398284912,
      "learning_rate": 8.054794520547946e-05,
      "loss": 0.2309,
      "step": 810
    },
    {
      "epoch": 0.656,
      "grad_norm": 1.6251477003097534,
      "learning_rate": 8.027397260273973e-05,
      "loss": 0.2257,
      "step": 820
    },
    {
      "epoch": 0.664,
      "grad_norm": 1.6587255001068115,
      "learning_rate": 8e-05,
      "loss": 0.2173,
      "step": 830
    },
    {
      "epoch": 0.672,
      "grad_norm": 1.50548255443573,
      "learning_rate": 7.972602739726027e-05,
      "loss": 0.1953,
      "step": 840
    },
    {
      "epoch": 0.68,
      "grad_norm": 1.5516282320022583,
      "learning_rate": 7.945205479452055e-05,
      "loss": 0.1777,
      "step": 850
    },
    {
      "epoch": 0.68,
      "eval_loss": 0.2899059057235718,
      "eval_runtime": 24.5072,
      "eval_samples_per_second": 40.804,
      "eval_steps_per_second": 5.101,
      "step": 850
    },
    {
      "epoch": 0.688,
      "grad_norm": 1.3263165950775146,
      "learning_rate": 7.917808219178083e-05,
      "loss": 0.2091,
      "step": 860
    },
    {
      "epoch": 0.696,
      "grad_norm": 1.5650769472122192,
      "learning_rate": 7.890410958904109e-05,
      "loss": 0.182,
      "step": 870
    },
    {
      "epoch": 0.704,
      "grad_norm": 1.9725035429000854,
      "learning_rate": 7.863013698630137e-05,
      "loss": 0.2321,
      "step": 880
    },
    {
      "epoch": 0.712,
      "grad_norm": 1.315184235572815,
      "learning_rate": 7.835616438356165e-05,
      "loss": 0.2126,
      "step": 890
    },
    {
      "epoch": 0.72,
      "grad_norm": 1.2860090732574463,
      "learning_rate": 7.808219178082192e-05,
      "loss": 0.1784,
      "step": 900
    },
    {
      "epoch": 0.72,
      "eval_loss": 0.2692398130893707,
      "eval_runtime": 24.8184,
      "eval_samples_per_second": 40.293,
      "eval_steps_per_second": 5.037,
      "step": 900
    },
    {
      "epoch": 0.728,
      "grad_norm": 1.8414716720581055,
      "learning_rate": 7.78082191780822e-05,
      "loss": 0.2013,
      "step": 910
    },
    {
      "epoch": 0.736,
      "grad_norm": 1.288512110710144,
      "learning_rate": 7.753424657534247e-05,
      "loss": 0.1712,
      "step": 920
    },
    {
      "epoch": 0.744,
      "grad_norm": 1.305853009223938,
      "learning_rate": 7.726027397260274e-05,
      "loss": 0.1869,
      "step": 930
    },
    {
      "epoch": 0.752,
      "grad_norm": 1.6711593866348267,
      "learning_rate": 7.698630136986301e-05,
      "loss": 0.2053,
      "step": 940
    },
    {
      "epoch": 0.76,
      "grad_norm": 1.6298977136611938,
      "learning_rate": 7.671232876712329e-05,
      "loss": 0.1902,
      "step": 950
    },
    {
      "epoch": 0.76,
      "eval_loss": 0.29507988691329956,
      "eval_runtime": 24.8332,
      "eval_samples_per_second": 40.269,
      "eval_steps_per_second": 5.034,
      "step": 950
    },
    {
      "epoch": 0.768,
      "grad_norm": 2.3082284927368164,
      "learning_rate": 7.643835616438356e-05,
      "loss": 0.1769,
      "step": 960
    },
    {
      "epoch": 0.776,
      "grad_norm": 1.2768274545669556,
      "learning_rate": 7.616438356164384e-05,
      "loss": 0.1531,
      "step": 970
    },
    {
      "epoch": 0.784,
      "grad_norm": 2.2713019847869873,
      "learning_rate": 7.589041095890411e-05,
      "loss": 0.1699,
      "step": 980
    },
    {
      "epoch": 0.792,
      "grad_norm": 1.6474982500076294,
      "learning_rate": 7.561643835616439e-05,
      "loss": 0.2053,
      "step": 990
    },
    {
      "epoch": 0.8,
      "grad_norm": 1.2655808925628662,
      "learning_rate": 7.534246575342466e-05,
      "loss": 0.1715,
      "step": 1000
    },
    {
      "epoch": 0.8,
      "eval_loss": 0.2587527930736542,
      "eval_runtime": 24.8399,
      "eval_samples_per_second": 40.258,
      "eval_steps_per_second": 5.032,
      "step": 1000
    },
    {
      "epoch": 0.808,
      "grad_norm": 2.276134490966797,
      "learning_rate": 7.506849315068494e-05,
      "loss": 0.1558,
      "step": 1010
    },
    {
      "epoch": 0.816,
      "grad_norm": 1.5761502981185913,
      "learning_rate": 7.479452054794522e-05,
      "loss": 0.1669,
      "step": 1020
    },
    {
      "epoch": 0.824,
      "grad_norm": 1.639851450920105,
      "learning_rate": 7.452054794520548e-05,
      "loss": 0.1672,
      "step": 1030
    },
    {
      "epoch": 0.832,
      "grad_norm": 1.4605337381362915,
      "learning_rate": 7.424657534246575e-05,
      "loss": 0.1637,
      "step": 1040
    },
    {
      "epoch": 0.84,
      "grad_norm": 1.1747487783432007,
      "learning_rate": 7.397260273972603e-05,
      "loss": 0.1657,
      "step": 1050
    },
    {
      "epoch": 0.84,
      "eval_loss": 0.24422861635684967,
      "eval_runtime": 24.8088,
      "eval_samples_per_second": 40.308,
      "eval_steps_per_second": 5.039,
      "step": 1050
    },
    {
      "epoch": 0.848,
      "grad_norm": 1.145734190940857,
      "learning_rate": 7.36986301369863e-05,
      "loss": 0.1574,
      "step": 1060
    },
    {
      "epoch": 0.856,
      "grad_norm": 1.6274511814117432,
      "learning_rate": 7.342465753424658e-05,
      "loss": 0.1467,
      "step": 1070
    },
    {
      "epoch": 0.864,
      "grad_norm": 1.4507982730865479,
      "learning_rate": 7.315068493150685e-05,
      "loss": 0.1395,
      "step": 1080
    },
    {
      "epoch": 0.872,
      "grad_norm": 1.8462451696395874,
      "learning_rate": 7.287671232876712e-05,
      "loss": 0.1514,
      "step": 1090
    },
    {
      "epoch": 0.88,
      "grad_norm": 0.6151412725448608,
      "learning_rate": 7.26027397260274e-05,
      "loss": 0.1615,
      "step": 1100
    },
    {
      "epoch": 0.88,
      "eval_loss": 0.26580244302749634,
      "eval_runtime": 24.817,
      "eval_samples_per_second": 40.295,
      "eval_steps_per_second": 5.037,
      "step": 1100
    },
    {
      "epoch": 0.888,
      "grad_norm": 1.690218210220337,
      "learning_rate": 7.232876712328768e-05,
      "loss": 0.2012,
      "step": 1110
    },
    {
      "epoch": 0.896,
      "grad_norm": 2.2413172721862793,
      "learning_rate": 7.205479452054796e-05,
      "loss": 0.1476,
      "step": 1120
    },
    {
      "epoch": 0.904,
      "grad_norm": 1.1031889915466309,
      "learning_rate": 7.178082191780822e-05,
      "loss": 0.1199,
      "step": 1130
    },
    {
      "epoch": 0.912,
      "grad_norm": 1.6899330615997314,
      "learning_rate": 7.150684931506849e-05,
      "loss": 0.1597,
      "step": 1140
    },
    {
      "epoch": 0.92,
      "grad_norm": 1.488455057144165,
      "learning_rate": 7.123287671232876e-05,
      "loss": 0.1411,
      "step": 1150
    },
    {
      "epoch": 0.92,
      "eval_loss": 0.25971555709838867,
      "eval_runtime": 24.8339,
      "eval_samples_per_second": 40.268,
      "eval_steps_per_second": 5.033,
      "step": 1150
    },
    {
      "epoch": 0.928,
      "grad_norm": 1.380375623703003,
      "learning_rate": 7.095890410958904e-05,
      "loss": 0.1536,
      "step": 1160
    },
    {
      "epoch": 0.936,
      "grad_norm": 1.2481878995895386,
      "learning_rate": 7.068493150684932e-05,
      "loss": 0.1571,
      "step": 1170
    },
    {
      "epoch": 0.944,
      "grad_norm": 1.4721931219100952,
      "learning_rate": 7.04109589041096e-05,
      "loss": 0.1597,
      "step": 1180
    },
    {
      "epoch": 0.952,
      "grad_norm": 1.4984403848648071,
      "learning_rate": 7.013698630136986e-05,
      "loss": 0.1213,
      "step": 1190
    },
    {
      "epoch": 0.96,
      "grad_norm": 1.8597270250320435,
      "learning_rate": 6.986301369863014e-05,
      "loss": 0.1447,
      "step": 1200
    },
    {
      "epoch": 0.96,
      "eval_loss": 0.2481565624475479,
      "eval_runtime": 24.8858,
      "eval_samples_per_second": 40.184,
      "eval_steps_per_second": 5.023,
      "step": 1200
    },
    {
      "epoch": 0.968,
      "grad_norm": 0.7994334101676941,
      "learning_rate": 6.958904109589042e-05,
      "loss": 0.1135,
      "step": 1210
    },
    {
      "epoch": 0.976,
      "grad_norm": 1.361968755722046,
      "learning_rate": 6.93150684931507e-05,
      "loss": 0.1541,
      "step": 1220
    },
    {
      "epoch": 0.984,
      "grad_norm": 1.4471145868301392,
      "learning_rate": 6.904109589041097e-05,
      "loss": 0.1243,
      "step": 1230
    },
    {
      "epoch": 0.992,
      "grad_norm": 1.3099193572998047,
      "learning_rate": 6.876712328767124e-05,
      "loss": 0.1287,
      "step": 1240
    },
    {
      "epoch": 1.0,
      "grad_norm": 0.9892821311950684,
      "learning_rate": 6.84931506849315e-05,
      "loss": 0.1732,
      "step": 1250
    },
    {
      "epoch": 1.0,
      "eval_loss": 0.260714054107666,
      "eval_runtime": 24.9382,
      "eval_samples_per_second": 40.099,
      "eval_steps_per_second": 5.012,
      "step": 1250
    },
    {
      "epoch": 1.008,
      "grad_norm": 1.307409644126892,
      "learning_rate": 6.821917808219178e-05,
      "loss": 0.1303,
      "step": 1260
    },
    {
      "epoch": 1.016,
      "grad_norm": 1.3596787452697754,
      "learning_rate": 6.794520547945206e-05,
      "loss": 0.127,
      "step": 1270
    },
    {
      "epoch": 1.024,
      "grad_norm": 4.548017978668213,
      "learning_rate": 6.767123287671234e-05,
      "loss": 0.1097,
      "step": 1280
    },
    {
      "epoch": 1.032,
      "grad_norm": 1.114829182624817,
      "learning_rate": 6.73972602739726e-05,
      "loss": 0.1244,
      "step": 1290
    },
    {
      "epoch": 1.04,
      "grad_norm": 1.3981624841690063,
      "learning_rate": 6.712328767123288e-05,
      "loss": 0.1592,
      "step": 1300
    },
    {
      "epoch": 1.04,
      "eval_loss": 0.24839119613170624,
      "eval_runtime": 24.8243,
      "eval_samples_per_second": 40.283,
      "eval_steps_per_second": 5.035,
      "step": 1300
    },
    {
      "epoch": 1.048,
      "grad_norm": 1.4718713760375977,
      "learning_rate": 6.684931506849316e-05,
      "loss": 0.1202,
      "step": 1310
    },
    {
      "epoch": 1.056,
      "grad_norm": 1.0976980924606323,
      "learning_rate": 6.657534246575343e-05,
      "loss": 0.1407,
      "step": 1320
    },
    {
      "epoch": 1.064,
      "grad_norm": 1.248806118965149,
      "learning_rate": 6.630136986301371e-05,
      "loss": 0.1231,
      "step": 1330
    },
    {
      "epoch": 1.072,
      "grad_norm": 2.993288516998291,
      "learning_rate": 6.602739726027398e-05,
      "loss": 0.1194,
      "step": 1340
    },
    {
      "epoch": 1.08,
      "grad_norm": 1.8662015199661255,
      "learning_rate": 6.575342465753424e-05,
      "loss": 0.1111,
      "step": 1350
    },
    {
      "epoch": 1.08,
      "eval_loss": 0.24670253694057465,
      "eval_runtime": 18.0807,
      "eval_samples_per_second": 55.308,
      "eval_steps_per_second": 6.913,
      "step": 1350
    },
    {
      "epoch": 1.088,
      "grad_norm": 1.0976550579071045,
      "learning_rate": 6.547945205479452e-05,
      "loss": 0.1314,
      "step": 1360
    },
    {
      "epoch": 1.096,
      "grad_norm": 1.2544418573379517,
      "learning_rate": 6.52054794520548e-05,
      "loss": 0.1096,
      "step": 1370
    },
    {
      "epoch": 1.104,
      "grad_norm": 1.1751530170440674,
      "learning_rate": 6.493150684931507e-05,
      "loss": 0.1311,
      "step": 1380
    },
    {
      "epoch": 1.112,
      "grad_norm": 0.8764196634292603,
      "learning_rate": 6.465753424657535e-05,
      "loss": 0.1394,
      "step": 1390
    },
    {
      "epoch": 1.12,
      "grad_norm": 1.1098536252975464,
      "learning_rate": 6.438356164383562e-05,
      "loss": 0.0919,
      "step": 1400
    },
    {
      "epoch": 1.12,
      "eval_loss": 0.25597938895225525,
      "eval_runtime": 17.8616,
      "eval_samples_per_second": 55.986,
      "eval_steps_per_second": 6.998,
      "step": 1400
    },
    {
      "epoch": 1.1280000000000001,
      "grad_norm": 1.483540654182434,
      "learning_rate": 6.41095890410959e-05,
      "loss": 0.0994,
      "step": 1410
    },
    {
      "epoch": 1.1360000000000001,
      "grad_norm": 2.5229275226593018,
      "learning_rate": 6.383561643835617e-05,
      "loss": 0.1118,
      "step": 1420
    },
    {
      "epoch": 1.144,
      "grad_norm": 2.014272689819336,
      "learning_rate": 6.356164383561645e-05,
      "loss": 0.112,
      "step": 1430
    },
    {
      "epoch": 1.152,
      "grad_norm": 0.9553103446960449,
      "learning_rate": 6.328767123287671e-05,
      "loss": 0.1207,
      "step": 1440
    },
    {
      "epoch": 1.16,
      "grad_norm": 1.4528369903564453,
      "learning_rate": 6.301369863013699e-05,
      "loss": 0.1068,
      "step": 1450
    },
    {
      "epoch": 1.16,
      "eval_loss": 0.2479792684316635,
      "eval_runtime": 18.3586,
      "eval_samples_per_second": 54.47,
      "eval_steps_per_second": 6.809,
      "step": 1450
    },
    {
      "epoch": 1.168,
      "grad_norm": 0.9160047769546509,
      "learning_rate": 6.273972602739726e-05,
      "loss": 0.1311,
      "step": 1460
    },
    {
      "epoch": 1.176,
      "grad_norm": 1.639249563217163,
      "learning_rate": 6.246575342465753e-05,
      "loss": 0.1056,
      "step": 1470
    },
    {
      "epoch": 1.184,
      "grad_norm": 1.0985738039016724,
      "learning_rate": 6.219178082191781e-05,
      "loss": 0.1384,
      "step": 1480
    },
    {
      "epoch": 1.192,
      "grad_norm": 2.6156015396118164,
      "learning_rate": 6.191780821917809e-05,
      "loss": 0.1268,
      "step": 1490
    },
    {
      "epoch": 1.2,
      "grad_norm": 1.7791260480880737,
      "learning_rate": 6.164383561643835e-05,
      "loss": 0.1091,
      "step": 1500
    },
    {
      "epoch": 1.2,
      "eval_loss": 0.23496121168136597,
      "eval_runtime": 18.5101,
      "eval_samples_per_second": 54.024,
      "eval_steps_per_second": 6.753,
      "step": 1500
    },
    {
      "epoch": 1.208,
      "grad_norm": 1.7722536325454712,
      "learning_rate": 6.136986301369863e-05,
      "loss": 0.1357,
      "step": 1510
    },
    {
      "epoch": 1.216,
      "grad_norm": 1.868872880935669,
      "learning_rate": 6.109589041095891e-05,
      "loss": 0.1128,
      "step": 1520
    },
    {
      "epoch": 1.224,
      "grad_norm": 1.1328438520431519,
      "learning_rate": 6.082191780821919e-05,
      "loss": 0.0977,
      "step": 1530
    },
    {
      "epoch": 1.232,
      "grad_norm": 2.4050562381744385,
      "learning_rate": 6.054794520547945e-05,
      "loss": 0.0993,
      "step": 1540
    },
    {
      "epoch": 1.24,
      "grad_norm": 1.660123348236084,
      "learning_rate": 6.0273972602739724e-05,
      "loss": 0.0969,
      "step": 1550
    },
    {
      "epoch": 1.24,
      "eval_loss": 0.24920648336410522,
      "eval_runtime": 18.4114,
      "eval_samples_per_second": 54.314,
      "eval_steps_per_second": 6.789,
      "step": 1550
    },
    {
      "epoch": 1.248,
      "grad_norm": 1.0388494729995728,
      "learning_rate": 6e-05,
      "loss": 0.0902,
      "step": 1560
    },
    {
      "epoch": 1.256,
      "grad_norm": 0.7607935667037964,
      "learning_rate": 5.972602739726027e-05,
      "loss": 0.1025,
      "step": 1570
    },
    {
      "epoch": 1.264,
      "grad_norm": 1.3437362909317017,
      "learning_rate": 5.945205479452055e-05,
      "loss": 0.1277,
      "step": 1580
    },
    {
      "epoch": 1.272,
      "grad_norm": 1.9008346796035767,
      "learning_rate": 5.917808219178083e-05,
      "loss": 0.1263,
      "step": 1590
    },
    {
      "epoch": 1.28,
      "grad_norm": 1.274158000946045,
      "learning_rate": 5.89041095890411e-05,
      "loss": 0.1122,
      "step": 1600
    },
    {
      "epoch": 1.28,
      "eval_loss": 0.22301599383354187,
      "eval_runtime": 18.5559,
      "eval_samples_per_second": 53.891,
      "eval_steps_per_second": 6.736,
      "step": 1600
    },
    {
      "epoch": 1.288,
      "grad_norm": 0.4918229877948761,
      "learning_rate": 5.863013698630138e-05,
      "loss": 0.1387,
      "step": 1610
    },
    {
      "epoch": 1.296,
      "grad_norm": 2.399345874786377,
      "learning_rate": 5.835616438356165e-05,
      "loss": 0.1207,
      "step": 1620
    },
    {
      "epoch": 1.304,
      "grad_norm": 1.6321951150894165,
      "learning_rate": 5.808219178082191e-05,
      "loss": 0.0883,
      "step": 1630
    },
    {
      "epoch": 1.312,
      "grad_norm": 1.5418812036514282,
      "learning_rate": 5.780821917808219e-05,
      "loss": 0.0951,
      "step": 1640
    },
    {
      "epoch": 1.32,
      "grad_norm": 1.2246149778366089,
      "learning_rate": 5.753424657534247e-05,
      "loss": 0.116,
      "step": 1650
    },
    {
      "epoch": 1.32,
      "eval_loss": 0.23912425339221954,
      "eval_runtime": 18.2892,
      "eval_samples_per_second": 54.677,
      "eval_steps_per_second": 6.835,
      "step": 1650
    },
    {
      "epoch": 1.328,
      "grad_norm": 1.564244270324707,
      "learning_rate": 5.726027397260274e-05,
      "loss": 0.1056,
      "step": 1660
    },
    {
      "epoch": 1.336,
      "grad_norm": 0.6236838102340698,
      "learning_rate": 5.698630136986302e-05,
      "loss": 0.1108,
      "step": 1670
    },
    {
      "epoch": 1.3439999999999999,
      "grad_norm": 1.367423415184021,
      "learning_rate": 5.671232876712329e-05,
      "loss": 0.1027,
      "step": 1680
    },
    {
      "epoch": 1.3519999999999999,
      "grad_norm": 2.3690881729125977,
      "learning_rate": 5.643835616438357e-05,
      "loss": 0.1076,
      "step": 1690
    },
    {
      "epoch": 1.3599999999999999,
      "grad_norm": 1.0713485479354858,
      "learning_rate": 5.616438356164384e-05,
      "loss": 0.0711,
      "step": 1700
    },
    {
      "epoch": 1.3599999999999999,
      "eval_loss": 0.23415832221508026,
      "eval_runtime": 18.5164,
      "eval_samples_per_second": 54.006,
      "eval_steps_per_second": 6.751,
      "step": 1700
    },
    {
      "epoch": 1.3679999999999999,
      "grad_norm": 1.1982767581939697,
      "learning_rate": 5.5890410958904116e-05,
      "loss": 0.1095,
      "step": 1710
    },
    {
      "epoch": 1.376,
      "grad_norm": 2.030862331390381,
      "learning_rate": 5.5616438356164394e-05,
      "loss": 0.0928,
      "step": 1720
    },
    {
      "epoch": 1.384,
      "grad_norm": 2.3972980976104736,
      "learning_rate": 5.534246575342466e-05,
      "loss": 0.1017,
      "step": 1730
    },
    {
      "epoch": 1.392,
      "grad_norm": 0.9659988880157471,
      "learning_rate": 5.506849315068493e-05,
      "loss": 0.0967,
      "step": 1740
    },
    {
      "epoch": 1.4,
      "grad_norm": 0.5235807299613953,
      "learning_rate": 5.479452054794521e-05,
      "loss": 0.0882,
      "step": 1750
    },
    {
      "epoch": 1.4,
      "eval_loss": 0.22954817116260529,
      "eval_runtime": 18.5571,
      "eval_samples_per_second": 53.888,
      "eval_steps_per_second": 6.736,
      "step": 1750
    },
    {
      "epoch": 1.408,
      "grad_norm": 1.8374351263046265,
      "learning_rate": 5.452054794520548e-05,
      "loss": 0.1017,
      "step": 1760
    },
    {
      "epoch": 1.416,
      "grad_norm": 1.3665727376937866,
      "learning_rate": 5.4246575342465756e-05,
      "loss": 0.1161,
      "step": 1770
    },
    {
      "epoch": 1.424,
      "grad_norm": 1.2117130756378174,
      "learning_rate": 5.397260273972603e-05,
      "loss": 0.0903,
      "step": 1780
    },
    {
      "epoch": 1.432,
      "grad_norm": 0.494384765625,
      "learning_rate": 5.3698630136986305e-05,
      "loss": 0.0953,
      "step": 1790
    },
    {
      "epoch": 1.44,
      "grad_norm": 1.148492693901062,
      "learning_rate": 5.342465753424658e-05,
      "loss": 0.1017,
      "step": 1800
    },
    {
      "epoch": 1.44,
      "eval_loss": 0.23621296882629395,
      "eval_runtime": 18.6929,
      "eval_samples_per_second": 53.496,
      "eval_steps_per_second": 6.687,
      "step": 1800
    },
    {
      "epoch": 1.448,
      "grad_norm": 0.9059622287750244,
      "learning_rate": 5.3150684931506854e-05,
      "loss": 0.0747,
      "step": 1810
    },
    {
      "epoch": 1.456,
      "grad_norm": 0.9492471814155579,
      "learning_rate": 5.287671232876713e-05,
      "loss": 0.0997,
      "step": 1820
    },
    {
      "epoch": 1.464,
      "grad_norm": 1.563873291015625,
      "learning_rate": 5.2602739726027396e-05,
      "loss": 0.0948,
      "step": 1830
    },
    {
      "epoch": 1.472,
      "grad_norm": 0.9548035264015198,
      "learning_rate": 5.232876712328767e-05,
      "loss": 0.0732,
      "step": 1840
    },
    {
      "epoch": 1.48,
      "grad_norm": 0.6475477814674377,
      "learning_rate": 5.2054794520547945e-05,
      "loss": 0.0514,
      "step": 1850
    },
    {
      "epoch": 1.48,
      "eval_loss": 0.25186431407928467,
      "eval_runtime": 23.3139,
      "eval_samples_per_second": 42.893,
      "eval_steps_per_second": 5.362,
      "step": 1850
    },
    {
      "epoch": 1.488,
      "grad_norm": 0.5346883535385132,
      "learning_rate": 5.178082191780822e-05,
      "loss": 0.1072,
      "step": 1860
    },
    {
      "epoch": 1.496,
      "grad_norm": 0.6826255917549133,
      "learning_rate": 5.1506849315068494e-05,
      "loss": 0.0806,
      "step": 1870
    },
    {
      "epoch": 1.504,
      "grad_norm": 1.225182056427002,
      "learning_rate": 5.123287671232877e-05,
      "loss": 0.1077,
      "step": 1880
    },
    {
      "epoch": 1.512,
      "grad_norm": 1.0838868618011475,
      "learning_rate": 5.095890410958904e-05,
      "loss": 0.0876,
      "step": 1890
    },
    {
      "epoch": 1.52,
      "grad_norm": 1.2794407606124878,
      "learning_rate": 5.068493150684932e-05,
      "loss": 0.0904,
      "step": 1900
    },
    {
      "epoch": 1.52,
      "eval_loss": 0.23514826595783234,
      "eval_runtime": 24.7733,
      "eval_samples_per_second": 40.366,
      "eval_steps_per_second": 5.046,
      "step": 1900
    },
    {
      "epoch": 1.528,
      "grad_norm": 1.2834234237670898,
      "learning_rate": 5.041095890410959e-05,
      "loss": 0.113,
      "step": 1910
    },
    {
      "epoch": 1.536,
      "grad_norm": 0.8498753309249878,
      "learning_rate": 5.013698630136987e-05,
      "loss": 0.0755,
      "step": 1920
    },
    {
      "epoch": 1.544,
      "grad_norm": 1.298750877380371,
      "learning_rate": 4.986301369863014e-05,
      "loss": 0.0812,
      "step": 1930
    },
    {
      "epoch": 1.552,
      "grad_norm": 1.800960659980774,
      "learning_rate": 4.958904109589041e-05,
      "loss": 0.0675,
      "step": 1940
    },
    {
      "epoch": 1.56,
      "grad_norm": 0.9642617106437683,
      "learning_rate": 4.9315068493150684e-05,
      "loss": 0.0915,
      "step": 1950
    },
    {
      "epoch": 1.56,
      "eval_loss": 0.253357470035553,
      "eval_runtime": 24.7099,
      "eval_samples_per_second": 40.47,
      "eval_steps_per_second": 5.059,
      "step": 1950
    },
    {
      "epoch": 1.568,
      "grad_norm": 1.12799870967865,
      "learning_rate": 4.904109589041096e-05,
      "loss": 0.069,
      "step": 1960
    },
    {
      "epoch": 1.576,
      "grad_norm": 0.612479567527771,
      "learning_rate": 4.876712328767123e-05,
      "loss": 0.0987,
      "step": 1970
    },
    {
      "epoch": 1.584,
      "grad_norm": 0.978496789932251,
      "learning_rate": 4.849315068493151e-05,
      "loss": 0.0907,
      "step": 1980
    },
    {
      "epoch": 1.592,
      "grad_norm": 1.6082817316055298,
      "learning_rate": 4.821917808219178e-05,
      "loss": 0.0908,
      "step": 1990
    },
    {
      "epoch": 1.6,
      "grad_norm": 1.0921881198883057,
      "learning_rate": 4.794520547945205e-05,
      "loss": 0.0839,
      "step": 2000
    },
    {
      "epoch": 1.6,
      "eval_loss": 0.23474261164665222,
      "eval_runtime": 24.6488,
      "eval_samples_per_second": 40.57,
      "eval_steps_per_second": 5.071,
      "step": 2000
    },
    {
      "epoch": 1.608,
      "grad_norm": 1.4330424070358276,
      "learning_rate": 4.767123287671233e-05,
      "loss": 0.1043,
      "step": 2010
    },
    {
      "epoch": 1.616,
      "grad_norm": 0.8260861039161682,
      "learning_rate": 4.73972602739726e-05,
      "loss": 0.0858,
      "step": 2020
    },
    {
      "epoch": 1.624,
      "grad_norm": 3.5593349933624268,
      "learning_rate": 4.712328767123288e-05,
      "loss": 0.0953,
      "step": 2030
    },
    {
      "epoch": 1.6320000000000001,
      "grad_norm": 0.5890489220619202,
      "learning_rate": 4.684931506849316e-05,
      "loss": 0.0699,
      "step": 2040
    },
    {
      "epoch": 1.6400000000000001,
      "grad_norm": 1.9446837902069092,
      "learning_rate": 4.657534246575342e-05,
      "loss": 0.1002,
      "step": 2050
    },
    {
      "epoch": 1.6400000000000001,
      "eval_loss": 0.24536734819412231,
      "eval_runtime": 24.7948,
      "eval_samples_per_second": 40.331,
      "eval_steps_per_second": 5.041,
      "step": 2050
    },
    {
      "epoch": 1.6480000000000001,
      "grad_norm": 1.1251742839813232,
      "learning_rate": 4.63013698630137e-05,
      "loss": 0.0954,
      "step": 2060
    },
    {
      "epoch": 1.6560000000000001,
      "grad_norm": 2.8996634483337402,
      "learning_rate": 4.602739726027398e-05,
      "loss": 0.0957,
      "step": 2070
    },
    {
      "epoch": 1.6640000000000001,
      "grad_norm": 1.4239124059677124,
      "learning_rate": 4.575342465753425e-05,
      "loss": 0.0712,
      "step": 2080
    },
    {
      "epoch": 1.6720000000000002,
      "grad_norm": 1.1117709875106812,
      "learning_rate": 4.547945205479453e-05,
      "loss": 0.0606,
      "step": 2090
    },
    {
      "epoch": 1.6800000000000002,
      "grad_norm": 0.4212247133255005,
      "learning_rate": 4.520547945205479e-05,
      "loss": 0.0614,
      "step": 2100
    },
    {
      "epoch": 1.6800000000000002,
      "eval_loss": 0.23057211935520172,
      "eval_runtime": 24.5885,
      "eval_samples_per_second": 40.669,
      "eval_steps_per_second": 5.084,
      "step": 2100
    },
    {
      "epoch": 1.688,
      "grad_norm": 0.544821560382843,
      "learning_rate": 4.493150684931507e-05,
      "loss": 0.069,
      "step": 2110
    },
    {
      "epoch": 1.696,
      "grad_norm": 1.0012943744659424,
      "learning_rate": 4.465753424657535e-05,
      "loss": 0.0756,
      "step": 2120
    },
    {
      "epoch": 1.704,
      "grad_norm": 0.8744885325431824,
      "learning_rate": 4.438356164383562e-05,
      "loss": 0.0646,
      "step": 2130
    },
    {
      "epoch": 1.712,
      "grad_norm": 0.8644313216209412,
      "learning_rate": 4.4109589041095896e-05,
      "loss": 0.0569,
      "step": 2140
    },
    {
      "epoch": 1.72,
      "grad_norm": 0.4704446792602539,
      "learning_rate": 4.383561643835617e-05,
      "loss": 0.0895,
      "step": 2150
    },
    {
      "epoch": 1.72,
      "eval_loss": 0.2602672874927521,
      "eval_runtime": 24.6049,
      "eval_samples_per_second": 40.642,
      "eval_steps_per_second": 5.08,
      "step": 2150
    },
    {
      "epoch": 1.728,
      "grad_norm": 0.940700888633728,
      "learning_rate": 4.356164383561644e-05,
      "loss": 0.0975,
      "step": 2160
    },
    {
      "epoch": 1.736,
      "grad_norm": 0.6912893056869507,
      "learning_rate": 4.3287671232876716e-05,
      "loss": 0.0534,
      "step": 2170
    },
    {
      "epoch": 1.744,
      "grad_norm": 1.5446268320083618,
      "learning_rate": 4.301369863013699e-05,
      "loss": 0.0872,
      "step": 2180
    },
    {
      "epoch": 1.752,
      "grad_norm": 0.5742741227149963,
      "learning_rate": 4.2739726027397265e-05,
      "loss": 0.0611,
      "step": 2190
    },
    {
      "epoch": 1.76,
      "grad_norm": 1.3469033241271973,
      "learning_rate": 4.2465753424657536e-05,
      "loss": 0.0716,
      "step": 2200
    },
    {
      "epoch": 1.76,
      "eval_loss": 0.26883813738822937,
      "eval_runtime": 24.7796,
      "eval_samples_per_second": 40.356,
      "eval_steps_per_second": 5.044,
      "step": 2200
    },
    {
      "epoch": 1.768,
      "grad_norm": 20.287694931030273,
      "learning_rate": 4.219178082191781e-05,
      "loss": 0.0891,
      "step": 2210
    },
    {
      "epoch": 1.776,
      "grad_norm": 1.5542397499084473,
      "learning_rate": 4.1917808219178085e-05,
      "loss": 0.0754,
      "step": 2220
    },
    {
      "epoch": 1.784,
      "grad_norm": 1.584434986114502,
      "learning_rate": 4.1643835616438356e-05,
      "loss": 0.0919,
      "step": 2230
    },
    {
      "epoch": 1.792,
      "grad_norm": 0.8370025157928467,
      "learning_rate": 4.1369863013698634e-05,
      "loss": 0.061,
      "step": 2240
    },
    {
      "epoch": 1.8,
      "grad_norm": 0.5933858752250671,
      "learning_rate": 4.1095890410958905e-05,
      "loss": 0.1098,
      "step": 2250
    },
    {
      "epoch": 1.8,
      "eval_loss": 0.25059664249420166,
      "eval_runtime": 24.551,
      "eval_samples_per_second": 40.731,
      "eval_steps_per_second": 5.091,
      "step": 2250
    },
    {
      "epoch": 1.808,
      "grad_norm": 1.1139296293258667,
      "learning_rate": 4.0821917808219176e-05,
      "loss": 0.0955,
      "step": 2260
    },
    {
      "epoch": 1.8159999999999998,
      "grad_norm": 0.5950649380683899,
      "learning_rate": 4.0547945205479454e-05,
      "loss": 0.0694,
      "step": 2270
    },
    {
      "epoch": 1.8239999999999998,
      "grad_norm": 0.7314907908439636,
      "learning_rate": 4.027397260273973e-05,
      "loss": 0.0852,
      "step": 2280
    },
    {
      "epoch": 1.8319999999999999,
      "grad_norm": 0.34100833535194397,
      "learning_rate": 4e-05,
      "loss": 0.0891,
      "step": 2290
    },
    {
      "epoch": 1.8399999999999999,
      "grad_norm": 1.09017014503479,
      "learning_rate": 3.9726027397260274e-05,
      "loss": 0.0631,
      "step": 2300
    },
    {
      "epoch": 1.8399999999999999,
      "eval_loss": 0.2800767421722412,
      "eval_runtime": 24.7422,
      "eval_samples_per_second": 40.417,
      "eval_steps_per_second": 5.052,
      "step": 2300
    },
    {
      "epoch": 1.8479999999999999,
      "grad_norm": 1.090883731842041,
      "learning_rate": 3.9452054794520546e-05,
      "loss": 0.0789,
      "step": 2310
    },
    {
      "epoch": 1.8559999999999999,
      "grad_norm": 2.0016398429870605,
      "learning_rate": 3.9178082191780823e-05,
      "loss": 0.086,
      "step": 2320
    },
    {
      "epoch": 1.8639999999999999,
      "grad_norm": 1.0737122297286987,
      "learning_rate": 3.89041095890411e-05,
      "loss": 0.0653,
      "step": 2330
    },
    {
      "epoch": 1.8719999999999999,
      "grad_norm": 0.7912832498550415,
      "learning_rate": 3.863013698630137e-05,
      "loss": 0.0387,
      "step": 2340
    },
    {
      "epoch": 1.88,
      "grad_norm": 1.4326428174972534,
      "learning_rate": 3.8356164383561644e-05,
      "loss": 0.0853,
      "step": 2350
    },
    {
      "epoch": 1.88,
      "eval_loss": 0.28604987263679504,
      "eval_runtime": 18.5574,
      "eval_samples_per_second": 53.887,
      "eval_steps_per_second": 6.736,
      "step": 2350
    },
    {
      "epoch": 1.888,
      "grad_norm": 0.825950026512146,
      "learning_rate": 3.808219178082192e-05,
      "loss": 0.0676,
      "step": 2360
    },
    {
      "epoch": 1.896,
      "grad_norm": 1.8131433725357056,
      "learning_rate": 3.780821917808219e-05,
      "loss": 0.0727,
      "step": 2370
    },
    {
      "epoch": 1.904,
      "grad_norm": 1.6796848773956299,
      "learning_rate": 3.753424657534247e-05,
      "loss": 0.0656,
      "step": 2380
    },
    {
      "epoch": 1.912,
      "grad_norm": 0.7453476786613464,
      "learning_rate": 3.726027397260274e-05,
      "loss": 0.0642,
      "step": 2390
    },
    {
      "epoch": 1.92,
      "grad_norm": 0.6287398934364319,
      "learning_rate": 3.698630136986301e-05,
      "loss": 0.0919,
      "step": 2400
    },
    {
      "epoch": 1.92,
      "eval_loss": 0.280868262052536,
      "eval_runtime": 18.1865,
      "eval_samples_per_second": 54.986,
      "eval_steps_per_second": 6.873,
      "step": 2400
    },
    {
      "epoch": 1.928,
      "grad_norm": 1.061767816543579,
      "learning_rate": 3.671232876712329e-05,
      "loss": 0.0689,
      "step": 2410
    },
    {
      "epoch": 1.936,
      "grad_norm": 0.8846475481987,
      "learning_rate": 3.643835616438356e-05,
      "loss": 0.0677,
      "step": 2420
    },
    {
      "epoch": 1.944,
      "grad_norm": 1.626930832862854,
      "learning_rate": 3.616438356164384e-05,
      "loss": 0.068,
      "step": 2430
    },
    {
      "epoch": 1.952,
      "grad_norm": 1.600319743156433,
      "learning_rate": 3.589041095890411e-05,
      "loss": 0.0443,
      "step": 2440
    },
    {
      "epoch": 1.96,
      "grad_norm": 0.8420302271842957,
      "learning_rate": 3.561643835616438e-05,
      "loss": 0.046,
      "step": 2450
    },
    {
      "epoch": 1.96,
      "eval_loss": 0.27119180560112,
      "eval_runtime": 18.0129,
      "eval_samples_per_second": 55.516,
      "eval_steps_per_second": 6.939,
      "step": 2450
    },
    {
      "epoch": 1.968,
      "grad_norm": 0.414347767829895,
      "learning_rate": 3.534246575342466e-05,
      "loss": 0.0625,
      "step": 2460
    },
    {
      "epoch": 1.976,
      "grad_norm": 1.4279108047485352,
      "learning_rate": 3.506849315068493e-05,
      "loss": 0.0696,
      "step": 2470
    },
    {
      "epoch": 1.984,
      "grad_norm": 0.8159459829330444,
      "learning_rate": 3.479452054794521e-05,
      "loss": 0.073,
      "step": 2480
    },
    {
      "epoch": 1.992,
      "grad_norm": 0.968721866607666,
      "learning_rate": 3.452054794520549e-05,
      "loss": 0.0672,
      "step": 2490
    },
    {
      "epoch": 2.0,
      "grad_norm": 1.313791036605835,
      "learning_rate": 3.424657534246575e-05,
      "loss": 0.0666,
      "step": 2500
    },
    {
      "epoch": 2.0,
      "eval_loss": 0.25880947709083557,
      "eval_runtime": 17.979,
      "eval_samples_per_second": 55.62,
      "eval_steps_per_second": 6.953,
      "step": 2500
    },
    {
      "epoch": 2.008,
      "grad_norm": 1.0095988512039185,
      "learning_rate": 3.397260273972603e-05,
      "loss": 0.0569,
      "step": 2510
    },
    {
      "epoch": 2.016,
      "grad_norm": 1.2445855140686035,
      "learning_rate": 3.36986301369863e-05,
      "loss": 0.0553,
      "step": 2520
    },
    {
      "epoch": 2.024,
      "grad_norm": 0.9653149247169495,
      "learning_rate": 3.342465753424658e-05,
      "loss": 0.0517,
      "step": 2530
    },
    {
      "epoch": 2.032,
      "grad_norm": 1.0746240615844727,
      "learning_rate": 3.3150684931506856e-05,
      "loss": 0.0554,
      "step": 2540
    },
    {
      "epoch": 2.04,
      "grad_norm": 1.1200075149536133,
      "learning_rate": 3.287671232876712e-05,
      "loss": 0.0503,
      "step": 2550
    },
    {
      "epoch": 2.04,
      "eval_loss": 0.29221829771995544,
      "eval_runtime": 18.5778,
      "eval_samples_per_second": 53.828,
      "eval_steps_per_second": 6.728,
      "step": 2550
    },
    {
      "epoch": 2.048,
      "grad_norm": 1.7508511543273926,
      "learning_rate": 3.26027397260274e-05,
      "loss": 0.0786,
      "step": 2560
    },
    {
      "epoch": 2.056,
      "grad_norm": 0.7971795797348022,
      "learning_rate": 3.2328767123287676e-05,
      "loss": 0.0477,
      "step": 2570
    },
    {
      "epoch": 2.064,
      "grad_norm": 0.9243114590644836,
      "learning_rate": 3.205479452054795e-05,
      "loss": 0.0679,
      "step": 2580
    },
    {
      "epoch": 2.072,
      "grad_norm": 0.9463210701942444,
      "learning_rate": 3.1780821917808225e-05,
      "loss": 0.0677,
      "step": 2590
    },
    {
      "epoch": 2.08,
      "grad_norm": 0.4817851185798645,
      "learning_rate": 3.1506849315068496e-05,
      "loss": 0.038,
      "step": 2600
    },
    {
      "epoch": 2.08,
      "eval_loss": 0.26382553577423096,
      "eval_runtime": 17.966,
      "eval_samples_per_second": 55.661,
      "eval_steps_per_second": 6.958,
      "step": 2600
    },
    {
      "epoch": 2.088,
      "grad_norm": 0.5949838757514954,
      "learning_rate": 3.123287671232877e-05,
      "loss": 0.05,
      "step": 2610
    },
    {
      "epoch": 2.096,
      "grad_norm": 1.2117911577224731,
      "learning_rate": 3.0958904109589045e-05,
      "loss": 0.0732,
      "step": 2620
    },
    {
      "epoch": 2.104,
      "grad_norm": 4.215543746948242,
      "learning_rate": 3.0684931506849316e-05,
      "loss": 0.0532,
      "step": 2630
    },
    {
      "epoch": 2.112,
      "grad_norm": 0.7218731641769409,
      "learning_rate": 3.0410958904109594e-05,
      "loss": 0.0496,
      "step": 2640
    },
    {
      "epoch": 2.12,
      "grad_norm": 0.41980043053627014,
      "learning_rate": 3.0136986301369862e-05,
      "loss": 0.0516,
      "step": 2650
    },
    {
      "epoch": 2.12,
      "eval_loss": 0.2897687256336212,
      "eval_runtime": 18.3124,
      "eval_samples_per_second": 54.608,
      "eval_steps_per_second": 6.826,
      "step": 2650
    },
    {
      "epoch": 2.128,
      "grad_norm": 0.25538715720176697,
      "learning_rate": 2.9863013698630136e-05,
      "loss": 0.0707,
      "step": 2660
    },
    {
      "epoch": 2.136,
      "grad_norm": 0.6783854961395264,
      "learning_rate": 2.9589041095890414e-05,
      "loss": 0.0527,
      "step": 2670
    },
    {
      "epoch": 2.144,
      "grad_norm": 1.475273609161377,
      "learning_rate": 2.931506849315069e-05,
      "loss": 0.0463,
      "step": 2680
    },
    {
      "epoch": 2.152,
      "grad_norm": 1.0220392942428589,
      "learning_rate": 2.9041095890410956e-05,
      "loss": 0.0576,
      "step": 2690
    },
    {
      "epoch": 2.16,
      "grad_norm": 0.9336622953414917,
      "learning_rate": 2.8767123287671234e-05,
      "loss": 0.0425,
      "step": 2700
    },
    {
      "epoch": 2.16,
      "eval_loss": 0.28975313901901245,
      "eval_runtime": 18.6518,
      "eval_samples_per_second": 53.614,
      "eval_steps_per_second": 6.702,
      "step": 2700
    },
    {
      "epoch": 2.168,
      "grad_norm": 0.4638125002384186,
      "learning_rate": 2.849315068493151e-05,
      "loss": 0.0611,
      "step": 2710
    },
    {
      "epoch": 2.176,
      "grad_norm": 1.8953595161437988,
      "learning_rate": 2.8219178082191783e-05,
      "loss": 0.0739,
      "step": 2720
    },
    {
      "epoch": 2.184,
      "grad_norm": 0.5876407623291016,
      "learning_rate": 2.7945205479452058e-05,
      "loss": 0.0761,
      "step": 2730
    },
    {
      "epoch": 2.192,
      "grad_norm": 0.8465718030929565,
      "learning_rate": 2.767123287671233e-05,
      "loss": 0.0599,
      "step": 2740
    },
    {
      "epoch": 2.2,
      "grad_norm": 1.0879125595092773,
      "learning_rate": 2.7397260273972603e-05,
      "loss": 0.0648,
      "step": 2750
    },
    {
      "epoch": 2.2,
      "eval_loss": 0.27811506390571594,
      "eval_runtime": 21.5839,
      "eval_samples_per_second": 46.331,
      "eval_steps_per_second": 5.791,
      "step": 2750
    },
    {
      "epoch": 2.208,
      "grad_norm": 0.35432296991348267,
      "learning_rate": 2.7123287671232878e-05,
      "loss": 0.0667,
      "step": 2760
    },
    {
      "epoch": 2.216,
      "grad_norm": 1.3089734315872192,
      "learning_rate": 2.6849315068493153e-05,
      "loss": 0.0634,
      "step": 2770
    },
    {
      "epoch": 2.224,
      "grad_norm": 1.2271103858947754,
      "learning_rate": 2.6575342465753427e-05,
      "loss": 0.0615,
      "step": 2780
    },
    {
      "epoch": 2.232,
      "grad_norm": 1.2523821592330933,
      "learning_rate": 2.6301369863013698e-05,
      "loss": 0.0541,
      "step": 2790
    },
    {
      "epoch": 2.24,
      "grad_norm": 0.3875863254070282,
      "learning_rate": 2.6027397260273973e-05,
      "loss": 0.0696,
      "step": 2800
    },
    {
      "epoch": 2.24,
      "eval_loss": 0.26916640996932983,
      "eval_runtime": 24.7383,
      "eval_samples_per_second": 40.423,
      "eval_steps_per_second": 5.053,
      "step": 2800
    },
    {
      "epoch": 2.248,
      "grad_norm": 1.3975516557693481,
      "learning_rate": 2.5753424657534247e-05,
      "loss": 0.0551,
      "step": 2810
    },
    {
      "epoch": 2.2560000000000002,
      "grad_norm": 0.7259540557861328,
      "learning_rate": 2.547945205479452e-05,
      "loss": 0.0297,
      "step": 2820
    },
    {
      "epoch": 2.2640000000000002,
      "grad_norm": 0.37967628240585327,
      "learning_rate": 2.5205479452054796e-05,
      "loss": 0.0584,
      "step": 2830
    },
    {
      "epoch": 2.2720000000000002,
      "grad_norm": 0.7999908328056335,
      "learning_rate": 2.493150684931507e-05,
      "loss": 0.0474,
      "step": 2840
    },
    {
      "epoch": 2.2800000000000002,
      "grad_norm": 0.6172999739646912,
      "learning_rate": 2.4657534246575342e-05,
      "loss": 0.0465,
      "step": 2850
    },
    {
      "epoch": 2.2800000000000002,
      "eval_loss": 0.28282153606414795,
      "eval_runtime": 19.9838,
      "eval_samples_per_second": 50.04,
      "eval_steps_per_second": 6.255,
      "step": 2850
    },
    {
      "epoch": 2.288,
      "grad_norm": 1.6436612606048584,
      "learning_rate": 2.4383561643835616e-05,
      "loss": 0.0563,
      "step": 2860
    },
    {
      "epoch": 2.296,
      "grad_norm": 0.9091852307319641,
      "learning_rate": 2.410958904109589e-05,
      "loss": 0.0507,
      "step": 2870
    },
    {
      "epoch": 2.304,
      "grad_norm": 1.8432751893997192,
      "learning_rate": 2.3835616438356165e-05,
      "loss": 0.0607,
      "step": 2880
    },
    {
      "epoch": 2.312,
      "grad_norm": 1.9648126363754272,
      "learning_rate": 2.356164383561644e-05,
      "loss": 0.0703,
      "step": 2890
    },
    {
      "epoch": 2.32,
      "grad_norm": 1.3173654079437256,
      "learning_rate": 2.328767123287671e-05,
      "loss": 0.0611,
      "step": 2900
    },
    {
      "epoch": 2.32,
      "eval_loss": 0.29284465312957764,
      "eval_runtime": 23.3036,
      "eval_samples_per_second": 42.912,
      "eval_steps_per_second": 5.364,
      "step": 2900
    },
    {
      "epoch": 2.328,
      "grad_norm": 0.8905419707298279,
      "learning_rate": 2.301369863013699e-05,
      "loss": 0.0657,
      "step": 2910
    },
    {
      "epoch": 2.336,
      "grad_norm": 1.2425132989883423,
      "learning_rate": 2.2739726027397263e-05,
      "loss": 0.0408,
      "step": 2920
    },
    {
      "epoch": 2.344,
      "grad_norm": 1.3770010471343994,
      "learning_rate": 2.2465753424657534e-05,
      "loss": 0.0528,
      "step": 2930
    },
    {
      "epoch": 2.352,
      "grad_norm": 0.6803381443023682,
      "learning_rate": 2.219178082191781e-05,
      "loss": 0.039,
      "step": 2940
    },
    {
      "epoch": 2.36,
      "grad_norm": 0.5991002321243286,
      "learning_rate": 2.1917808219178083e-05,
      "loss": 0.0338,
      "step": 2950
    },
    {
      "epoch": 2.36,
      "eval_loss": 0.29061469435691833,
      "eval_runtime": 18.0138,
      "eval_samples_per_second": 55.513,
      "eval_steps_per_second": 6.939,
      "step": 2950
    },
    {
      "epoch": 2.368,
      "grad_norm": 1.134713888168335,
      "learning_rate": 2.1643835616438358e-05,
      "loss": 0.0526,
      "step": 2960
    },
    {
      "epoch": 2.376,
      "grad_norm": 1.7000930309295654,
      "learning_rate": 2.1369863013698632e-05,
      "loss": 0.052,
      "step": 2970
    },
    {
      "epoch": 2.384,
      "grad_norm": 1.36154305934906,
      "learning_rate": 2.1095890410958904e-05,
      "loss": 0.0409,
      "step": 2980
    },
    {
      "epoch": 2.392,
      "grad_norm": 0.4112170934677124,
      "learning_rate": 2.0821917808219178e-05,
      "loss": 0.041,
      "step": 2990
    },
    {
      "epoch": 2.4,
      "grad_norm": 0.513670802116394,
      "learning_rate": 2.0547945205479453e-05,
      "loss": 0.0444,
      "step": 3000
    },
    {
      "epoch": 2.4,
      "eval_loss": 0.2921173572540283,
      "eval_runtime": 18.0301,
      "eval_samples_per_second": 55.463,
      "eval_steps_per_second": 6.933,
      "step": 3000
    },
    {
      "epoch": 2.408,
      "grad_norm": 2.3044869899749756,
      "learning_rate": 2.0273972602739727e-05,
      "loss": 0.0407,
      "step": 3010
    },
    {
      "epoch": 2.416,
      "grad_norm": 0.9236288070678711,
      "learning_rate": 2e-05,
      "loss": 0.0599,
      "step": 3020
    },
    {
      "epoch": 2.424,
      "grad_norm": 0.6979769468307495,
      "learning_rate": 1.9726027397260273e-05,
      "loss": 0.0493,
      "step": 3030
    },
    {
      "epoch": 2.432,
      "grad_norm": 2.1598060131073,
      "learning_rate": 1.945205479452055e-05,
      "loss": 0.061,
      "step": 3040
    },
    {
      "epoch": 2.44,
      "grad_norm": 0.8236116170883179,
      "learning_rate": 1.9178082191780822e-05,
      "loss": 0.0509,
      "step": 3050
    },
    {
      "epoch": 2.44,
      "eval_loss": 0.2874731123447418,
      "eval_runtime": 18.0439,
      "eval_samples_per_second": 55.42,
      "eval_steps_per_second": 6.928,
      "step": 3050
    },
    {
      "epoch": 2.448,
      "grad_norm": 0.8803660273551941,
      "learning_rate": 1.8904109589041096e-05,
      "loss": 0.0517,
      "step": 3060
    },
    {
      "epoch": 2.456,
      "grad_norm": 0.6471184492111206,
      "learning_rate": 1.863013698630137e-05,
      "loss": 0.0518,
      "step": 3070
    },
    {
      "epoch": 2.464,
      "grad_norm": 1.0863877534866333,
      "learning_rate": 1.8356164383561645e-05,
      "loss": 0.0527,
      "step": 3080
    },
    {
      "epoch": 2.472,
      "grad_norm": 1.2369729280471802,
      "learning_rate": 1.808219178082192e-05,
      "loss": 0.0391,
      "step": 3090
    },
    {
      "epoch": 2.48,
      "grad_norm": 0.8460246324539185,
      "learning_rate": 1.780821917808219e-05,
      "loss": 0.0411,
      "step": 3100
    },
    {
      "epoch": 2.48,
      "eval_loss": 0.2889753580093384,
      "eval_runtime": 18.2629,
      "eval_samples_per_second": 54.756,
      "eval_steps_per_second": 6.844,
      "step": 3100
    },
    {
      "epoch": 2.488,
      "grad_norm": 0.8444854021072388,
      "learning_rate": 1.7534246575342465e-05,
      "loss": 0.0649,
      "step": 3110
    },
    {
      "epoch": 2.496,
      "grad_norm": 0.12409707903862,
      "learning_rate": 1.7260273972602743e-05,
      "loss": 0.0344,
      "step": 3120
    },
    {
      "epoch": 2.504,
      "grad_norm": 1.3270409107208252,
      "learning_rate": 1.6986301369863014e-05,
      "loss": 0.0489,
      "step": 3130
    },
    {
      "epoch": 2.512,
      "grad_norm": 1.8644980192184448,
      "learning_rate": 1.671232876712329e-05,
      "loss": 0.0569,
      "step": 3140
    },
    {
      "epoch": 2.52,
      "grad_norm": 1.5373574495315552,
      "learning_rate": 1.643835616438356e-05,
      "loss": 0.0766,
      "step": 3150
    },
    {
      "epoch": 2.52,
      "eval_loss": 0.2986830770969391,
      "eval_runtime": 18.4094,
      "eval_samples_per_second": 54.32,
      "eval_steps_per_second": 6.79,
      "step": 3150
    },
    {
      "epoch": 2.528,
      "grad_norm": 1.5775411128997803,
      "learning_rate": 1.6164383561643838e-05,
      "loss": 0.0406,
      "step": 3160
    },
    {
      "epoch": 2.536,
      "grad_norm": 1.67123544216156,
      "learning_rate": 1.5890410958904112e-05,
      "loss": 0.041,
      "step": 3170
    },
    {
      "epoch": 2.544,
      "grad_norm": 1.3917399644851685,
      "learning_rate": 1.5616438356164384e-05,
      "loss": 0.0581,
      "step": 3180
    },
    {
      "epoch": 2.552,
      "grad_norm": 0.9995627999305725,
      "learning_rate": 1.5342465753424658e-05,
      "loss": 0.0444,
      "step": 3190
    },
    {
      "epoch": 2.56,
      "grad_norm": 2.9415433406829834,
      "learning_rate": 1.5068493150684931e-05,
      "loss": 0.0508,
      "step": 3200
    },
    {
      "epoch": 2.56,
      "eval_loss": 0.305264949798584,
      "eval_runtime": 18.6514,
      "eval_samples_per_second": 53.615,
      "eval_steps_per_second": 6.702,
      "step": 3200
    },
    {
      "epoch": 2.568,
      "grad_norm": 1.091497540473938,
      "learning_rate": 1.4794520547945207e-05,
      "loss": 0.0513,
      "step": 3210
    },
    {
      "epoch": 2.576,
      "grad_norm": 1.019310474395752,
      "learning_rate": 1.4520547945205478e-05,
      "loss": 0.0352,
      "step": 3220
    },
    {
      "epoch": 2.584,
      "grad_norm": 1.3811999559402466,
      "learning_rate": 1.4246575342465754e-05,
      "loss": 0.0598,
      "step": 3230
    },
    {
      "epoch": 2.592,
      "grad_norm": 0.9290745258331299,
      "learning_rate": 1.3972602739726029e-05,
      "loss": 0.04,
      "step": 3240
    },
    {
      "epoch": 2.6,
      "grad_norm": 1.004621148109436,
      "learning_rate": 1.3698630136986302e-05,
      "loss": 0.0414,
      "step": 3250
    },
    {
      "epoch": 2.6,
      "eval_loss": 0.30265122652053833,
      "eval_runtime": 19.6032,
      "eval_samples_per_second": 51.012,
      "eval_steps_per_second": 6.377,
      "step": 3250
    },
    {
      "epoch": 2.608,
      "grad_norm": 1.3471252918243408,
      "learning_rate": 1.3424657534246576e-05,
      "loss": 0.0525,
      "step": 3260
    },
    {
      "epoch": 2.616,
      "grad_norm": 0.594821035861969,
      "learning_rate": 1.3150684931506849e-05,
      "loss": 0.0358,
      "step": 3270
    },
    {
      "epoch": 2.624,
      "grad_norm": 0.6003671884536743,
      "learning_rate": 1.2876712328767124e-05,
      "loss": 0.0284,
      "step": 3280
    },
    {
      "epoch": 2.632,
      "grad_norm": 0.6536270380020142,
      "learning_rate": 1.2602739726027398e-05,
      "loss": 0.0407,
      "step": 3290
    },
    {
      "epoch": 2.64,
      "grad_norm": 1.3092049360275269,
      "learning_rate": 1.2328767123287671e-05,
      "loss": 0.0479,
      "step": 3300
    },
    {
      "epoch": 2.64,
      "eval_loss": 0.292395681142807,
      "eval_runtime": 23.5049,
      "eval_samples_per_second": 42.544,
      "eval_steps_per_second": 5.318,
      "step": 3300
    },
    {
      "epoch": 2.648,
      "grad_norm": 2.320707082748413,
      "learning_rate": 1.2054794520547945e-05,
      "loss": 0.0652,
      "step": 3310
    },
    {
      "epoch": 2.656,
      "grad_norm": 0.8099920153617859,
      "learning_rate": 1.178082191780822e-05,
      "loss": 0.0415,
      "step": 3320
    },
    {
      "epoch": 2.664,
      "grad_norm": 0.33888909220695496,
      "learning_rate": 1.1506849315068494e-05,
      "loss": 0.0499,
      "step": 3330
    },
    {
      "epoch": 2.672,
      "grad_norm": 2.187974691390991,
      "learning_rate": 1.1232876712328767e-05,
      "loss": 0.0557,
      "step": 3340
    },
    {
      "epoch": 2.68,
      "grad_norm": 0.6363622546195984,
      "learning_rate": 1.0958904109589042e-05,
      "loss": 0.0573,
      "step": 3350
    },
    {
      "epoch": 2.68,
      "eval_loss": 0.29363715648651123,
      "eval_runtime": 24.7778,
      "eval_samples_per_second": 40.359,
      "eval_steps_per_second": 5.045,
      "step": 3350
    },
    {
      "epoch": 2.6879999999999997,
      "grad_norm": 1.1061391830444336,
      "learning_rate": 1.0684931506849316e-05,
      "loss": 0.0714,
      "step": 3360
    },
    {
      "epoch": 2.6959999999999997,
      "grad_norm": 1.161045789718628,
      "learning_rate": 1.0410958904109589e-05,
      "loss": 0.0419,
      "step": 3370
    },
    {
      "epoch": 2.7039999999999997,
      "grad_norm": 0.760764479637146,
      "learning_rate": 1.0136986301369864e-05,
      "loss": 0.0413,
      "step": 3380
    },
    {
      "epoch": 2.7119999999999997,
      "grad_norm": 0.946137547492981,
      "learning_rate": 9.863013698630136e-06,
      "loss": 0.0412,
      "step": 3390
    },
    {
      "epoch": 2.7199999999999998,
      "grad_norm": 0.7663030028343201,
      "learning_rate": 9.589041095890411e-06,
      "loss": 0.0413,
      "step": 3400
    },
    {
      "epoch": 2.7199999999999998,
      "eval_loss": 0.29503554105758667,
      "eval_runtime": 24.5562,
      "eval_samples_per_second": 40.723,
      "eval_steps_per_second": 5.09,
      "step": 3400
    },
    {
      "epoch": 2.7279999999999998,
      "grad_norm": 1.5147595405578613,
      "learning_rate": 9.315068493150685e-06,
      "loss": 0.0583,
      "step": 3410
    },
    {
      "epoch": 2.7359999999999998,
      "grad_norm": 0.32320117950439453,
      "learning_rate": 9.04109589041096e-06,
      "loss": 0.048,
      "step": 3420
    },
    {
      "epoch": 2.7439999999999998,
      "grad_norm": 0.3719773590564728,
      "learning_rate": 8.767123287671233e-06,
      "loss": 0.033,
      "step": 3430
    },
    {
      "epoch": 2.752,
      "grad_norm": 3.2742888927459717,
      "learning_rate": 8.493150684931507e-06,
      "loss": 0.0737,
      "step": 3440
    },
    {
      "epoch": 2.76,
      "grad_norm": 1.5557715892791748,
      "learning_rate": 8.21917808219178e-06,
      "loss": 0.0659,
      "step": 3450
    },
    {
      "epoch": 2.76,
      "eval_loss": 0.3057798445224762,
      "eval_runtime": 24.5637,
      "eval_samples_per_second": 40.71,
      "eval_steps_per_second": 5.089,
      "step": 3450
    },
    {
      "epoch": 2.768,
      "grad_norm": 1.411348581314087,
      "learning_rate": 7.945205479452056e-06,
      "loss": 0.0359,
      "step": 3460
    },
    {
      "epoch": 2.776,
      "grad_norm": 1.164149284362793,
      "learning_rate": 7.671232876712329e-06,
      "loss": 0.0312,
      "step": 3470
    },
    {
      "epoch": 2.784,
      "grad_norm": 0.38810354471206665,
      "learning_rate": 7.3972602739726036e-06,
      "loss": 0.0434,
      "step": 3480
    },
    {
      "epoch": 2.792,
      "grad_norm": 0.39881059527397156,
      "learning_rate": 7.123287671232877e-06,
      "loss": 0.045,
      "step": 3490
    },
    {
      "epoch": 2.8,
      "grad_norm": 6.544364929199219,
      "learning_rate": 6.849315068493151e-06,
      "loss": 0.0538,
      "step": 3500
    },
    {
      "epoch": 2.8,
      "eval_loss": 0.3029436767101288,
      "eval_runtime": 24.6234,
      "eval_samples_per_second": 40.612,
      "eval_steps_per_second": 5.076,
      "step": 3500
    },
    {
      "epoch": 2.808,
      "grad_norm": 2.1032164096832275,
      "learning_rate": 6.5753424657534245e-06,
      "loss": 0.045,
      "step": 3510
    },
    {
      "epoch": 2.816,
      "grad_norm": 0.86745285987854,
      "learning_rate": 6.301369863013699e-06,
      "loss": 0.0494,
      "step": 3520
    },
    {
      "epoch": 2.824,
      "grad_norm": 0.3865259289741516,
      "learning_rate": 6.027397260273973e-06,
      "loss": 0.04,
      "step": 3530
    },
    {
      "epoch": 2.832,
      "grad_norm": 0.055052127689123154,
      "learning_rate": 5.753424657534247e-06,
      "loss": 0.0313,
      "step": 3540
    },
    {
      "epoch": 2.84,
      "grad_norm": 2.030033826828003,
      "learning_rate": 5.479452054794521e-06,
      "loss": 0.0368,
      "step": 3550
    },
    {
      "epoch": 2.84,
      "eval_loss": 0.30838286876678467,
      "eval_runtime": 18.6345,
      "eval_samples_per_second": 53.664,
      "eval_steps_per_second": 6.708,
      "step": 3550
    },
    {
      "epoch": 2.848,
      "grad_norm": 0.34520021080970764,
      "learning_rate": 5.2054794520547945e-06,
      "loss": 0.0422,
      "step": 3560
    },
    {
      "epoch": 2.856,
      "grad_norm": 0.7305697798728943,
      "learning_rate": 4.931506849315068e-06,
      "loss": 0.0454,
      "step": 3570
    },
    {
      "epoch": 2.864,
      "grad_norm": 2.4478354454040527,
      "learning_rate": 4.657534246575343e-06,
      "loss": 0.0452,
      "step": 3580
    },
    {
      "epoch": 2.872,
      "grad_norm": 1.2446939945220947,
      "learning_rate": 4.383561643835616e-06,
      "loss": 0.0478,
      "step": 3590
    },
    {
      "epoch": 2.88,
      "grad_norm": 0.2722845673561096,
      "learning_rate": 4.10958904109589e-06,
      "loss": 0.0392,
      "step": 3600
    },
    {
      "epoch": 2.88,
      "eval_loss": 0.304413765668869,
      "eval_runtime": 18.5172,
      "eval_samples_per_second": 54.004,
      "eval_steps_per_second": 6.75,
      "step": 3600
    },
    {
      "epoch": 2.888,
      "grad_norm": 1.7607394456863403,
      "learning_rate": 3.8356164383561645e-06,
      "loss": 0.0548,
      "step": 3610
    },
    {
      "epoch": 2.896,
      "grad_norm": 0.9144805073738098,
      "learning_rate": 3.5616438356164386e-06,
      "loss": 0.0331,
      "step": 3620
    },
    {
      "epoch": 2.904,
      "grad_norm": 0.9016626477241516,
      "learning_rate": 3.2876712328767123e-06,
      "loss": 0.0538,
      "step": 3630
    },
    {
      "epoch": 2.912,
      "grad_norm": 3.0978500843048096,
      "learning_rate": 3.0136986301369864e-06,
      "loss": 0.0897,
      "step": 3640
    },
    {
      "epoch": 2.92,
      "grad_norm": 0.8942356109619141,
      "learning_rate": 2.7397260273972604e-06,
      "loss": 0.0319,
      "step": 3650
    },
    {
      "epoch": 2.92,
      "eval_loss": 0.3007606863975525,
      "eval_runtime": 24.0513,
      "eval_samples_per_second": 41.578,
      "eval_steps_per_second": 5.197,
      "step": 3650
    },
    {
      "epoch": 2.928,
      "grad_norm": 0.7314944267272949,
      "learning_rate": 2.465753424657534e-06,
      "loss": 0.055,
      "step": 3660
    },
    {
      "epoch": 2.936,
      "grad_norm": 0.7625493407249451,
      "learning_rate": 2.191780821917808e-06,
      "loss": 0.0482,
      "step": 3670
    },
    {
      "epoch": 2.944,
      "grad_norm": 0.5771563649177551,
      "learning_rate": 1.9178082191780823e-06,
      "loss": 0.0365,
      "step": 3680
    },
    {
      "epoch": 2.952,
      "grad_norm": 0.9448912739753723,
      "learning_rate": 1.6438356164383561e-06,
      "loss": 0.0474,
      "step": 3690
    },
    {
      "epoch": 2.96,
      "grad_norm": 0.6642317771911621,
      "learning_rate": 1.3698630136986302e-06,
      "loss": 0.0622,
      "step": 3700
    },
    {
      "epoch": 2.96,
      "eval_loss": 0.29985055327415466,
      "eval_runtime": 24.9092,
      "eval_samples_per_second": 40.146,
      "eval_steps_per_second": 5.018,
      "step": 3700
    },
    {
      "epoch": 2.968,
      "grad_norm": 1.4204808473587036,
      "learning_rate": 1.095890410958904e-06,
      "loss": 0.0701,
      "step": 3710
    },
    {
      "epoch": 2.976,
      "grad_norm": 0.18917609751224518,
      "learning_rate": 8.219178082191781e-07,
      "loss": 0.0509,
      "step": 3720
    },
    {
      "epoch": 2.984,
      "grad_norm": 1.3436576128005981,
      "learning_rate": 5.47945205479452e-07,
      "loss": 0.0471,
      "step": 3730
    },
    {
      "epoch": 2.992,
      "grad_norm": 1.0260422229766846,
      "learning_rate": 2.73972602739726e-07,
      "loss": 0.0434,
      "step": 3740
    },
    {
      "epoch": 3.0,
      "grad_norm": 1.6749581098556519,
      "learning_rate": 0.0,
      "loss": 0.0595,
      "step": 3750
    },
    {
      "epoch": 3.0,
      "eval_loss": 0.3015829026699066,
      "eval_runtime": 25.4669,
      "eval_samples_per_second": 39.267,
      "eval_steps_per_second": 4.908,
      "step": 3750
    }
  ],
  "logging_steps": 10,
  "max_steps": 3750,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 3,
  "save_steps": 100,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 3975027467673600.0,
  "train_batch_size": 8,
  "trial_name": null,
  "trial_params": null
}
