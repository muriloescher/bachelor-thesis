{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 3.0,
  "eval_steps": 50,
  "global_step": 3750,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.008,
      "grad_norm": 61.83757781982422,
      "learning_rate": 1e-05,
      "loss": 6.2464,
      "step": 10
    },
    {
      "epoch": 0.016,
      "grad_norm": 138.88076782226562,
      "learning_rate": 2e-05,
      "loss": 6.161,
      "step": 20
    },
    {
      "epoch": 0.024,
      "grad_norm": 67.14315795898438,
      "learning_rate": 3e-05,
      "loss": 5.3552,
      "step": 30
    },
    {
      "epoch": 0.032,
      "grad_norm": 156.527587890625,
      "learning_rate": 4e-05,
      "loss": 4.7742,
      "step": 40
    },
    {
      "epoch": 0.04,
      "grad_norm": 94.0799789428711,
      "learning_rate": 5e-05,
      "loss": 3.7843,
      "step": 50
    },
    {
      "epoch": 0.04,
      "eval_loss": 2.914081573486328,
      "eval_runtime": 21.8172,
      "eval_samples_per_second": 45.835,
      "eval_steps_per_second": 5.729,
      "step": 50
    },
    {
      "epoch": 0.048,
      "grad_norm": 60.85225296020508,
      "learning_rate": 6e-05,
      "loss": 3.2134,
      "step": 60
    },
    {
      "epoch": 0.056,
      "grad_norm": 67.17304992675781,
      "learning_rate": 7e-05,
      "loss": 2.7563,
      "step": 70
    },
    {
      "epoch": 0.064,
      "grad_norm": 30.890159606933594,
      "learning_rate": 8e-05,
      "loss": 2.1614,
      "step": 80
    },
    {
      "epoch": 0.072,
      "grad_norm": 17.481748580932617,
      "learning_rate": 9e-05,
      "loss": 1.9667,
      "step": 90
    },
    {
      "epoch": 0.08,
      "grad_norm": 24.946866989135742,
      "learning_rate": 0.0001,
      "loss": 1.7077,
      "step": 100
    },
    {
      "epoch": 0.08,
      "eval_loss": 1.3345024585723877,
      "eval_runtime": 22.2484,
      "eval_samples_per_second": 44.947,
      "eval_steps_per_second": 5.618,
      "step": 100
    },
    {
      "epoch": 0.088,
      "grad_norm": 27.997304916381836,
      "learning_rate": 9.972602739726028e-05,
      "loss": 1.3998,
      "step": 110
    },
    {
      "epoch": 0.096,
      "grad_norm": 43.613399505615234,
      "learning_rate": 9.945205479452056e-05,
      "loss": 1.0897,
      "step": 120
    },
    {
      "epoch": 0.104,
      "grad_norm": 24.40776824951172,
      "learning_rate": 9.917808219178082e-05,
      "loss": 1.0193,
      "step": 130
    },
    {
      "epoch": 0.112,
      "grad_norm": 14.056256294250488,
      "learning_rate": 9.89041095890411e-05,
      "loss": 0.971,
      "step": 140
    },
    {
      "epoch": 0.12,
      "grad_norm": 105.88226318359375,
      "learning_rate": 9.863013698630137e-05,
      "loss": 0.9407,
      "step": 150
    },
    {
      "epoch": 0.12,
      "eval_loss": 0.5924355387687683,
      "eval_runtime": 22.2909,
      "eval_samples_per_second": 44.861,
      "eval_steps_per_second": 5.608,
      "step": 150
    },
    {
      "epoch": 0.128,
      "grad_norm": 54.92223358154297,
      "learning_rate": 9.835616438356165e-05,
      "loss": 0.8014,
      "step": 160
    },
    {
      "epoch": 0.136,
      "grad_norm": 20.299407958984375,
      "learning_rate": 9.808219178082192e-05,
      "loss": 0.7201,
      "step": 170
    },
    {
      "epoch": 0.144,
      "grad_norm": 7.1623454093933105,
      "learning_rate": 9.78082191780822e-05,
      "loss": 0.731,
      "step": 180
    },
    {
      "epoch": 0.152,
      "grad_norm": 12.116061210632324,
      "learning_rate": 9.753424657534247e-05,
      "loss": 0.7495,
      "step": 190
    },
    {
      "epoch": 0.16,
      "grad_norm": 8.97696304321289,
      "learning_rate": 9.726027397260274e-05,
      "loss": 0.6453,
      "step": 200
    },
    {
      "epoch": 0.16,
      "eval_loss": 0.49785754084587097,
      "eval_runtime": 22.2397,
      "eval_samples_per_second": 44.965,
      "eval_steps_per_second": 5.621,
      "step": 200
    },
    {
      "epoch": 0.168,
      "grad_norm": 8.270094871520996,
      "learning_rate": 9.698630136986302e-05,
      "loss": 0.6397,
      "step": 210
    },
    {
      "epoch": 0.176,
      "grad_norm": 4.652703762054443,
      "learning_rate": 9.67123287671233e-05,
      "loss": 0.6185,
      "step": 220
    },
    {
      "epoch": 0.184,
      "grad_norm": 7.285937309265137,
      "learning_rate": 9.643835616438356e-05,
      "loss": 0.6476,
      "step": 230
    },
    {
      "epoch": 0.192,
      "grad_norm": 8.953363418579102,
      "learning_rate": 9.616438356164384e-05,
      "loss": 0.5953,
      "step": 240
    },
    {
      "epoch": 0.2,
      "grad_norm": 3.7836480140686035,
      "learning_rate": 9.58904109589041e-05,
      "loss": 0.605,
      "step": 250
    },
    {
      "epoch": 0.2,
      "eval_loss": 0.44834110140800476,
      "eval_runtime": 22.2183,
      "eval_samples_per_second": 45.008,
      "eval_steps_per_second": 5.626,
      "step": 250
    },
    {
      "epoch": 0.208,
      "grad_norm": 6.246558666229248,
      "learning_rate": 9.561643835616438e-05,
      "loss": 0.5539,
      "step": 260
    },
    {
      "epoch": 0.216,
      "grad_norm": 9.202291488647461,
      "learning_rate": 9.534246575342466e-05,
      "loss": 0.573,
      "step": 270
    },
    {
      "epoch": 0.224,
      "grad_norm": 6.2751240730285645,
      "learning_rate": 9.506849315068494e-05,
      "loss": 0.5118,
      "step": 280
    },
    {
      "epoch": 0.232,
      "grad_norm": 4.424081802368164,
      "learning_rate": 9.47945205479452e-05,
      "loss": 0.5806,
      "step": 290
    },
    {
      "epoch": 0.24,
      "grad_norm": 4.351860046386719,
      "learning_rate": 9.452054794520548e-05,
      "loss": 0.4974,
      "step": 300
    },
    {
      "epoch": 0.24,
      "eval_loss": 0.40114977955818176,
      "eval_runtime": 22.2598,
      "eval_samples_per_second": 44.924,
      "eval_steps_per_second": 5.616,
      "step": 300
    },
    {
      "epoch": 0.248,
      "grad_norm": 8.560762405395508,
      "learning_rate": 9.424657534246576e-05,
      "loss": 0.4979,
      "step": 310
    },
    {
      "epoch": 0.256,
      "grad_norm": 3.9015963077545166,
      "learning_rate": 9.397260273972604e-05,
      "loss": 0.5201,
      "step": 320
    },
    {
      "epoch": 0.264,
      "grad_norm": 5.619845867156982,
      "learning_rate": 9.369863013698632e-05,
      "loss": 0.4913,
      "step": 330
    },
    {
      "epoch": 0.272,
      "grad_norm": 3.473003625869751,
      "learning_rate": 9.342465753424658e-05,
      "loss": 0.4859,
      "step": 340
    },
    {
      "epoch": 0.28,
      "grad_norm": 3.5052478313446045,
      "learning_rate": 9.315068493150684e-05,
      "loss": 0.4149,
      "step": 350
    },
    {
      "epoch": 0.28,
      "eval_loss": 0.2993048131465912,
      "eval_runtime": 22.2721,
      "eval_samples_per_second": 44.899,
      "eval_steps_per_second": 5.612,
      "step": 350
    },
    {
      "epoch": 0.288,
      "grad_norm": 18.812223434448242,
      "learning_rate": 9.287671232876712e-05,
      "loss": 0.4582,
      "step": 360
    },
    {
      "epoch": 0.296,
      "grad_norm": 10.649950981140137,
      "learning_rate": 9.26027397260274e-05,
      "loss": 0.4508,
      "step": 370
    },
    {
      "epoch": 0.304,
      "grad_norm": 2.4963889122009277,
      "learning_rate": 9.232876712328768e-05,
      "loss": 0.3986,
      "step": 380
    },
    {
      "epoch": 0.312,
      "grad_norm": 2.870506525039673,
      "learning_rate": 9.205479452054796e-05,
      "loss": 0.3677,
      "step": 390
    },
    {
      "epoch": 0.32,
      "grad_norm": 4.021672248840332,
      "learning_rate": 9.178082191780822e-05,
      "loss": 0.3803,
      "step": 400
    },
    {
      "epoch": 0.32,
      "eval_loss": 0.2514532804489136,
      "eval_runtime": 22.264,
      "eval_samples_per_second": 44.916,
      "eval_steps_per_second": 5.614,
      "step": 400
    },
    {
      "epoch": 0.328,
      "grad_norm": 5.847721576690674,
      "learning_rate": 9.15068493150685e-05,
      "loss": 0.3884,
      "step": 410
    },
    {
      "epoch": 0.336,
      "grad_norm": 3.5345637798309326,
      "learning_rate": 9.123287671232878e-05,
      "loss": 0.37,
      "step": 420
    },
    {
      "epoch": 0.344,
      "grad_norm": 4.665220737457275,
      "learning_rate": 9.095890410958905e-05,
      "loss": 0.3418,
      "step": 430
    },
    {
      "epoch": 0.352,
      "grad_norm": 3.4210996627807617,
      "learning_rate": 9.068493150684932e-05,
      "loss": 0.3679,
      "step": 440
    },
    {
      "epoch": 0.36,
      "grad_norm": 1.9367239475250244,
      "learning_rate": 9.041095890410958e-05,
      "loss": 0.3355,
      "step": 450
    },
    {
      "epoch": 0.36,
      "eval_loss": 0.20732617378234863,
      "eval_runtime": 22.1897,
      "eval_samples_per_second": 45.066,
      "eval_steps_per_second": 5.633,
      "step": 450
    },
    {
      "epoch": 0.368,
      "grad_norm": 5.356752395629883,
      "learning_rate": 9.013698630136986e-05,
      "loss": 0.311,
      "step": 460
    },
    {
      "epoch": 0.376,
      "grad_norm": 4.402359485626221,
      "learning_rate": 8.986301369863014e-05,
      "loss": 0.2925,
      "step": 470
    },
    {
      "epoch": 0.384,
      "grad_norm": 2.8397090435028076,
      "learning_rate": 8.958904109589042e-05,
      "loss": 0.3421,
      "step": 480
    },
    {
      "epoch": 0.392,
      "grad_norm": 2.0414469242095947,
      "learning_rate": 8.93150684931507e-05,
      "loss": 0.3098,
      "step": 490
    },
    {
      "epoch": 0.4,
      "grad_norm": 13.604084014892578,
      "learning_rate": 8.904109589041096e-05,
      "loss": 0.3053,
      "step": 500
    },
    {
      "epoch": 0.4,
      "eval_loss": 0.1726982146501541,
      "eval_runtime": 22.2424,
      "eval_samples_per_second": 44.959,
      "eval_steps_per_second": 5.62,
      "step": 500
    },
    {
      "epoch": 0.408,
      "grad_norm": 4.2930169105529785,
      "learning_rate": 8.876712328767124e-05,
      "loss": 0.2759,
      "step": 510
    },
    {
      "epoch": 0.416,
      "grad_norm": 3.5744762420654297,
      "learning_rate": 8.849315068493151e-05,
      "loss": 0.2504,
      "step": 520
    },
    {
      "epoch": 0.424,
      "grad_norm": 3.2666609287261963,
      "learning_rate": 8.821917808219179e-05,
      "loss": 0.3357,
      "step": 530
    },
    {
      "epoch": 0.432,
      "grad_norm": 3.767303228378296,
      "learning_rate": 8.794520547945207e-05,
      "loss": 0.2812,
      "step": 540
    },
    {
      "epoch": 0.44,
      "grad_norm": 5.135329246520996,
      "learning_rate": 8.767123287671233e-05,
      "loss": 0.2844,
      "step": 550
    },
    {
      "epoch": 0.44,
      "eval_loss": 0.15422165393829346,
      "eval_runtime": 22.2073,
      "eval_samples_per_second": 45.03,
      "eval_steps_per_second": 5.629,
      "step": 550
    },
    {
      "epoch": 0.448,
      "grad_norm": 4.698729038238525,
      "learning_rate": 8.73972602739726e-05,
      "loss": 0.2592,
      "step": 560
    },
    {
      "epoch": 0.456,
      "grad_norm": 1.821150541305542,
      "learning_rate": 8.712328767123288e-05,
      "loss": 0.2598,
      "step": 570
    },
    {
      "epoch": 0.464,
      "grad_norm": 2.327390432357788,
      "learning_rate": 8.684931506849315e-05,
      "loss": 0.2159,
      "step": 580
    },
    {
      "epoch": 0.472,
      "grad_norm": 2.011589288711548,
      "learning_rate": 8.657534246575343e-05,
      "loss": 0.2977,
      "step": 590
    },
    {
      "epoch": 0.48,
      "grad_norm": 1.8066450357437134,
      "learning_rate": 8.630136986301371e-05,
      "loss": 0.2335,
      "step": 600
    },
    {
      "epoch": 0.48,
      "eval_loss": 0.13293179869651794,
      "eval_runtime": 22.3113,
      "eval_samples_per_second": 44.82,
      "eval_steps_per_second": 5.603,
      "step": 600
    },
    {
      "epoch": 0.488,
      "grad_norm": 2.5994861125946045,
      "learning_rate": 8.602739726027397e-05,
      "loss": 0.3228,
      "step": 610
    },
    {
      "epoch": 0.496,
      "grad_norm": 1.9725885391235352,
      "learning_rate": 8.575342465753425e-05,
      "loss": 0.2672,
      "step": 620
    },
    {
      "epoch": 0.504,
      "grad_norm": 1.3013607263565063,
      "learning_rate": 8.547945205479453e-05,
      "loss": 0.2082,
      "step": 630
    },
    {
      "epoch": 0.512,
      "grad_norm": 1.9570516347885132,
      "learning_rate": 8.520547945205481e-05,
      "loss": 0.1952,
      "step": 640
    },
    {
      "epoch": 0.52,
      "grad_norm": 2.6003479957580566,
      "learning_rate": 8.493150684931507e-05,
      "loss": 0.25,
      "step": 650
    },
    {
      "epoch": 0.52,
      "eval_loss": 0.13006143271923065,
      "eval_runtime": 22.3346,
      "eval_samples_per_second": 44.773,
      "eval_steps_per_second": 5.597,
      "step": 650
    },
    {
      "epoch": 0.528,
      "grad_norm": 4.677509784698486,
      "learning_rate": 8.465753424657534e-05,
      "loss": 0.2203,
      "step": 660
    },
    {
      "epoch": 0.536,
      "grad_norm": 2.2781693935394287,
      "learning_rate": 8.438356164383561e-05,
      "loss": 0.1856,
      "step": 670
    },
    {
      "epoch": 0.544,
      "grad_norm": 1.8331979513168335,
      "learning_rate": 8.410958904109589e-05,
      "loss": 0.21,
      "step": 680
    },
    {
      "epoch": 0.552,
      "grad_norm": 3.4025704860687256,
      "learning_rate": 8.383561643835617e-05,
      "loss": 0.2451,
      "step": 690
    },
    {
      "epoch": 0.56,
      "grad_norm": 3.057403326034546,
      "learning_rate": 8.356164383561645e-05,
      "loss": 0.2216,
      "step": 700
    },
    {
      "epoch": 0.56,
      "eval_loss": 0.10455218702554703,
      "eval_runtime": 22.4214,
      "eval_samples_per_second": 44.6,
      "eval_steps_per_second": 5.575,
      "step": 700
    },
    {
      "epoch": 0.568,
      "grad_norm": 1.4531105756759644,
      "learning_rate": 8.328767123287671e-05,
      "loss": 0.2159,
      "step": 710
    },
    {
      "epoch": 0.576,
      "grad_norm": 1.7435094118118286,
      "learning_rate": 8.301369863013699e-05,
      "loss": 0.1772,
      "step": 720
    },
    {
      "epoch": 0.584,
      "grad_norm": 3.4430816173553467,
      "learning_rate": 8.273972602739727e-05,
      "loss": 0.2271,
      "step": 730
    },
    {
      "epoch": 0.592,
      "grad_norm": 1.6883870363235474,
      "learning_rate": 8.246575342465755e-05,
      "loss": 0.1374,
      "step": 740
    },
    {
      "epoch": 0.6,
      "grad_norm": 1.3159875869750977,
      "learning_rate": 8.219178082191781e-05,
      "loss": 0.1731,
      "step": 750
    },
    {
      "epoch": 0.6,
      "eval_loss": 0.10332629084587097,
      "eval_runtime": 22.3621,
      "eval_samples_per_second": 44.719,
      "eval_steps_per_second": 5.59,
      "step": 750
    },
    {
      "epoch": 0.608,
      "grad_norm": 2.6129908561706543,
      "learning_rate": 8.191780821917809e-05,
      "loss": 0.1848,
      "step": 760
    },
    {
      "epoch": 0.616,
      "grad_norm": 2.187896490097046,
      "learning_rate": 8.164383561643835e-05,
      "loss": 0.1695,
      "step": 770
    },
    {
      "epoch": 0.624,
      "grad_norm": 9.58680248260498,
      "learning_rate": 8.136986301369863e-05,
      "loss": 0.1885,
      "step": 780
    },
    {
      "epoch": 0.632,
      "grad_norm": 2.115246057510376,
      "learning_rate": 8.109589041095891e-05,
      "loss": 0.1886,
      "step": 790
    },
    {
      "epoch": 0.64,
      "grad_norm": 1.8751416206359863,
      "learning_rate": 8.082191780821919e-05,
      "loss": 0.1513,
      "step": 800
    },
    {
      "epoch": 0.64,
      "eval_loss": 0.08514914661645889,
      "eval_runtime": 22.2886,
      "eval_samples_per_second": 44.866,
      "eval_steps_per_second": 5.608,
      "step": 800
    },
    {
      "epoch": 0.648,
      "grad_norm": 2.0437443256378174,
      "learning_rate": 8.054794520547946e-05,
      "loss": 0.1428,
      "step": 810
    },
    {
      "epoch": 0.656,
      "grad_norm": 2.917829990386963,
      "learning_rate": 8.027397260273973e-05,
      "loss": 0.1265,
      "step": 820
    },
    {
      "epoch": 0.664,
      "grad_norm": 1.9184778928756714,
      "learning_rate": 8e-05,
      "loss": 0.1579,
      "step": 830
    },
    {
      "epoch": 0.672,
      "grad_norm": 2.149683952331543,
      "learning_rate": 7.972602739726027e-05,
      "loss": 0.1433,
      "step": 840
    },
    {
      "epoch": 0.68,
      "grad_norm": 3.3750624656677246,
      "learning_rate": 7.945205479452055e-05,
      "loss": 0.1927,
      "step": 850
    },
    {
      "epoch": 0.68,
      "eval_loss": 0.08116517961025238,
      "eval_runtime": 16.4651,
      "eval_samples_per_second": 60.734,
      "eval_steps_per_second": 7.592,
      "step": 850
    },
    {
      "epoch": 0.688,
      "grad_norm": 8.187959671020508,
      "learning_rate": 7.917808219178083e-05,
      "loss": 0.1623,
      "step": 860
    },
    {
      "epoch": 0.696,
      "grad_norm": 2.636824607849121,
      "learning_rate": 7.890410958904109e-05,
      "loss": 0.1592,
      "step": 870
    },
    {
      "epoch": 0.704,
      "grad_norm": 1.2090593576431274,
      "learning_rate": 7.863013698630137e-05,
      "loss": 0.147,
      "step": 880
    },
    {
      "epoch": 0.712,
      "grad_norm": 2.581777811050415,
      "learning_rate": 7.835616438356165e-05,
      "loss": 0.1541,
      "step": 890
    },
    {
      "epoch": 0.72,
      "grad_norm": 1.4499485492706299,
      "learning_rate": 7.808219178082192e-05,
      "loss": 0.1308,
      "step": 900
    },
    {
      "epoch": 0.72,
      "eval_loss": 0.07963738590478897,
      "eval_runtime": 16.3981,
      "eval_samples_per_second": 60.983,
      "eval_steps_per_second": 7.623,
      "step": 900
    },
    {
      "epoch": 0.728,
      "grad_norm": 2.4894418716430664,
      "learning_rate": 7.78082191780822e-05,
      "loss": 0.1186,
      "step": 910
    },
    {
      "epoch": 0.736,
      "grad_norm": 1.8242923021316528,
      "learning_rate": 7.753424657534247e-05,
      "loss": 0.1219,
      "step": 920
    },
    {
      "epoch": 0.744,
      "grad_norm": 1.6284013986587524,
      "learning_rate": 7.726027397260274e-05,
      "loss": 0.1429,
      "step": 930
    },
    {
      "epoch": 0.752,
      "grad_norm": 0.9512782692909241,
      "learning_rate": 7.698630136986301e-05,
      "loss": 0.1334,
      "step": 940
    },
    {
      "epoch": 0.76,
      "grad_norm": 2.4080870151519775,
      "learning_rate": 7.671232876712329e-05,
      "loss": 0.1311,
      "step": 950
    },
    {
      "epoch": 0.76,
      "eval_loss": 0.06700371950864792,
      "eval_runtime": 16.2964,
      "eval_samples_per_second": 61.363,
      "eval_steps_per_second": 7.67,
      "step": 950
    },
    {
      "epoch": 0.768,
      "grad_norm": 0.8815796971321106,
      "learning_rate": 7.643835616438356e-05,
      "loss": 0.0749,
      "step": 960
    },
    {
      "epoch": 0.776,
      "grad_norm": 1.5410351753234863,
      "learning_rate": 7.616438356164384e-05,
      "loss": 0.1638,
      "step": 970
    },
    {
      "epoch": 0.784,
      "grad_norm": 2.1756932735443115,
      "learning_rate": 7.589041095890411e-05,
      "loss": 0.1411,
      "step": 980
    },
    {
      "epoch": 0.792,
      "grad_norm": 1.9905332326889038,
      "learning_rate": 7.561643835616439e-05,
      "loss": 0.1012,
      "step": 990
    },
    {
      "epoch": 0.8,
      "grad_norm": 1.8663055896759033,
      "learning_rate": 7.534246575342466e-05,
      "loss": 0.119,
      "step": 1000
    },
    {
      "epoch": 0.8,
      "eval_loss": 0.07232051342725754,
      "eval_runtime": 16.2848,
      "eval_samples_per_second": 61.407,
      "eval_steps_per_second": 7.676,
      "step": 1000
    },
    {
      "epoch": 0.808,
      "grad_norm": 2.549450635910034,
      "learning_rate": 7.506849315068494e-05,
      "loss": 0.1876,
      "step": 1010
    },
    {
      "epoch": 0.816,
      "grad_norm": 1.9803016185760498,
      "learning_rate": 7.479452054794522e-05,
      "loss": 0.1505,
      "step": 1020
    },
    {
      "epoch": 0.824,
      "grad_norm": 2.1216001510620117,
      "learning_rate": 7.452054794520548e-05,
      "loss": 0.1783,
      "step": 1030
    },
    {
      "epoch": 0.832,
      "grad_norm": 0.9436479806900024,
      "learning_rate": 7.424657534246575e-05,
      "loss": 0.1108,
      "step": 1040
    },
    {
      "epoch": 0.84,
      "grad_norm": 1.1859169006347656,
      "learning_rate": 7.397260273972603e-05,
      "loss": 0.0921,
      "step": 1050
    },
    {
      "epoch": 0.84,
      "eval_loss": 0.06316372007131577,
      "eval_runtime": 16.3058,
      "eval_samples_per_second": 61.328,
      "eval_steps_per_second": 7.666,
      "step": 1050
    },
    {
      "epoch": 0.848,
      "grad_norm": 1.41228449344635,
      "learning_rate": 7.36986301369863e-05,
      "loss": 0.1332,
      "step": 1060
    },
    {
      "epoch": 0.856,
      "grad_norm": 1.260988473892212,
      "learning_rate": 7.342465753424658e-05,
      "loss": 0.1444,
      "step": 1070
    },
    {
      "epoch": 0.864,
      "grad_norm": 1.6325854063034058,
      "learning_rate": 7.315068493150685e-05,
      "loss": 0.1313,
      "step": 1080
    },
    {
      "epoch": 0.872,
      "grad_norm": 1.3298276662826538,
      "learning_rate": 7.287671232876712e-05,
      "loss": 0.1516,
      "step": 1090
    },
    {
      "epoch": 0.88,
      "grad_norm": 1.1638357639312744,
      "learning_rate": 7.26027397260274e-05,
      "loss": 0.1123,
      "step": 1100
    },
    {
      "epoch": 0.88,
      "eval_loss": 0.05690063536167145,
      "eval_runtime": 16.3022,
      "eval_samples_per_second": 61.342,
      "eval_steps_per_second": 7.668,
      "step": 1100
    },
    {
      "epoch": 0.888,
      "grad_norm": 1.4716520309448242,
      "learning_rate": 7.232876712328768e-05,
      "loss": 0.1527,
      "step": 1110
    },
    {
      "epoch": 0.896,
      "grad_norm": 2.6754977703094482,
      "learning_rate": 7.205479452054796e-05,
      "loss": 0.0977,
      "step": 1120
    },
    {
      "epoch": 0.904,
      "grad_norm": 1.9451628923416138,
      "learning_rate": 7.178082191780822e-05,
      "loss": 0.1227,
      "step": 1130
    },
    {
      "epoch": 0.912,
      "grad_norm": 0.4881458878517151,
      "learning_rate": 7.150684931506849e-05,
      "loss": 0.1133,
      "step": 1140
    },
    {
      "epoch": 0.92,
      "grad_norm": 0.7971002459526062,
      "learning_rate": 7.123287671232876e-05,
      "loss": 0.0834,
      "step": 1150
    },
    {
      "epoch": 0.92,
      "eval_loss": 0.05442599952220917,
      "eval_runtime": 16.8228,
      "eval_samples_per_second": 59.443,
      "eval_steps_per_second": 7.43,
      "step": 1150
    },
    {
      "epoch": 0.928,
      "grad_norm": 0.7475246787071228,
      "learning_rate": 7.095890410958904e-05,
      "loss": 0.0953,
      "step": 1160
    },
    {
      "epoch": 0.936,
      "grad_norm": 1.514207363128662,
      "learning_rate": 7.068493150684932e-05,
      "loss": 0.0792,
      "step": 1170
    },
    {
      "epoch": 0.944,
      "grad_norm": 3.484978675842285,
      "learning_rate": 7.04109589041096e-05,
      "loss": 0.1123,
      "step": 1180
    },
    {
      "epoch": 0.952,
      "grad_norm": 3.5371341705322266,
      "learning_rate": 7.013698630136986e-05,
      "loss": 0.1075,
      "step": 1190
    },
    {
      "epoch": 0.96,
      "grad_norm": 0.8241435885429382,
      "learning_rate": 6.986301369863014e-05,
      "loss": 0.1048,
      "step": 1200
    },
    {
      "epoch": 0.96,
      "eval_loss": 0.049877189099788666,
      "eval_runtime": 22.2823,
      "eval_samples_per_second": 44.879,
      "eval_steps_per_second": 5.61,
      "step": 1200
    },
    {
      "epoch": 0.968,
      "grad_norm": 0.9279725551605225,
      "learning_rate": 6.958904109589042e-05,
      "loss": 0.1625,
      "step": 1210
    },
    {
      "epoch": 0.976,
      "grad_norm": 1.0033388137817383,
      "learning_rate": 6.93150684931507e-05,
      "loss": 0.078,
      "step": 1220
    },
    {
      "epoch": 0.984,
      "grad_norm": 1.3912944793701172,
      "learning_rate": 6.904109589041097e-05,
      "loss": 0.0758,
      "step": 1230
    },
    {
      "epoch": 0.992,
      "grad_norm": 0.49856728315353394,
      "learning_rate": 6.876712328767124e-05,
      "loss": 0.0689,
      "step": 1240
    },
    {
      "epoch": 1.0,
      "grad_norm": 1.3210631608963013,
      "learning_rate": 6.84931506849315e-05,
      "loss": 0.1351,
      "step": 1250
    },
    {
      "epoch": 1.0,
      "eval_loss": 0.04948359727859497,
      "eval_runtime": 22.1367,
      "eval_samples_per_second": 45.174,
      "eval_steps_per_second": 5.647,
      "step": 1250
    },
    {
      "epoch": 1.008,
      "grad_norm": 1.477503776550293,
      "learning_rate": 6.821917808219178e-05,
      "loss": 0.1176,
      "step": 1260
    },
    {
      "epoch": 1.016,
      "grad_norm": 0.747490644454956,
      "learning_rate": 6.794520547945206e-05,
      "loss": 0.0842,
      "step": 1270
    },
    {
      "epoch": 1.024,
      "grad_norm": 2.5590386390686035,
      "learning_rate": 6.767123287671234e-05,
      "loss": 0.085,
      "step": 1280
    },
    {
      "epoch": 1.032,
      "grad_norm": 0.9616838693618774,
      "learning_rate": 6.73972602739726e-05,
      "loss": 0.103,
      "step": 1290
    },
    {
      "epoch": 1.04,
      "grad_norm": 2.1083407402038574,
      "learning_rate": 6.712328767123288e-05,
      "loss": 0.1051,
      "step": 1300
    },
    {
      "epoch": 1.04,
      "eval_loss": 0.04310024157166481,
      "eval_runtime": 22.2488,
      "eval_samples_per_second": 44.946,
      "eval_steps_per_second": 5.618,
      "step": 1300
    },
    {
      "epoch": 1.048,
      "grad_norm": 1.797791600227356,
      "learning_rate": 6.684931506849316e-05,
      "loss": 0.079,
      "step": 1310
    },
    {
      "epoch": 1.056,
      "grad_norm": 1.091505765914917,
      "learning_rate": 6.657534246575343e-05,
      "loss": 0.0662,
      "step": 1320
    },
    {
      "epoch": 1.064,
      "grad_norm": 0.7668530344963074,
      "learning_rate": 6.630136986301371e-05,
      "loss": 0.1111,
      "step": 1330
    },
    {
      "epoch": 1.072,
      "grad_norm": 1.7082430124282837,
      "learning_rate": 6.602739726027398e-05,
      "loss": 0.0708,
      "step": 1340
    },
    {
      "epoch": 1.08,
      "grad_norm": 1.0913666486740112,
      "learning_rate": 6.575342465753424e-05,
      "loss": 0.0673,
      "step": 1350
    },
    {
      "epoch": 1.08,
      "eval_loss": 0.044242974370718,
      "eval_runtime": 22.2971,
      "eval_samples_per_second": 44.849,
      "eval_steps_per_second": 5.606,
      "step": 1350
    },
    {
      "epoch": 1.088,
      "grad_norm": 1.3234087228775024,
      "learning_rate": 6.547945205479452e-05,
      "loss": 0.0663,
      "step": 1360
    },
    {
      "epoch": 1.096,
      "grad_norm": 2.067595958709717,
      "learning_rate": 6.52054794520548e-05,
      "loss": 0.0828,
      "step": 1370
    },
    {
      "epoch": 1.104,
      "grad_norm": 0.5489318370819092,
      "learning_rate": 6.493150684931507e-05,
      "loss": 0.0558,
      "step": 1380
    },
    {
      "epoch": 1.112,
      "grad_norm": 0.320097416639328,
      "learning_rate": 6.465753424657535e-05,
      "loss": 0.0401,
      "step": 1390
    },
    {
      "epoch": 1.12,
      "grad_norm": 1.5495504140853882,
      "learning_rate": 6.438356164383562e-05,
      "loss": 0.07,
      "step": 1400
    },
    {
      "epoch": 1.12,
      "eval_loss": 0.04372769966721535,
      "eval_runtime": 21.1997,
      "eval_samples_per_second": 47.17,
      "eval_steps_per_second": 5.896,
      "step": 1400
    },
    {
      "epoch": 1.1280000000000001,
      "grad_norm": 1.194077491760254,
      "learning_rate": 6.41095890410959e-05,
      "loss": 0.0918,
      "step": 1410
    },
    {
      "epoch": 1.1360000000000001,
      "grad_norm": 2.066185235977173,
      "learning_rate": 6.383561643835617e-05,
      "loss": 0.0811,
      "step": 1420
    },
    {
      "epoch": 1.144,
      "grad_norm": 1.052864670753479,
      "learning_rate": 6.356164383561645e-05,
      "loss": 0.0838,
      "step": 1430
    },
    {
      "epoch": 1.152,
      "grad_norm": 1.280822515487671,
      "learning_rate": 6.328767123287671e-05,
      "loss": 0.0822,
      "step": 1440
    },
    {
      "epoch": 1.16,
      "grad_norm": 0.7252323031425476,
      "learning_rate": 6.301369863013699e-05,
      "loss": 0.0515,
      "step": 1450
    },
    {
      "epoch": 1.16,
      "eval_loss": 0.037570253014564514,
      "eval_runtime": 20.0395,
      "eval_samples_per_second": 49.901,
      "eval_steps_per_second": 6.238,
      "step": 1450
    },
    {
      "epoch": 1.168,
      "grad_norm": 1.708153486251831,
      "learning_rate": 6.273972602739726e-05,
      "loss": 0.0483,
      "step": 1460
    },
    {
      "epoch": 1.176,
      "grad_norm": 2.5002102851867676,
      "learning_rate": 6.246575342465753e-05,
      "loss": 0.1023,
      "step": 1470
    },
    {
      "epoch": 1.184,
      "grad_norm": 0.8064674735069275,
      "learning_rate": 6.219178082191781e-05,
      "loss": 0.0708,
      "step": 1480
    },
    {
      "epoch": 1.192,
      "grad_norm": 1.6501160860061646,
      "learning_rate": 6.191780821917809e-05,
      "loss": 0.0475,
      "step": 1490
    },
    {
      "epoch": 1.2,
      "grad_norm": 1.1064374446868896,
      "learning_rate": 6.164383561643835e-05,
      "loss": 0.0513,
      "step": 1500
    },
    {
      "epoch": 1.2,
      "eval_loss": 0.033732470124959946,
      "eval_runtime": 22.2643,
      "eval_samples_per_second": 44.915,
      "eval_steps_per_second": 5.614,
      "step": 1500
    },
    {
      "epoch": 1.208,
      "grad_norm": 3.143739700317383,
      "learning_rate": 6.136986301369863e-05,
      "loss": 0.0941,
      "step": 1510
    },
    {
      "epoch": 1.216,
      "grad_norm": 1.6252672672271729,
      "learning_rate": 6.109589041095891e-05,
      "loss": 0.0558,
      "step": 1520
    },
    {
      "epoch": 1.224,
      "grad_norm": 1.2464507818222046,
      "learning_rate": 6.082191780821919e-05,
      "loss": 0.0759,
      "step": 1530
    },
    {
      "epoch": 1.232,
      "grad_norm": 1.6384994983673096,
      "learning_rate": 6.054794520547945e-05,
      "loss": 0.077,
      "step": 1540
    },
    {
      "epoch": 1.24,
      "grad_norm": 1.1619091033935547,
      "learning_rate": 6.0273972602739724e-05,
      "loss": 0.0624,
      "step": 1550
    },
    {
      "epoch": 1.24,
      "eval_loss": 0.031590234488248825,
      "eval_runtime": 18.935,
      "eval_samples_per_second": 52.812,
      "eval_steps_per_second": 6.602,
      "step": 1550
    },
    {
      "epoch": 1.248,
      "grad_norm": 0.9302007555961609,
      "learning_rate": 6e-05,
      "loss": 0.0659,
      "step": 1560
    },
    {
      "epoch": 1.256,
      "grad_norm": 0.5965500473976135,
      "learning_rate": 5.972602739726027e-05,
      "loss": 0.0628,
      "step": 1570
    },
    {
      "epoch": 1.264,
      "grad_norm": 2.1590542793273926,
      "learning_rate": 5.945205479452055e-05,
      "loss": 0.0801,
      "step": 1580
    },
    {
      "epoch": 1.272,
      "grad_norm": 1.5337750911712646,
      "learning_rate": 5.917808219178083e-05,
      "loss": 0.0899,
      "step": 1590
    },
    {
      "epoch": 1.28,
      "grad_norm": 1.0004363059997559,
      "learning_rate": 5.89041095890411e-05,
      "loss": 0.0803,
      "step": 1600
    },
    {
      "epoch": 1.28,
      "eval_loss": 0.027908124029636383,
      "eval_runtime": 21.5759,
      "eval_samples_per_second": 46.348,
      "eval_steps_per_second": 5.794,
      "step": 1600
    },
    {
      "epoch": 1.288,
      "grad_norm": 0.21992719173431396,
      "learning_rate": 5.863013698630138e-05,
      "loss": 0.1151,
      "step": 1610
    },
    {
      "epoch": 1.296,
      "grad_norm": 1.0464705228805542,
      "learning_rate": 5.835616438356165e-05,
      "loss": 0.0459,
      "step": 1620
    },
    {
      "epoch": 1.304,
      "grad_norm": 0.7552561163902283,
      "learning_rate": 5.808219178082191e-05,
      "loss": 0.048,
      "step": 1630
    },
    {
      "epoch": 1.312,
      "grad_norm": 2.913182020187378,
      "learning_rate": 5.780821917808219e-05,
      "loss": 0.1028,
      "step": 1640
    },
    {
      "epoch": 1.32,
      "grad_norm": 1.806087613105774,
      "learning_rate": 5.753424657534247e-05,
      "loss": 0.1265,
      "step": 1650
    },
    {
      "epoch": 1.32,
      "eval_loss": 0.02737043984234333,
      "eval_runtime": 21.3074,
      "eval_samples_per_second": 46.932,
      "eval_steps_per_second": 5.867,
      "step": 1650
    },
    {
      "epoch": 1.328,
      "grad_norm": 0.25489822030067444,
      "learning_rate": 5.726027397260274e-05,
      "loss": 0.0433,
      "step": 1660
    },
    {
      "epoch": 1.336,
      "grad_norm": 0.6301125884056091,
      "learning_rate": 5.698630136986302e-05,
      "loss": 0.0356,
      "step": 1670
    },
    {
      "epoch": 1.3439999999999999,
      "grad_norm": 1.7812910079956055,
      "learning_rate": 5.671232876712329e-05,
      "loss": 0.036,
      "step": 1680
    },
    {
      "epoch": 1.3519999999999999,
      "grad_norm": 3.8669891357421875,
      "learning_rate": 5.643835616438357e-05,
      "loss": 0.061,
      "step": 1690
    },
    {
      "epoch": 1.3599999999999999,
      "grad_norm": 0.4303673207759857,
      "learning_rate": 5.616438356164384e-05,
      "loss": 0.0441,
      "step": 1700
    },
    {
      "epoch": 1.3599999999999999,
      "eval_loss": 0.030308542773127556,
      "eval_runtime": 22.258,
      "eval_samples_per_second": 44.928,
      "eval_steps_per_second": 5.616,
      "step": 1700
    },
    {
      "epoch": 1.3679999999999999,
      "grad_norm": 1.195558786392212,
      "learning_rate": 5.5890410958904116e-05,
      "loss": 0.0543,
      "step": 1710
    },
    {
      "epoch": 1.376,
      "grad_norm": 1.1674761772155762,
      "learning_rate": 5.5616438356164394e-05,
      "loss": 0.0583,
      "step": 1720
    },
    {
      "epoch": 1.384,
      "grad_norm": 1.3791906833648682,
      "learning_rate": 5.534246575342466e-05,
      "loss": 0.0744,
      "step": 1730
    },
    {
      "epoch": 1.392,
      "grad_norm": 2.957868814468384,
      "learning_rate": 5.506849315068493e-05,
      "loss": 0.0498,
      "step": 1740
    },
    {
      "epoch": 1.4,
      "grad_norm": 0.301054984331131,
      "learning_rate": 5.479452054794521e-05,
      "loss": 0.0482,
      "step": 1750
    },
    {
      "epoch": 1.4,
      "eval_loss": 0.02625320479273796,
      "eval_runtime": 22.1002,
      "eval_samples_per_second": 45.248,
      "eval_steps_per_second": 5.656,
      "step": 1750
    },
    {
      "epoch": 1.408,
      "grad_norm": 0.20422087609767914,
      "learning_rate": 5.452054794520548e-05,
      "loss": 0.0524,
      "step": 1760
    },
    {
      "epoch": 1.416,
      "grad_norm": 0.3881286084651947,
      "learning_rate": 5.4246575342465756e-05,
      "loss": 0.0589,
      "step": 1770
    },
    {
      "epoch": 1.424,
      "grad_norm": 0.8336181640625,
      "learning_rate": 5.397260273972603e-05,
      "loss": 0.0492,
      "step": 1780
    },
    {
      "epoch": 1.432,
      "grad_norm": 1.7646546363830566,
      "learning_rate": 5.3698630136986305e-05,
      "loss": 0.042,
      "step": 1790
    },
    {
      "epoch": 1.44,
      "grad_norm": 0.37244465947151184,
      "learning_rate": 5.342465753424658e-05,
      "loss": 0.078,
      "step": 1800
    },
    {
      "epoch": 1.44,
      "eval_loss": 0.028779173269867897,
      "eval_runtime": 22.2489,
      "eval_samples_per_second": 44.946,
      "eval_steps_per_second": 5.618,
      "step": 1800
    },
    {
      "epoch": 1.448,
      "grad_norm": 2.9501523971557617,
      "learning_rate": 5.3150684931506854e-05,
      "loss": 0.0851,
      "step": 1810
    },
    {
      "epoch": 1.456,
      "grad_norm": 0.9570401906967163,
      "learning_rate": 5.287671232876713e-05,
      "loss": 0.0787,
      "step": 1820
    },
    {
      "epoch": 1.464,
      "grad_norm": 0.370771199464798,
      "learning_rate": 5.2602739726027396e-05,
      "loss": 0.0809,
      "step": 1830
    },
    {
      "epoch": 1.472,
      "grad_norm": 1.002983570098877,
      "learning_rate": 5.232876712328767e-05,
      "loss": 0.0643,
      "step": 1840
    },
    {
      "epoch": 1.48,
      "grad_norm": 0.6935033798217773,
      "learning_rate": 5.2054794520547945e-05,
      "loss": 0.07,
      "step": 1850
    },
    {
      "epoch": 1.48,
      "eval_loss": 0.022602131590247154,
      "eval_runtime": 22.329,
      "eval_samples_per_second": 44.785,
      "eval_steps_per_second": 5.598,
      "step": 1850
    },
    {
      "epoch": 1.488,
      "grad_norm": 1.3676304817199707,
      "learning_rate": 5.178082191780822e-05,
      "loss": 0.0642,
      "step": 1860
    },
    {
      "epoch": 1.496,
      "grad_norm": 2.0602684020996094,
      "learning_rate": 5.1506849315068494e-05,
      "loss": 0.0662,
      "step": 1870
    },
    {
      "epoch": 1.504,
      "grad_norm": 0.9892136454582214,
      "learning_rate": 5.123287671232877e-05,
      "loss": 0.0262,
      "step": 1880
    },
    {
      "epoch": 1.512,
      "grad_norm": 1.0242482423782349,
      "learning_rate": 5.095890410958904e-05,
      "loss": 0.0646,
      "step": 1890
    },
    {
      "epoch": 1.52,
      "grad_norm": 0.20952048897743225,
      "learning_rate": 5.068493150684932e-05,
      "loss": 0.0686,
      "step": 1900
    },
    {
      "epoch": 1.52,
      "eval_loss": 0.023495374247431755,
      "eval_runtime": 22.293,
      "eval_samples_per_second": 44.857,
      "eval_steps_per_second": 5.607,
      "step": 1900
    },
    {
      "epoch": 1.528,
      "grad_norm": 5.1926655769348145,
      "learning_rate": 5.041095890410959e-05,
      "loss": 0.0631,
      "step": 1910
    },
    {
      "epoch": 1.536,
      "grad_norm": 1.586557388305664,
      "learning_rate": 5.013698630136987e-05,
      "loss": 0.0448,
      "step": 1920
    },
    {
      "epoch": 1.544,
      "grad_norm": 2.0204925537109375,
      "learning_rate": 4.986301369863014e-05,
      "loss": 0.0971,
      "step": 1930
    },
    {
      "epoch": 1.552,
      "grad_norm": 0.5713384747505188,
      "learning_rate": 4.958904109589041e-05,
      "loss": 0.0408,
      "step": 1940
    },
    {
      "epoch": 1.56,
      "grad_norm": 1.2568279504776,
      "learning_rate": 4.9315068493150684e-05,
      "loss": 0.0861,
      "step": 1950
    },
    {
      "epoch": 1.56,
      "eval_loss": 0.023479759693145752,
      "eval_runtime": 16.7685,
      "eval_samples_per_second": 59.636,
      "eval_steps_per_second": 7.454,
      "step": 1950
    },
    {
      "epoch": 1.568,
      "grad_norm": 0.1449020951986313,
      "learning_rate": 4.904109589041096e-05,
      "loss": 0.0308,
      "step": 1960
    },
    {
      "epoch": 1.576,
      "grad_norm": 1.895337700843811,
      "learning_rate": 4.876712328767123e-05,
      "loss": 0.0478,
      "step": 1970
    },
    {
      "epoch": 1.584,
      "grad_norm": 0.8849165439605713,
      "learning_rate": 4.849315068493151e-05,
      "loss": 0.038,
      "step": 1980
    },
    {
      "epoch": 1.592,
      "grad_norm": 2.4786508083343506,
      "learning_rate": 4.821917808219178e-05,
      "loss": 0.0375,
      "step": 1990
    },
    {
      "epoch": 1.6,
      "grad_norm": 1.6239209175109863,
      "learning_rate": 4.794520547945205e-05,
      "loss": 0.0573,
      "step": 2000
    },
    {
      "epoch": 1.6,
      "eval_loss": 0.025135057047009468,
      "eval_runtime": 16.5123,
      "eval_samples_per_second": 60.561,
      "eval_steps_per_second": 7.57,
      "step": 2000
    },
    {
      "epoch": 1.608,
      "grad_norm": 1.5267127752304077,
      "learning_rate": 4.767123287671233e-05,
      "loss": 0.0306,
      "step": 2010
    },
    {
      "epoch": 1.616,
      "grad_norm": 2.1554055213928223,
      "learning_rate": 4.73972602739726e-05,
      "loss": 0.0562,
      "step": 2020
    },
    {
      "epoch": 1.624,
      "grad_norm": 0.40959420800209045,
      "learning_rate": 4.712328767123288e-05,
      "loss": 0.0242,
      "step": 2030
    },
    {
      "epoch": 1.6320000000000001,
      "grad_norm": 0.5296052098274231,
      "learning_rate": 4.684931506849316e-05,
      "loss": 0.0567,
      "step": 2040
    },
    {
      "epoch": 1.6400000000000001,
      "grad_norm": 0.5205649137496948,
      "learning_rate": 4.657534246575342e-05,
      "loss": 0.0457,
      "step": 2050
    },
    {
      "epoch": 1.6400000000000001,
      "eval_loss": 0.023944703862071037,
      "eval_runtime": 16.3662,
      "eval_samples_per_second": 61.101,
      "eval_steps_per_second": 7.638,
      "step": 2050
    },
    {
      "epoch": 1.6480000000000001,
      "grad_norm": 1.2464851140975952,
      "learning_rate": 4.63013698630137e-05,
      "loss": 0.084,
      "step": 2060
    },
    {
      "epoch": 1.6560000000000001,
      "grad_norm": 3.0052757263183594,
      "learning_rate": 4.602739726027398e-05,
      "loss": 0.042,
      "step": 2070
    },
    {
      "epoch": 1.6640000000000001,
      "grad_norm": 0.2039213627576828,
      "learning_rate": 4.575342465753425e-05,
      "loss": 0.0311,
      "step": 2080
    },
    {
      "epoch": 1.6720000000000002,
      "grad_norm": 0.7459041476249695,
      "learning_rate": 4.547945205479453e-05,
      "loss": 0.0338,
      "step": 2090
    },
    {
      "epoch": 1.6800000000000002,
      "grad_norm": 3.785764217376709,
      "learning_rate": 4.520547945205479e-05,
      "loss": 0.1039,
      "step": 2100
    },
    {
      "epoch": 1.6800000000000002,
      "eval_loss": 0.019811322912573814,
      "eval_runtime": 16.3099,
      "eval_samples_per_second": 61.313,
      "eval_steps_per_second": 7.664,
      "step": 2100
    },
    {
      "epoch": 1.688,
      "grad_norm": 1.6482373476028442,
      "learning_rate": 4.493150684931507e-05,
      "loss": 0.0514,
      "step": 2110
    },
    {
      "epoch": 1.696,
      "grad_norm": 0.8851730823516846,
      "learning_rate": 4.465753424657535e-05,
      "loss": 0.0341,
      "step": 2120
    },
    {
      "epoch": 1.704,
      "grad_norm": 0.14161434769630432,
      "learning_rate": 4.438356164383562e-05,
      "loss": 0.0367,
      "step": 2130
    },
    {
      "epoch": 1.712,
      "grad_norm": 2.860074996948242,
      "learning_rate": 4.4109589041095896e-05,
      "loss": 0.0717,
      "step": 2140
    },
    {
      "epoch": 1.72,
      "grad_norm": 0.16247746348381042,
      "learning_rate": 4.383561643835617e-05,
      "loss": 0.0312,
      "step": 2150
    },
    {
      "epoch": 1.72,
      "eval_loss": 0.021958841010928154,
      "eval_runtime": 16.3069,
      "eval_samples_per_second": 61.324,
      "eval_steps_per_second": 7.665,
      "step": 2150
    },
    {
      "epoch": 1.728,
      "grad_norm": 1.040608525276184,
      "learning_rate": 4.356164383561644e-05,
      "loss": 0.0369,
      "step": 2160
    },
    {
      "epoch": 1.736,
      "grad_norm": 1.4293060302734375,
      "learning_rate": 4.3287671232876716e-05,
      "loss": 0.0438,
      "step": 2170
    },
    {
      "epoch": 1.744,
      "grad_norm": 0.20610064268112183,
      "learning_rate": 4.301369863013699e-05,
      "loss": 0.0621,
      "step": 2180
    },
    {
      "epoch": 1.752,
      "grad_norm": 0.26926177740097046,
      "learning_rate": 4.2739726027397265e-05,
      "loss": 0.0337,
      "step": 2190
    },
    {
      "epoch": 1.76,
      "grad_norm": 1.2351797819137573,
      "learning_rate": 4.2465753424657536e-05,
      "loss": 0.068,
      "step": 2200
    },
    {
      "epoch": 1.76,
      "eval_loss": 0.020618095993995667,
      "eval_runtime": 16.6212,
      "eval_samples_per_second": 60.164,
      "eval_steps_per_second": 7.521,
      "step": 2200
    },
    {
      "epoch": 1.768,
      "grad_norm": 0.35592618584632874,
      "learning_rate": 4.219178082191781e-05,
      "loss": 0.0385,
      "step": 2210
    },
    {
      "epoch": 1.776,
      "grad_norm": 1.1612550020217896,
      "learning_rate": 4.1917808219178085e-05,
      "loss": 0.0493,
      "step": 2220
    },
    {
      "epoch": 1.784,
      "grad_norm": 0.19617699086666107,
      "learning_rate": 4.1643835616438356e-05,
      "loss": 0.0188,
      "step": 2230
    },
    {
      "epoch": 1.792,
      "grad_norm": 0.7052519917488098,
      "learning_rate": 4.1369863013698634e-05,
      "loss": 0.0462,
      "step": 2240
    },
    {
      "epoch": 1.8,
      "grad_norm": 0.4183410108089447,
      "learning_rate": 4.1095890410958905e-05,
      "loss": 0.0266,
      "step": 2250
    },
    {
      "epoch": 1.8,
      "eval_loss": 0.021336093544960022,
      "eval_runtime": 19.9489,
      "eval_samples_per_second": 50.128,
      "eval_steps_per_second": 6.266,
      "step": 2250
    },
    {
      "epoch": 1.808,
      "grad_norm": 0.32427430152893066,
      "learning_rate": 4.0821917808219176e-05,
      "loss": 0.0765,
      "step": 2260
    },
    {
      "epoch": 1.8159999999999998,
      "grad_norm": 1.1242574453353882,
      "learning_rate": 4.0547945205479454e-05,
      "loss": 0.0219,
      "step": 2270
    },
    {
      "epoch": 1.8239999999999998,
      "grad_norm": 1.7495530843734741,
      "learning_rate": 4.027397260273973e-05,
      "loss": 0.0307,
      "step": 2280
    },
    {
      "epoch": 1.8319999999999999,
      "grad_norm": 2.6465187072753906,
      "learning_rate": 4e-05,
      "loss": 0.0451,
      "step": 2290
    },
    {
      "epoch": 1.8399999999999999,
      "grad_norm": 1.7370187044143677,
      "learning_rate": 3.9726027397260274e-05,
      "loss": 0.0429,
      "step": 2300
    },
    {
      "epoch": 1.8399999999999999,
      "eval_loss": 0.02127021923661232,
      "eval_runtime": 22.2923,
      "eval_samples_per_second": 44.859,
      "eval_steps_per_second": 5.607,
      "step": 2300
    },
    {
      "epoch": 1.8479999999999999,
      "grad_norm": 1.4893746376037598,
      "learning_rate": 3.9452054794520546e-05,
      "loss": 0.0171,
      "step": 2310
    },
    {
      "epoch": 1.8559999999999999,
      "grad_norm": 0.8861199021339417,
      "learning_rate": 3.9178082191780823e-05,
      "loss": 0.0267,
      "step": 2320
    },
    {
      "epoch": 1.8639999999999999,
      "grad_norm": 0.9244638681411743,
      "learning_rate": 3.89041095890411e-05,
      "loss": 0.037,
      "step": 2330
    },
    {
      "epoch": 1.8719999999999999,
      "grad_norm": 0.5133044123649597,
      "learning_rate": 3.863013698630137e-05,
      "loss": 0.0476,
      "step": 2340
    },
    {
      "epoch": 1.88,
      "grad_norm": 0.34398671984672546,
      "learning_rate": 3.8356164383561644e-05,
      "loss": 0.0267,
      "step": 2350
    },
    {
      "epoch": 1.88,
      "eval_loss": 0.022133052349090576,
      "eval_runtime": 21.3477,
      "eval_samples_per_second": 46.843,
      "eval_steps_per_second": 5.855,
      "step": 2350
    },
    {
      "epoch": 1.888,
      "grad_norm": 0.33398985862731934,
      "learning_rate": 3.808219178082192e-05,
      "loss": 0.0461,
      "step": 2360
    },
    {
      "epoch": 1.896,
      "grad_norm": 2.4404704570770264,
      "learning_rate": 3.780821917808219e-05,
      "loss": 0.0296,
      "step": 2370
    },
    {
      "epoch": 1.904,
      "grad_norm": 0.30467328429222107,
      "learning_rate": 3.753424657534247e-05,
      "loss": 0.0477,
      "step": 2380
    },
    {
      "epoch": 1.912,
      "grad_norm": 2.855813503265381,
      "learning_rate": 3.726027397260274e-05,
      "loss": 0.0504,
      "step": 2390
    },
    {
      "epoch": 1.92,
      "grad_norm": 1.032546043395996,
      "learning_rate": 3.698630136986301e-05,
      "loss": 0.0459,
      "step": 2400
    },
    {
      "epoch": 1.92,
      "eval_loss": 0.020324204117059708,
      "eval_runtime": 22.1663,
      "eval_samples_per_second": 45.114,
      "eval_steps_per_second": 5.639,
      "step": 2400
    },
    {
      "epoch": 1.928,
      "grad_norm": 1.539283275604248,
      "learning_rate": 3.671232876712329e-05,
      "loss": 0.0285,
      "step": 2410
    },
    {
      "epoch": 1.936,
      "grad_norm": 0.770753026008606,
      "learning_rate": 3.643835616438356e-05,
      "loss": 0.0645,
      "step": 2420
    },
    {
      "epoch": 1.944,
      "grad_norm": 0.3170672655105591,
      "learning_rate": 3.616438356164384e-05,
      "loss": 0.0283,
      "step": 2430
    },
    {
      "epoch": 1.952,
      "grad_norm": 2.8821394443511963,
      "learning_rate": 3.589041095890411e-05,
      "loss": 0.041,
      "step": 2440
    },
    {
      "epoch": 1.96,
      "grad_norm": 1.3754349946975708,
      "learning_rate": 3.561643835616438e-05,
      "loss": 0.0565,
      "step": 2450
    },
    {
      "epoch": 1.96,
      "eval_loss": 0.019266445189714432,
      "eval_runtime": 21.0325,
      "eval_samples_per_second": 47.545,
      "eval_steps_per_second": 5.943,
      "step": 2450
    },
    {
      "epoch": 1.968,
      "grad_norm": 0.4013175368309021,
      "learning_rate": 3.534246575342466e-05,
      "loss": 0.0223,
      "step": 2460
    },
    {
      "epoch": 1.976,
      "grad_norm": 6.68011474609375,
      "learning_rate": 3.506849315068493e-05,
      "loss": 0.0854,
      "step": 2470
    },
    {
      "epoch": 1.984,
      "grad_norm": 0.19758649170398712,
      "learning_rate": 3.479452054794521e-05,
      "loss": 0.0253,
      "step": 2480
    },
    {
      "epoch": 1.992,
      "grad_norm": 0.983833909034729,
      "learning_rate": 3.452054794520549e-05,
      "loss": 0.0214,
      "step": 2490
    },
    {
      "epoch": 2.0,
      "grad_norm": 0.46071454882621765,
      "learning_rate": 3.424657534246575e-05,
      "loss": 0.0235,
      "step": 2500
    },
    {
      "epoch": 2.0,
      "eval_loss": 0.021115105599164963,
      "eval_runtime": 22.3154,
      "eval_samples_per_second": 44.812,
      "eval_steps_per_second": 5.602,
      "step": 2500
    },
    {
      "epoch": 2.008,
      "grad_norm": 0.6077607870101929,
      "learning_rate": 3.397260273972603e-05,
      "loss": 0.0403,
      "step": 2510
    },
    {
      "epoch": 2.016,
      "grad_norm": 0.5663872361183167,
      "learning_rate": 3.36986301369863e-05,
      "loss": 0.0386,
      "step": 2520
    },
    {
      "epoch": 2.024,
      "grad_norm": 0.9404841661453247,
      "learning_rate": 3.342465753424658e-05,
      "loss": 0.036,
      "step": 2530
    },
    {
      "epoch": 2.032,
      "grad_norm": 0.9700506329536438,
      "learning_rate": 3.3150684931506856e-05,
      "loss": 0.0189,
      "step": 2540
    },
    {
      "epoch": 2.04,
      "grad_norm": 1.8529490232467651,
      "learning_rate": 3.287671232876712e-05,
      "loss": 0.0472,
      "step": 2550
    },
    {
      "epoch": 2.04,
      "eval_loss": 0.01985567808151245,
      "eval_runtime": 21.624,
      "eval_samples_per_second": 46.245,
      "eval_steps_per_second": 5.781,
      "step": 2550
    },
    {
      "epoch": 2.048,
      "grad_norm": 0.8852730989456177,
      "learning_rate": 3.26027397260274e-05,
      "loss": 0.0368,
      "step": 2560
    },
    {
      "epoch": 2.056,
      "grad_norm": 0.45899707078933716,
      "learning_rate": 3.2328767123287676e-05,
      "loss": 0.0204,
      "step": 2570
    },
    {
      "epoch": 2.064,
      "grad_norm": 1.70969557762146,
      "learning_rate": 3.205479452054795e-05,
      "loss": 0.0638,
      "step": 2580
    },
    {
      "epoch": 2.072,
      "grad_norm": 0.5084442496299744,
      "learning_rate": 3.1780821917808225e-05,
      "loss": 0.0536,
      "step": 2590
    },
    {
      "epoch": 2.08,
      "grad_norm": 0.21449245512485504,
      "learning_rate": 3.1506849315068496e-05,
      "loss": 0.0302,
      "step": 2600
    },
    {
      "epoch": 2.08,
      "eval_loss": 0.019362786784768105,
      "eval_runtime": 22.18,
      "eval_samples_per_second": 45.086,
      "eval_steps_per_second": 5.636,
      "step": 2600
    },
    {
      "epoch": 2.088,
      "grad_norm": 0.15908902883529663,
      "learning_rate": 3.123287671232877e-05,
      "loss": 0.0211,
      "step": 2610
    },
    {
      "epoch": 2.096,
      "grad_norm": 0.41698938608169556,
      "learning_rate": 3.0958904109589045e-05,
      "loss": 0.0256,
      "step": 2620
    },
    {
      "epoch": 2.104,
      "grad_norm": 0.29587286710739136,
      "learning_rate": 3.0684931506849316e-05,
      "loss": 0.027,
      "step": 2630
    },
    {
      "epoch": 2.112,
      "grad_norm": 0.3678203821182251,
      "learning_rate": 3.0410958904109594e-05,
      "loss": 0.0268,
      "step": 2640
    },
    {
      "epoch": 2.12,
      "grad_norm": 0.006983905099332333,
      "learning_rate": 3.0136986301369862e-05,
      "loss": 0.0283,
      "step": 2650
    },
    {
      "epoch": 2.12,
      "eval_loss": 0.017671504989266396,
      "eval_runtime": 22.2127,
      "eval_samples_per_second": 45.019,
      "eval_steps_per_second": 5.627,
      "step": 2650
    },
    {
      "epoch": 2.128,
      "grad_norm": 1.9045978784561157,
      "learning_rate": 2.9863013698630136e-05,
      "loss": 0.0311,
      "step": 2660
    },
    {
      "epoch": 2.136,
      "grad_norm": 1.964074969291687,
      "learning_rate": 2.9589041095890414e-05,
      "loss": 0.0455,
      "step": 2670
    },
    {
      "epoch": 2.144,
      "grad_norm": 1.457910180091858,
      "learning_rate": 2.931506849315069e-05,
      "loss": 0.0248,
      "step": 2680
    },
    {
      "epoch": 2.152,
      "grad_norm": 0.6531630158424377,
      "learning_rate": 2.9041095890410956e-05,
      "loss": 0.0342,
      "step": 2690
    },
    {
      "epoch": 2.16,
      "grad_norm": 0.5718494653701782,
      "learning_rate": 2.8767123287671234e-05,
      "loss": 0.0205,
      "step": 2700
    },
    {
      "epoch": 2.16,
      "eval_loss": 0.018619129434227943,
      "eval_runtime": 21.1322,
      "eval_samples_per_second": 47.321,
      "eval_steps_per_second": 5.915,
      "step": 2700
    },
    {
      "epoch": 2.168,
      "grad_norm": 1.8760405778884888,
      "learning_rate": 2.849315068493151e-05,
      "loss": 0.0396,
      "step": 2710
    },
    {
      "epoch": 2.176,
      "grad_norm": 1.4555516242980957,
      "learning_rate": 2.8219178082191783e-05,
      "loss": 0.0589,
      "step": 2720
    },
    {
      "epoch": 2.184,
      "grad_norm": 0.47975078225135803,
      "learning_rate": 2.7945205479452058e-05,
      "loss": 0.0169,
      "step": 2730
    },
    {
      "epoch": 2.192,
      "grad_norm": 0.6301300525665283,
      "learning_rate": 2.767123287671233e-05,
      "loss": 0.0159,
      "step": 2740
    },
    {
      "epoch": 2.2,
      "grad_norm": 0.626194417476654,
      "learning_rate": 2.7397260273972603e-05,
      "loss": 0.0369,
      "step": 2750
    },
    {
      "epoch": 2.2,
      "eval_loss": 0.018161699175834656,
      "eval_runtime": 22.1294,
      "eval_samples_per_second": 45.189,
      "eval_steps_per_second": 5.649,
      "step": 2750
    },
    {
      "epoch": 2.208,
      "grad_norm": 0.34319183230400085,
      "learning_rate": 2.7123287671232878e-05,
      "loss": 0.0294,
      "step": 2760
    },
    {
      "epoch": 2.216,
      "grad_norm": 1.316065788269043,
      "learning_rate": 2.6849315068493153e-05,
      "loss": 0.0306,
      "step": 2770
    },
    {
      "epoch": 2.224,
      "grad_norm": 1.4393892288208008,
      "learning_rate": 2.6575342465753427e-05,
      "loss": 0.0344,
      "step": 2780
    },
    {
      "epoch": 2.232,
      "grad_norm": 2.8810296058654785,
      "learning_rate": 2.6301369863013698e-05,
      "loss": 0.0196,
      "step": 2790
    },
    {
      "epoch": 2.24,
      "grad_norm": 1.0446206331253052,
      "learning_rate": 2.6027397260273973e-05,
      "loss": 0.0202,
      "step": 2800
    },
    {
      "epoch": 2.24,
      "eval_loss": 0.01697271317243576,
      "eval_runtime": 22.0676,
      "eval_samples_per_second": 45.315,
      "eval_steps_per_second": 5.664,
      "step": 2800
    },
    {
      "epoch": 2.248,
      "grad_norm": 0.43777063488960266,
      "learning_rate": 2.5753424657534247e-05,
      "loss": 0.0246,
      "step": 2810
    },
    {
      "epoch": 2.2560000000000002,
      "grad_norm": 1.1104341745376587,
      "learning_rate": 2.547945205479452e-05,
      "loss": 0.0398,
      "step": 2820
    },
    {
      "epoch": 2.2640000000000002,
      "grad_norm": 0.541327953338623,
      "learning_rate": 2.5205479452054796e-05,
      "loss": 0.0361,
      "step": 2830
    },
    {
      "epoch": 2.2720000000000002,
      "grad_norm": 0.26432037353515625,
      "learning_rate": 2.493150684931507e-05,
      "loss": 0.0213,
      "step": 2840
    },
    {
      "epoch": 2.2800000000000002,
      "grad_norm": 0.6358492970466614,
      "learning_rate": 2.4657534246575342e-05,
      "loss": 0.025,
      "step": 2850
    },
    {
      "epoch": 2.2800000000000002,
      "eval_loss": 0.01642666943371296,
      "eval_runtime": 16.2411,
      "eval_samples_per_second": 61.572,
      "eval_steps_per_second": 7.697,
      "step": 2850
    },
    {
      "epoch": 2.288,
      "grad_norm": 1.0048714876174927,
      "learning_rate": 2.4383561643835616e-05,
      "loss": 0.018,
      "step": 2860
    },
    {
      "epoch": 2.296,
      "grad_norm": 0.9910967350006104,
      "learning_rate": 2.410958904109589e-05,
      "loss": 0.0423,
      "step": 2870
    },
    {
      "epoch": 2.304,
      "grad_norm": 1.0713342428207397,
      "learning_rate": 2.3835616438356165e-05,
      "loss": 0.0208,
      "step": 2880
    },
    {
      "epoch": 2.312,
      "grad_norm": 0.04542650282382965,
      "learning_rate": 2.356164383561644e-05,
      "loss": 0.0208,
      "step": 2890
    },
    {
      "epoch": 2.32,
      "grad_norm": 37.556617736816406,
      "learning_rate": 2.328767123287671e-05,
      "loss": 0.0311,
      "step": 2900
    },
    {
      "epoch": 2.32,
      "eval_loss": 0.01670709252357483,
      "eval_runtime": 16.1726,
      "eval_samples_per_second": 61.833,
      "eval_steps_per_second": 7.729,
      "step": 2900
    },
    {
      "epoch": 2.328,
      "grad_norm": 0.9276155829429626,
      "learning_rate": 2.301369863013699e-05,
      "loss": 0.0307,
      "step": 2910
    },
    {
      "epoch": 2.336,
      "grad_norm": 0.4345059394836426,
      "learning_rate": 2.2739726027397263e-05,
      "loss": 0.0418,
      "step": 2920
    },
    {
      "epoch": 2.344,
      "grad_norm": 0.7556586861610413,
      "learning_rate": 2.2465753424657534e-05,
      "loss": 0.0312,
      "step": 2930
    },
    {
      "epoch": 2.352,
      "grad_norm": 1.416539192199707,
      "learning_rate": 2.219178082191781e-05,
      "loss": 0.0268,
      "step": 2940
    },
    {
      "epoch": 2.36,
      "grad_norm": 0.6930264830589294,
      "learning_rate": 2.1917808219178083e-05,
      "loss": 0.0377,
      "step": 2950
    },
    {
      "epoch": 2.36,
      "eval_loss": 0.017447613179683685,
      "eval_runtime": 16.6063,
      "eval_samples_per_second": 60.218,
      "eval_steps_per_second": 7.527,
      "step": 2950
    },
    {
      "epoch": 2.368,
      "grad_norm": 0.762338399887085,
      "learning_rate": 2.1643835616438358e-05,
      "loss": 0.0252,
      "step": 2960
    },
    {
      "epoch": 2.376,
      "grad_norm": 1.637494683265686,
      "learning_rate": 2.1369863013698632e-05,
      "loss": 0.0443,
      "step": 2970
    },
    {
      "epoch": 2.384,
      "grad_norm": 1.2968872785568237,
      "learning_rate": 2.1095890410958904e-05,
      "loss": 0.0286,
      "step": 2980
    },
    {
      "epoch": 2.392,
      "grad_norm": 2.533851385116577,
      "learning_rate": 2.0821917808219178e-05,
      "loss": 0.0374,
      "step": 2990
    },
    {
      "epoch": 2.4,
      "grad_norm": 0.6508400440216064,
      "learning_rate": 2.0547945205479453e-05,
      "loss": 0.0481,
      "step": 3000
    },
    {
      "epoch": 2.4,
      "eval_loss": 0.016056163236498833,
      "eval_runtime": 16.7907,
      "eval_samples_per_second": 59.557,
      "eval_steps_per_second": 7.445,
      "step": 3000
    },
    {
      "epoch": 2.408,
      "grad_norm": 0.8974454998970032,
      "learning_rate": 2.0273972602739727e-05,
      "loss": 0.0114,
      "step": 3010
    },
    {
      "epoch": 2.416,
      "grad_norm": 0.5431960225105286,
      "learning_rate": 2e-05,
      "loss": 0.0242,
      "step": 3020
    },
    {
      "epoch": 2.424,
      "grad_norm": 0.2346200793981552,
      "learning_rate": 1.9726027397260273e-05,
      "loss": 0.0648,
      "step": 3030
    },
    {
      "epoch": 2.432,
      "grad_norm": 0.12754204869270325,
      "learning_rate": 1.945205479452055e-05,
      "loss": 0.0238,
      "step": 3040
    },
    {
      "epoch": 2.44,
      "grad_norm": 0.9931102395057678,
      "learning_rate": 1.9178082191780822e-05,
      "loss": 0.0356,
      "step": 3050
    },
    {
      "epoch": 2.44,
      "eval_loss": 0.015602350234985352,
      "eval_runtime": 16.8637,
      "eval_samples_per_second": 59.299,
      "eval_steps_per_second": 7.412,
      "step": 3050
    },
    {
      "epoch": 2.448,
      "grad_norm": 0.1236674040555954,
      "learning_rate": 1.8904109589041096e-05,
      "loss": 0.0273,
      "step": 3060
    },
    {
      "epoch": 2.456,
      "grad_norm": 2.2327189445495605,
      "learning_rate": 1.863013698630137e-05,
      "loss": 0.0381,
      "step": 3070
    },
    {
      "epoch": 2.464,
      "grad_norm": 2.2115132808685303,
      "learning_rate": 1.8356164383561645e-05,
      "loss": 0.0496,
      "step": 3080
    },
    {
      "epoch": 2.472,
      "grad_norm": 2.492055892944336,
      "learning_rate": 1.808219178082192e-05,
      "loss": 0.0249,
      "step": 3090
    },
    {
      "epoch": 2.48,
      "grad_norm": 0.43154236674308777,
      "learning_rate": 1.780821917808219e-05,
      "loss": 0.0211,
      "step": 3100
    },
    {
      "epoch": 2.48,
      "eval_loss": 0.015806499868631363,
      "eval_runtime": 19.3852,
      "eval_samples_per_second": 51.586,
      "eval_steps_per_second": 6.448,
      "step": 3100
    },
    {
      "epoch": 2.488,
      "grad_norm": 0.22027379274368286,
      "learning_rate": 1.7534246575342465e-05,
      "loss": 0.025,
      "step": 3110
    },
    {
      "epoch": 2.496,
      "grad_norm": 0.1001138985157013,
      "learning_rate": 1.7260273972602743e-05,
      "loss": 0.0401,
      "step": 3120
    },
    {
      "epoch": 2.504,
      "grad_norm": 0.13954514265060425,
      "learning_rate": 1.6986301369863014e-05,
      "loss": 0.0148,
      "step": 3130
    },
    {
      "epoch": 2.512,
      "grad_norm": 0.07444072514772415,
      "learning_rate": 1.671232876712329e-05,
      "loss": 0.0481,
      "step": 3140
    },
    {
      "epoch": 2.52,
      "grad_norm": 0.5855003595352173,
      "learning_rate": 1.643835616438356e-05,
      "loss": 0.0208,
      "step": 3150
    },
    {
      "epoch": 2.52,
      "eval_loss": 0.01500316895544529,
      "eval_runtime": 17.1949,
      "eval_samples_per_second": 58.157,
      "eval_steps_per_second": 7.27,
      "step": 3150
    },
    {
      "epoch": 2.528,
      "grad_norm": 0.0903218686580658,
      "learning_rate": 1.6164383561643838e-05,
      "loss": 0.0237,
      "step": 3160
    },
    {
      "epoch": 2.536,
      "grad_norm": 5.421360492706299,
      "learning_rate": 1.5890410958904112e-05,
      "loss": 0.0226,
      "step": 3170
    },
    {
      "epoch": 2.544,
      "grad_norm": 0.5542370676994324,
      "learning_rate": 1.5616438356164384e-05,
      "loss": 0.0338,
      "step": 3180
    },
    {
      "epoch": 2.552,
      "grad_norm": 0.11085626482963562,
      "learning_rate": 1.5342465753424658e-05,
      "loss": 0.0225,
      "step": 3190
    },
    {
      "epoch": 2.56,
      "grad_norm": 2.29176926612854,
      "learning_rate": 1.5068493150684931e-05,
      "loss": 0.0433,
      "step": 3200
    },
    {
      "epoch": 2.56,
      "eval_loss": 0.015276880003511906,
      "eval_runtime": 16.3221,
      "eval_samples_per_second": 61.267,
      "eval_steps_per_second": 7.658,
      "step": 3200
    },
    {
      "epoch": 2.568,
      "grad_norm": 3.7918550968170166,
      "learning_rate": 1.4794520547945207e-05,
      "loss": 0.0194,
      "step": 3210
    },
    {
      "epoch": 2.576,
      "grad_norm": 0.7816351056098938,
      "learning_rate": 1.4520547945205478e-05,
      "loss": 0.026,
      "step": 3220
    },
    {
      "epoch": 2.584,
      "grad_norm": 0.6508844494819641,
      "learning_rate": 1.4246575342465754e-05,
      "loss": 0.0306,
      "step": 3230
    },
    {
      "epoch": 2.592,
      "grad_norm": 0.8497304320335388,
      "learning_rate": 1.3972602739726029e-05,
      "loss": 0.0298,
      "step": 3240
    },
    {
      "epoch": 2.6,
      "grad_norm": 0.3278293311595917,
      "learning_rate": 1.3698630136986302e-05,
      "loss": 0.021,
      "step": 3250
    },
    {
      "epoch": 2.6,
      "eval_loss": 0.016433708369731903,
      "eval_runtime": 16.2643,
      "eval_samples_per_second": 61.484,
      "eval_steps_per_second": 7.686,
      "step": 3250
    },
    {
      "epoch": 2.608,
      "grad_norm": 0.3869769871234894,
      "learning_rate": 1.3424657534246576e-05,
      "loss": 0.0165,
      "step": 3260
    },
    {
      "epoch": 2.616,
      "grad_norm": 0.528069257736206,
      "learning_rate": 1.3150684931506849e-05,
      "loss": 0.0426,
      "step": 3270
    },
    {
      "epoch": 2.624,
      "grad_norm": 2.7373907566070557,
      "learning_rate": 1.2876712328767124e-05,
      "loss": 0.0608,
      "step": 3280
    },
    {
      "epoch": 2.632,
      "grad_norm": 3.355268955230713,
      "learning_rate": 1.2602739726027398e-05,
      "loss": 0.0257,
      "step": 3290
    },
    {
      "epoch": 2.64,
      "grad_norm": 0.32252100110054016,
      "learning_rate": 1.2328767123287671e-05,
      "loss": 0.0247,
      "step": 3300
    },
    {
      "epoch": 2.64,
      "eval_loss": 0.01616072840988636,
      "eval_runtime": 16.2804,
      "eval_samples_per_second": 61.424,
      "eval_steps_per_second": 7.678,
      "step": 3300
    },
    {
      "epoch": 2.648,
      "grad_norm": 0.925988495349884,
      "learning_rate": 1.2054794520547945e-05,
      "loss": 0.0248,
      "step": 3310
    },
    {
      "epoch": 2.656,
      "grad_norm": 0.6365585327148438,
      "learning_rate": 1.178082191780822e-05,
      "loss": 0.0233,
      "step": 3320
    },
    {
      "epoch": 2.664,
      "grad_norm": 2.661167621612549,
      "learning_rate": 1.1506849315068494e-05,
      "loss": 0.0352,
      "step": 3330
    },
    {
      "epoch": 2.672,
      "grad_norm": 0.17919190227985382,
      "learning_rate": 1.1232876712328767e-05,
      "loss": 0.0145,
      "step": 3340
    },
    {
      "epoch": 2.68,
      "grad_norm": 1.519063115119934,
      "learning_rate": 1.0958904109589042e-05,
      "loss": 0.0431,
      "step": 3350
    },
    {
      "epoch": 2.68,
      "eval_loss": 0.015954433009028435,
      "eval_runtime": 16.5858,
      "eval_samples_per_second": 60.293,
      "eval_steps_per_second": 7.537,
      "step": 3350
    },
    {
      "epoch": 2.6879999999999997,
      "grad_norm": 0.12159691005945206,
      "learning_rate": 1.0684931506849316e-05,
      "loss": 0.0259,
      "step": 3360
    },
    {
      "epoch": 2.6959999999999997,
      "grad_norm": 1.0774297714233398,
      "learning_rate": 1.0410958904109589e-05,
      "loss": 0.0241,
      "step": 3370
    },
    {
      "epoch": 2.7039999999999997,
      "grad_norm": 0.6912699341773987,
      "learning_rate": 1.0136986301369864e-05,
      "loss": 0.015,
      "step": 3380
    },
    {
      "epoch": 2.7119999999999997,
      "grad_norm": 0.5537358522415161,
      "learning_rate": 9.863013698630136e-06,
      "loss": 0.0096,
      "step": 3390
    },
    {
      "epoch": 2.7199999999999998,
      "grad_norm": 0.3010788857936859,
      "learning_rate": 9.589041095890411e-06,
      "loss": 0.0409,
      "step": 3400
    },
    {
      "epoch": 2.7199999999999998,
      "eval_loss": 0.015697866678237915,
      "eval_runtime": 16.0828,
      "eval_samples_per_second": 62.178,
      "eval_steps_per_second": 7.772,
      "step": 3400
    },
    {
      "epoch": 2.7279999999999998,
      "grad_norm": 0.6130049824714661,
      "learning_rate": 9.315068493150685e-06,
      "loss": 0.0168,
      "step": 3410
    },
    {
      "epoch": 2.7359999999999998,
      "grad_norm": 0.4199168086051941,
      "learning_rate": 9.04109589041096e-06,
      "loss": 0.0081,
      "step": 3420
    },
    {
      "epoch": 2.7439999999999998,
      "grad_norm": 0.11563803255558014,
      "learning_rate": 8.767123287671233e-06,
      "loss": 0.0435,
      "step": 3430
    },
    {
      "epoch": 2.752,
      "grad_norm": 0.2072083204984665,
      "learning_rate": 8.493150684931507e-06,
      "loss": 0.0258,
      "step": 3440
    },
    {
      "epoch": 2.76,
      "grad_norm": 0.016769232228398323,
      "learning_rate": 8.21917808219178e-06,
      "loss": 0.0108,
      "step": 3450
    },
    {
      "epoch": 2.76,
      "eval_loss": 0.01549376267939806,
      "eval_runtime": 16.3151,
      "eval_samples_per_second": 61.293,
      "eval_steps_per_second": 7.662,
      "step": 3450
    },
    {
      "epoch": 2.768,
      "grad_norm": 1.4588873386383057,
      "learning_rate": 7.945205479452056e-06,
      "loss": 0.0339,
      "step": 3460
    },
    {
      "epoch": 2.776,
      "grad_norm": 0.09976152330636978,
      "learning_rate": 7.671232876712329e-06,
      "loss": 0.0146,
      "step": 3470
    },
    {
      "epoch": 2.784,
      "grad_norm": 0.5568811893463135,
      "learning_rate": 7.3972602739726036e-06,
      "loss": 0.0329,
      "step": 3480
    },
    {
      "epoch": 2.792,
      "grad_norm": 1.3805524110794067,
      "learning_rate": 7.123287671232877e-06,
      "loss": 0.0598,
      "step": 3490
    },
    {
      "epoch": 2.8,
      "grad_norm": 1.203710913658142,
      "learning_rate": 6.849315068493151e-06,
      "loss": 0.029,
      "step": 3500
    },
    {
      "epoch": 2.8,
      "eval_loss": 0.015325655229389668,
      "eval_runtime": 16.2974,
      "eval_samples_per_second": 61.359,
      "eval_steps_per_second": 7.67,
      "step": 3500
    },
    {
      "epoch": 2.808,
      "grad_norm": 2.8054895401000977,
      "learning_rate": 6.5753424657534245e-06,
      "loss": 0.0524,
      "step": 3510
    },
    {
      "epoch": 2.816,
      "grad_norm": 0.3247010409832001,
      "learning_rate": 6.301369863013699e-06,
      "loss": 0.0193,
      "step": 3520
    },
    {
      "epoch": 2.824,
      "grad_norm": 0.7575758695602417,
      "learning_rate": 6.027397260273973e-06,
      "loss": 0.0328,
      "step": 3530
    },
    {
      "epoch": 2.832,
      "grad_norm": 0.08834008872509003,
      "learning_rate": 5.753424657534247e-06,
      "loss": 0.0247,
      "step": 3540
    },
    {
      "epoch": 2.84,
      "grad_norm": 0.07176603376865387,
      "learning_rate": 5.479452054794521e-06,
      "loss": 0.0161,
      "step": 3550
    },
    {
      "epoch": 2.84,
      "eval_loss": 0.015091960318386555,
      "eval_runtime": 16.4877,
      "eval_samples_per_second": 60.651,
      "eval_steps_per_second": 7.581,
      "step": 3550
    },
    {
      "epoch": 2.848,
      "grad_norm": 1.6232233047485352,
      "learning_rate": 5.2054794520547945e-06,
      "loss": 0.028,
      "step": 3560
    },
    {
      "epoch": 2.856,
      "grad_norm": 0.016541561111807823,
      "learning_rate": 4.931506849315068e-06,
      "loss": 0.0198,
      "step": 3570
    },
    {
      "epoch": 2.864,
      "grad_norm": 0.8808953166007996,
      "learning_rate": 4.657534246575343e-06,
      "loss": 0.015,
      "step": 3580
    },
    {
      "epoch": 2.872,
      "grad_norm": 0.05748804658651352,
      "learning_rate": 4.383561643835616e-06,
      "loss": 0.0527,
      "step": 3590
    },
    {
      "epoch": 2.88,
      "grad_norm": 3.226975679397583,
      "learning_rate": 4.10958904109589e-06,
      "loss": 0.0369,
      "step": 3600
    },
    {
      "epoch": 2.88,
      "eval_loss": 0.014841089025139809,
      "eval_runtime": 16.6513,
      "eval_samples_per_second": 60.055,
      "eval_steps_per_second": 7.507,
      "step": 3600
    },
    {
      "epoch": 2.888,
      "grad_norm": 0.21008822321891785,
      "learning_rate": 3.8356164383561645e-06,
      "loss": 0.0147,
      "step": 3610
    },
    {
      "epoch": 2.896,
      "grad_norm": 2.897786855697632,
      "learning_rate": 3.5616438356164386e-06,
      "loss": 0.0556,
      "step": 3620
    },
    {
      "epoch": 2.904,
      "grad_norm": 0.34739241003990173,
      "learning_rate": 3.2876712328767123e-06,
      "loss": 0.0189,
      "step": 3630
    },
    {
      "epoch": 2.912,
      "grad_norm": 0.1247481033205986,
      "learning_rate": 3.0136986301369864e-06,
      "loss": 0.0148,
      "step": 3640
    },
    {
      "epoch": 2.92,
      "grad_norm": 0.20174768567085266,
      "learning_rate": 2.7397260273972604e-06,
      "loss": 0.0544,
      "step": 3650
    },
    {
      "epoch": 2.92,
      "eval_loss": 0.014559171162545681,
      "eval_runtime": 16.6443,
      "eval_samples_per_second": 60.08,
      "eval_steps_per_second": 7.51,
      "step": 3650
    },
    {
      "epoch": 2.928,
      "grad_norm": 2.397451400756836,
      "learning_rate": 2.465753424657534e-06,
      "loss": 0.0395,
      "step": 3660
    },
    {
      "epoch": 2.936,
      "grad_norm": 4.486625671386719,
      "learning_rate": 2.191780821917808e-06,
      "loss": 0.0295,
      "step": 3670
    },
    {
      "epoch": 2.944,
      "grad_norm": 0.9509544968605042,
      "learning_rate": 1.9178082191780823e-06,
      "loss": 0.0231,
      "step": 3680
    },
    {
      "epoch": 2.952,
      "grad_norm": 2.5998098850250244,
      "learning_rate": 1.6438356164383561e-06,
      "loss": 0.0282,
      "step": 3690
    },
    {
      "epoch": 2.96,
      "grad_norm": 0.6369380950927734,
      "learning_rate": 1.3698630136986302e-06,
      "loss": 0.0164,
      "step": 3700
    },
    {
      "epoch": 2.96,
      "eval_loss": 0.014471596106886864,
      "eval_runtime": 16.7933,
      "eval_samples_per_second": 59.548,
      "eval_steps_per_second": 7.443,
      "step": 3700
    },
    {
      "epoch": 2.968,
      "grad_norm": 0.4532206654548645,
      "learning_rate": 1.095890410958904e-06,
      "loss": 0.0192,
      "step": 3710
    },
    {
      "epoch": 2.976,
      "grad_norm": 0.5350725054740906,
      "learning_rate": 8.219178082191781e-07,
      "loss": 0.0516,
      "step": 3720
    },
    {
      "epoch": 2.984,
      "grad_norm": 1.2795262336730957,
      "learning_rate": 5.47945205479452e-07,
      "loss": 0.0252,
      "step": 3730
    },
    {
      "epoch": 2.992,
      "grad_norm": 5.827698707580566,
      "learning_rate": 2.73972602739726e-07,
      "loss": 0.0536,
      "step": 3740
    },
    {
      "epoch": 3.0,
      "grad_norm": 0.05416474491357803,
      "learning_rate": 0.0,
      "loss": 0.0424,
      "step": 3750
    },
    {
      "epoch": 3.0,
      "eval_loss": 0.014445898123085499,
      "eval_runtime": 16.7039,
      "eval_samples_per_second": 59.866,
      "eval_steps_per_second": 7.483,
      "step": 3750
    }
  ],
  "logging_steps": 10,
  "max_steps": 3750,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 3,
  "save_steps": 100,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 3407082318870528.0,
  "train_batch_size": 8,
  "trial_name": null,
  "trial_params": null
}
